<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>技忆</title>
  <subtitle>Phoebe&#39;s little progress</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://phoebepan.cn/"/>
  <updated>2017-07-08T11:35:58.000Z</updated>
  <id>http://phoebepan.cn/</id>
  
  <author>
    <name>Phoebe</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>调超参神器——GridSearchCV</title>
    <link href="http://phoebepan.cn/2017/06/16/GridSearchCV/"/>
    <id>http://phoebepan.cn/2017/06/16/GridSearchCV/</id>
    <published>2017-06-16T07:30:16.000Z</published>
    <updated>2017-07-08T11:35:58.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote class="blockquote-center"><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>所谓超参，就是机器学习算法中，不能通过自身学习设定的参数，如SVM的惩罚因子C，核函数kernel，gamma参数等，参数间的组合很是繁琐，人工调节这些超参数时间成本太高，易出错。本文主要介绍sklearn模块的调参神器<code>GridSearchCV</code>模块，它能够在指定范围内自动搜索具有不同超参数的不同模型组合，寻找最佳参数，大大提高调参效率。</p>
</blockquote>
<a id="more"></a>
<h3 id="缘起"><a href="#缘起" class="headerlink" title="缘起"></a>缘起</h3><p>这两天，闲来参加下Ctrip的一个数据竞赛，model选择的是XGboost，好用是自然，但是参数有很多，最迫切需要一个自动调节参数工具，于是接触到GridSearchCV模块。</p>
<h3 id="官方手册"><a href="#官方手册" class="headerlink" title="官方手册"></a>官方手册</h3><p><a href="http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html#sklearn.grid_search.GridSearchCV" target="_blank" rel="external">手册链接</a></p>
<h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><p>自己训练的代码如下(XGboost+5-fold Cross Validation)，清晰易懂，无须解释。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</div><div class="line"><span class="keyword">from</span> sklearn.grid_search <span class="keyword">import</span> GridSearchCV</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">xgbmodel_train</span><span class="params">(train)</span>:</span></div><div class="line">    xgb_model = xgb.XGBClassifier()</div><div class="line">    train_feature, train_label = train.drop(<span class="string">'orderlabel'</span>, axis=<span class="number">1</span>), train[<span class="string">'orderlabel'</span>]</div><div class="line"></div><div class="line">    parameters = &#123;<span class="string">'nthread'</span>: [<span class="number">4</span>],</div><div class="line">                  <span class="string">'objective'</span>: [<span class="string">'binary:logistic'</span>],</div><div class="line">                  <span class="string">'learning_rate'</span>: [<span class="number">0.05</span>,<span class="number">0.06</span>,<span class="number">0.1</span>],</div><div class="line">                  <span class="string">'max_depth'</span>: [<span class="number">5</span>, <span class="number">6</span>],</div><div class="line">                  <span class="string">'min_child_weight'</span>: [<span class="number">1</span>, <span class="number">3</span>],</div><div class="line">                  <span class="string">'silent'</span>: [<span class="number">1</span>],</div><div class="line">                  <span class="string">'gamma'</span>: [<span class="number">0</span>, <span class="number">0.1</span>],</div><div class="line">                  <span class="string">'subsample'</span>: [<span class="number">0.6</span>, <span class="number">0.7</span>, <span class="number">0.8</span>],</div><div class="line">                  <span class="string">'colsample_bytree'</span>: [<span class="number">0.7</span>, <span class="number">0.5</span>, <span class="number">0.6</span>],</div><div class="line">                  <span class="string">'n_estimators'</span>: [<span class="number">5</span>],</div><div class="line">                  <span class="string">'missing'</span>: [<span class="number">-999</span>],</div><div class="line">                  <span class="string">'seed'</span>: [<span class="number">12455</span>]&#125;</div><div class="line"></div><div class="line">    clf = GridSearchCV(xgb_model, parameters, n_jobs=<span class="number">1</span>,</div><div class="line">                       cv=StratifiedKFold(train[<span class="string">'orderlabel'</span>], n_folds=<span class="number">5</span>, shuffle=<span class="keyword">True</span>),</div><div class="line">                       scoring=<span class="string">'roc_auc'</span>,</div><div class="line">                       verbose=<span class="number">2</span>, refit=<span class="keyword">True</span>)</div><div class="line"></div><div class="line"></div><div class="line">    clf.fit(train_feature, train_label)</div><div class="line">   </div><div class="line">    best_parameters, score, _ = max(clf.grid_scores_, key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>])</div><div class="line">    print(<span class="string">'AUC score:'</span>, score)</div><div class="line">    <span class="keyword">for</span> param_name <span class="keyword">in</span> sorted(best_parameters.keys()):</div><div class="line">        print(<span class="string">'%s: %r'</span> % (param_name, best_parameters[param_name]))</div></pre></td></tr></table></figure></p>
<h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p><img src="/images/process.png" alt="process"><br><img src="/images/best_score.png" alt="best para"></p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote class=&quot;blockquote-center&quot;&gt;&lt;h3 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h3&gt;&lt;p&gt;所谓超参，就是机器学习算法中，不能通过自身学习设定的参数，如SVM的惩罚因子C，核函数kernel，gamma参数等，参数间的组合很是繁琐，人工调节这些超参数时间成本太高，易出错。本文主要介绍sklearn模块的调参神器&lt;code&gt;GridSearchCV&lt;/code&gt;模块，它能够在指定范围内自动搜索具有不同超参数的不同模型组合，寻找最佳参数，大大提高调参效率。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Machine Learning" scheme="http://phoebepan.cn/categories/Machine-Learning/"/>
    
    
      <category term="ML Tune" scheme="http://phoebepan.cn/tags/ML-Tune/"/>
    
  </entry>
  
  <entry>
    <title>数据可视化——Seaborn</title>
    <link href="http://phoebepan.cn/2017/06/06/learn_seaborn/"/>
    <id>http://phoebepan.cn/2017/06/06/learn_seaborn/</id>
    <published>2017-06-06T07:30:16.000Z</published>
    <updated>2017-06-28T15:14:42.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote class="blockquote-center"><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>EDA过程中，想要更了解你的数据，选择一个合适的可视化工具，可以说会让你的工作事半功倍。<br>本文主要介绍一个以matplotlib作为底层，更易上手的作图库<code>seaborn</code>。</p>
</blockquote>
<a id="more"></a>
<h3 id="Seaborn"><a href="#Seaborn" class="headerlink" title="Seaborn"></a>Seaborn</h3><p>基于matplotlib的可视化库，旨在使默认的数据可视化更加悦目，简化复杂图表创建，可以与pandas很好的集成。</p>
<h3 id="简易用法"><a href="#简易用法" class="headerlink" title="简易用法"></a>简易用法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns <span class="comment">#一旦导入了seaborn，matplotlib的默认作图风格就会被覆盖成seaborn的格式</span></div><div class="line">%matplotlib inline </div><div class="line"><span class="comment">#在jupyter notebook里作图，需要用到这个命令</span></div></pre></td></tr></table></figure>
<h4 id="读取原始数据（这是一份红酒成分与口感评分数据）"><a href="#读取原始数据（这是一份红酒成分与口感评分数据）" class="headerlink" title="读取原始数据（这是一份红酒成分与口感评分数据）"></a>读取原始数据（这是一份红酒成分与口感评分数据）</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">winedata=pd.read_csv(<span class="string">'winequality-red.csv'</span>)</div><div class="line">winedata.head()</div></pre></td></tr></table></figure>
<p><img src="/images/winedata.png" alt="png"></p>
<h4 id="直方图——seaborn-distplot"><a href="#直方图——seaborn-distplot" class="headerlink" title="直方图——seaborn.distplot()"></a><strong>直方图</strong>——seaborn.distplot()</h4><p>如对上面的quality列做直方图，保留概率密度曲线<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">sns.distplot(winedata[<span class="string">'quality'</span>])   <span class="comment"># 不需要概率密度曲线直接将 kde=False 即可</span></div><div class="line">sns.set_style(<span class="string">'dark'</span>)    <span class="comment">#设置背景色</span></div><div class="line">sns.utils.axlabel(<span class="string">'Quality'</span>, <span class="string">'Frequency'</span>) <span class="comment">#设置X,Y坐标名</span></div><div class="line">sns.plt.show()</div></pre></td></tr></table></figure></p>
<p><img src="/images/output_5_0.png" alt="png"></p>
<h4 id="折线图"><a href="#折线图" class="headerlink" title="折线图"></a>折线图</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">sns.factorplot(data=winedata, x=<span class="string">'quality'</span>, y=<span class="string">'total sulfur dioxide'</span>,size=<span class="number">3</span>)</div><div class="line">sns.plt.show()</div></pre></td></tr></table></figure>
<p><img src="/images/output_7_0.png" alt="png"></p>
<h4 id="柱状图——seaborn-barplot"><a href="#柱状图——seaborn-barplot" class="headerlink" title="柱状图——seaborn.barplot()"></a>柱状图——seaborn.barplot()</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">sns.factorplot(data=winedata, x=<span class="string">'quality'</span>, y=<span class="string">'total sulfur dioxide'</span>,kind=<span class="string">'bar'</span>,size=<span class="number">3</span>)</div><div class="line"><span class="comment">#ax = sns.barplot(data=winedata, x='quality', y='total sulfur dioxide',ci=0)</span></div><div class="line">sns.plt.show()</div></pre></td></tr></table></figure>
<p><img src="/images/output_9_0.png" alt="png"></p>
<h4 id="散点图——seaborn-stripplot"><a href="#散点图——seaborn-stripplot" class="headerlink" title="散点图——seaborn.stripplot()"></a>散点图——seaborn.stripplot()</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">temp=sns.FacetGrid(winedata, hue=<span class="string">'quality'</span>, size=<span class="number">3</span>)   <span class="comment">#hue参数设置区分色彩列</span></div><div class="line">temp.map(plt.scatter, <span class="string">'volatile acidity'</span>, <span class="string">'alcohol'</span>)</div><div class="line">temp.add_legend()</div><div class="line">sns.plt.show()</div><div class="line"><span class="comment">#ax = sns.stripplot(x='quality', y='alcohol', data=winedata) #普通散点图</span></div><div class="line"><span class="comment">#ax = sns.stripplot(x='quality', y='alcohol', data=winedata, jitter=True) #带抖动的散点图</span></div><div class="line"><span class="comment">#sns.plt.show()</span></div></pre></td></tr></table></figure>
<p><img src="/images/output_11_0.png" alt="png"></p>
<h4 id="箱型图——seaborn-boxplot"><a href="#箱型图——seaborn-boxplot" class="headerlink" title="箱型图——seaborn.boxplot()"></a>箱型图——seaborn.boxplot()</h4><p>以quality为X轴，alcohol为Y轴，做出箱线图，可以看出异常值<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">ax=sns.boxplot(x=<span class="string">'quality'</span>, y=<span class="string">'alcohol'</span>, data=winedata)</div><div class="line">ax=sns.stripplot(x=<span class="string">'quality'</span>, y=<span class="string">'alcohol'</span>, data=winedata, jitter=<span class="keyword">True</span>, color=<span class="string">'.3'</span>)  <span class="comment">#加上点，jitter=True 使各个散点分开，要不然会是一条直线</span></div><div class="line">sns.plt.show()</div></pre></td></tr></table></figure></p>
<p><img src="/images/output_13_0.png" alt="png"></p>
<h4 id="小提琴图——seaborn-violinplot"><a href="#小提琴图——seaborn-violinplot" class="headerlink" title="小提琴图——seaborn.violinplot()"></a>小提琴图——seaborn.violinplot()</h4><p>可以看出密度分布<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">ax = sns.violinplot(x=<span class="string">'quality'</span>, y=<span class="string">'alcohol'</span>, data=winedata, size=<span class="number">5</span>)</div><div class="line">ax = sns.swarmplot(x=<span class="string">'quality'</span>, y=<span class="string">'alcohol'</span>, data=winedata,color=<span class="string">'.9'</span>)</div><div class="line">sns.plt.show()</div></pre></td></tr></table></figure></p>
<p><img src="/images/output_15_0.png" alt="png"></p>
<h4 id="多变量作图——seaborn-pairplot"><a href="#多变量作图——seaborn-pairplot" class="headerlink" title="多变量作图——seaborn.pairplot()"></a>多变量作图——seaborn.pairplot()</h4><p>seaborn可以一次性两两组合多个变量做出多个对比图，有n个变量，就会做出一个n × n个格子的图，相同的两个变量之间以直方图展示，不同的变量则以散点图展示，<strong>要注意的是数据中不能有NaN（缺失的数据），否则会报错。</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">sns.pairplot(winedata, vars=[<span class="string">'quality'</span>, <span class="string">'residual sugar'</span>,<span class="string">'alcohol'</span>],hue=<span class="string">'quality'</span>)</div><div class="line">sns.plt.show()</div></pre></td></tr></table></figure></p>
<p><img src="/images/output_17_0.png" alt="png"></p>
<h4 id="回归图——seaborn-lmplot-、seaborn-regplot"><a href="#回归图——seaborn-lmplot-、seaborn-regplot" class="headerlink" title="回归图——seaborn.lmplot()、seaborn.regplot()"></a>回归图——seaborn.lmplot()、seaborn.regplot()</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">sns.lmplot(x=<span class="string">'volatile acidity'</span>, y=<span class="string">'alcohol'</span>, data=winedata)   <span class="comment"># hue参数进行分组拟合，markers=['o', 'x']，col参数不同组的子图</span></div><div class="line">sns.plt.show()</div></pre></td></tr></table></figure>
<p><img src="/images/output_19_0.png" alt="png"><br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">sns.regplot(x=<span class="string">'fixed acidity'</span>, y=<span class="string">'alcohol'</span>, data=winedata)</div><div class="line">sns.plt.show()</div></pre></td></tr></table></figure></p>
<p><img src="/images/output_20_0.png" alt="png"></p>
<p><a href="http://seaborn.pydata.org/tutorial.html" target="_blank" rel="external">更多用法参考官方手册</a><br>点这查看本文<a href="https://github.com/phoebepx/normally-accumulate/blob/master/learn_seaborn.ipynb" target="_blank" rel="external">.ipynb文件</a>，欢迎纠错~</p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote class=&quot;blockquote-center&quot;&gt;&lt;h3 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h3&gt;&lt;p&gt;EDA过程中，想要更了解你的数据，选择一个合适的可视化工具，可以说会让你的工作事半功倍。&lt;br&gt;本文主要介绍一个以matplotlib作为底层，更易上手的作图库&lt;code&gt;seaborn&lt;/code&gt;。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Data Visualization" scheme="http://phoebepan.cn/categories/Data-Visualization/"/>
    
    
      <category term="ML" scheme="http://phoebepan.cn/tags/ML/"/>
    
      <category term="Visualization" scheme="http://phoebepan.cn/tags/Visualization/"/>
    
  </entry>
  
  <entry>
    <title>阅读笔记——7 Techniques to Handle Imbalanced Data</title>
    <link href="http://phoebepan.cn/2017/06/05/Imbalanced_data/"/>
    <id>http://phoebepan.cn/2017/06/05/Imbalanced_data/</id>
    <published>2017-06-05T07:30:16.000Z</published>
    <updated>2017-06-28T15:15:00.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote class="blockquote-center"><p>这篇阅读笔记，主要介绍处理不平衡数据的常见7种方法。所谓<strong>不平衡数据</strong>，指在网络入侵、癌症监测、银行信用卡检测等领域，出现如下图所示的数据集中，正负样本比例严重失调的情况。<br><img src="/images/imbalanced-data-1.png" alt="imbalanced-data-1" title="正负样本分布"></p>
</blockquote>
<a id="more"></a>
<p><a href="http://www.kdnuggets.com/2017/06/7-techniques-handle-imbalanced-data.html" target="_blank" rel="external">博客中</a>介绍了7种方法帮助我们训练一个分类器，来处理这些不平衡的数据。</p>
<h3 id="1-使用正确的评价指标"><a href="#1-使用正确的评价指标" class="headerlink" title="1.使用正确的评价指标"></a>1.使用正确的评价指标</h3><p>针对上图这样的数据集，如果我们还是采用准确度(accuracy)来评估模型训练结果，那么所有的分类器将所有的测试样本都分到“0”这一类，模型准确率无疑非常好，但显然，这样的model对我们来说，是没有价值的。<br>这种情况，其他适宜的评估指标有：<code>Precision/Specificity</code>、<code>Recall/Sensitivity</code>、<code>F1 score</code>、<code>MCC</code>、<code>AUC</code>、<code>G-Mean</code></p>
<h3 id="2-训练集重新采样-Resample"><a href="#2-训练集重新采样-Resample" class="headerlink" title="2.训练集重新采样(Resample)"></a>2.训练集重新采样(Resample)</h3><p>除了使用不同的评价指标，另外可以通过<strong>下采样</strong>和<strong>过采样</strong>在不平衡数据中得到平衡数据集。</p>
<h4 id="下采样-Under-sampling"><a href="#下采样-Under-sampling" class="headerlink" title="下采样(Under-sampling)"></a>下采样(Under-sampling)</h4><p>当数据量充足时，下采样通过减少负样本数量（即多数的类），即保留正样本和随机选择相同数量的负样本，得到新的平衡训练集。</p>
<h4 id="过采样-Over-sampling"><a href="#过采样-Over-sampling" class="headerlink" title="过采样(Over-sampling)"></a>过采样(Over-sampling)</h4><p>当数据量不够时，过采样通过增加正样本数来平衡数据集，可以采用<code>repetition</code>、<code>bootstrapping</code>、<code>SMOTE</code>得到新的正样本。<br><a href="https://github.com/scikit-learn-contrib/imbalanced-learn" target="_blank" rel="external">Python实现</a></p>
<p>下采样和过采样两者之间没有谁优谁劣，具体用哪种方式取决于数据集本身，有时两者结合使用可能效果更好。</p>
<h3 id="3-正确使用K折交叉验证"><a href="#3-正确使用K折交叉验证" class="headerlink" title="3.正确使用K折交叉验证"></a>3.正确使用K折交叉验证</h3><p>值得注意的是，当我们用过采样处理不平衡训练集时，通常需要在<strong>过采样之前应用交叉验证</strong>，这样做的好处就是避免模型过拟合。</p>
<h4 id="过拟合产生原因："><a href="#过拟合产生原因：" class="headerlink" title="过拟合产生原因："></a>过拟合产生原因：</h4><ul>
<li>模型的复杂度越高，越容易overfitting</li>
<li>数据的噪声越大，越容易overfitting</li>
<li>数据量越少，越容易overfitting</li>
</ul>
<h3 id="4-重采样训练集集成-Ensemble"><a href="#4-重采样训练集集成-Ensemble" class="headerlink" title="4.重采样训练集集成(Ensemble)"></a>4.重采样训练集集成(Ensemble)</h3><p><img src="/images/imbalanced-data-2.png" alt="imbalanced-data-2" title="Ensemble different resampled datasets"><br>如上面示例图所示，使用所有的正样本和 n 个不同的负样本建立 n 个models。比如你想得到10个models，如果正样本是1000个，那么你需要随机选择10000个负样本，然后将这10000个负样本分成10份，接下来训练这10个不同的models。<br>这种方法，简单方便，易扩展，更好的泛化能力。</p>
<h3 id="5-不同比例采样"><a href="#5-不同比例采样" class="headerlink" title="5.不同比例采样"></a>5.不同比例采样</h3><p>之前的方法，都是1:1调和样本，最佳的比例取决于数据和使用的模型。与其对所有models使用同样的比例进行ensemble，更值得尝试的是采用不同的比例进行ensemble。正如下图所示：<br><img src="/images/imbalanced-data-3.png" alt="imbalanced-data-3" title="Resample with different ratios"></p>
<h3 id="6-负样本进行聚类"><a href="#6-负样本进行聚类" class="headerlink" title="6.负样本进行聚类"></a>6.负样本进行聚类</h3><p>Sergey在Quora上提出一个更完美的<a href="www.quora.com/In-classification-how-do-you-handle-an-unbalanced-training-set/answers/1144228?srid=h3G6o">方法</a>，对负样本进行聚类，只用负样本聚类的簇中心和正样本组成训练集。</p>
<h3 id="7-自己设计模型"><a href="#7-自己设计模型" class="headerlink" title="7.自己设计模型"></a>7.自己设计模型</h3><p>事实上，已经有一些models本身就可以处理非平衡数据集，无需进行重新采样，如XGBoost。<br>重设损失函数，比起负样本误分，对正样本误分设置更大的惩罚系数。</p>
<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>这些处理方法只是一个起点，没有一种方法可以解决所有问题，<code>多试才是王道</code>！</p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote class=&quot;blockquote-center&quot;&gt;&lt;p&gt;这篇阅读笔记，主要介绍处理不平衡数据的常见7种方法。所谓&lt;strong&gt;不平衡数据&lt;/strong&gt;，指在网络入侵、癌症监测、银行信用卡检测等领域，出现如下图所示的数据集中，正负样本比例严重失调的情况。&lt;br&gt;&lt;img src=&quot;/images/imbalanced-data-1.png&quot; alt=&quot;imbalanced-data-1&quot; title=&quot;正负样本分布&quot;&gt;&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Machine Learning" scheme="http://phoebepan.cn/categories/Machine-Learning/"/>
    
    
      <category term="ML" scheme="http://phoebepan.cn/tags/ML/"/>
    
      <category term="Reading" scheme="http://phoebepan.cn/tags/Reading/"/>
    
  </entry>
  
  <entry>
    <title>充实的无话可说</title>
    <link href="http://phoebepan.cn/2017/05/15/fine_life/"/>
    <id>http://phoebepan.cn/2017/05/15/fine_life/</id>
    <published>2017-05-15T07:30:16.000Z</published>
    <updated>2017-06-04T02:26:13.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote class="blockquote-center"><p>有人说，人生有两大遗憾，太晚谈恋爱，太早读经典。读懂一本书，看懂一部电影和谈对一场恋爱，都需要刚刚好的时间。太早理解不了，太晚就少了份陪伴感。</p>
</blockquote>
<a id="more"></a>
<h3 id="碎碎念1"><a href="#碎碎念1" class="headerlink" title="碎碎念1"></a><center>碎碎念1</center></h3><blockquote>
<p>好朋友问我，嘿，最近怎么不见你出去浪了呢，端午打算去哪耍去？<br>我笑着答道，宅家看书。<br>朋友诡异的看着我说，不是吧，学霸真可怕！</p>
</blockquote>
<p>回想年后这几个月自己的转变还真是蛮大的，从以前放荡自由的野孩子，变得像点研究僧的模样，而且越来越喜欢这样自律的自己。<br>研一的周末，要么在研究烘焙，要么参加户外活动，认识了很多有意思的朋友，相比较单调的校园生活，可以说外面的世界太精彩，一次次被惊艳，看着他们活出自己理想生活状态，可以说是非常羡慕。然而渐渐我发现，如果自己不够优秀，认识再多的人，你的生活也不会有所改变。现在的我，学着跟自己和平相处，控制情绪，学着量化每天的时间，每天有小目标，生活得很充实。</p>
<h3 id="碎碎念2"><a href="#碎碎念2" class="headerlink" title="碎碎念2"></a><center>碎碎念2</center></h3><p>现在的我，每天不管多忙，多晚，也要读几页书，读书，可以说是一种自嗨的事儿，一旦这样的自嗨能力养成了，你就不容易陷入无聊，不容易被别人的想法左右。<br>人只能活一次，没有可以对标的人生，上一辈的建议有时过气，同龄人其实也一样迷茫，而读书就不一样了，只要你尝试阅读不同的书，你就可以尝试不同的人生，体验不同的精彩生活，重回现实，你会活的更明白。<br>平淡的日子，不急不躁，继续丰盈自己~</p>
<p><img src="/images/Shawshank_Redemption.jpg" alt="肖申克的救赎" title="The Shawshank Redemption"></p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote class=&quot;blockquote-center&quot;&gt;&lt;p&gt;有人说，人生有两大遗憾，太晚谈恋爱，太早读经典。读懂一本书，看懂一部电影和谈对一场恋爱，都需要刚刚好的时间。太早理解不了，太晚就少了份陪伴感。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Thinking" scheme="http://phoebepan.cn/categories/Thinking/"/>
    
    
      <category term="Thinking" scheme="http://phoebepan.cn/tags/Thinking/"/>
    
      <category term="Life" scheme="http://phoebepan.cn/tags/Life/"/>
    
  </entry>
  
  <entry>
    <title>Modern Machine Learning Algorithms:Strengths and Weaknesses(阅读笔记)</title>
    <link href="http://phoebepan.cn/2017/05/13/ML_good_weak/"/>
    <id>http://phoebepan.cn/2017/05/13/ML_good_weak/</id>
    <published>2017-05-13T07:30:16.000Z</published>
    <updated>2017-06-02T14:34:39.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote class="blockquote-center"><p><center><strong>推荐理由</strong></center><br>对于机器学习算法的盘点，网上有很多。但本文亮点在于结合使用场景来把问题说明白，作者结合他的实际经验，细致剖析每种算法在实践中的优势和不足。</p>
</blockquote>
<a id="more"></a>
<p>当前的「三大」最常见的机器学习任务：</p>
<ul>
<li>回归（Regression）</li>
<li>分类（Classification）</li>
<li>聚类（Clustering）</li>
</ul>
<p>下面是我阅读这篇文章后总结的的思维导图：<br><img src="/images/whole.png" alt="机器学习3大任务" title="机器学习3大任务"><br><img src="/images/regression1.png" alt="回归"><br><img src="/images/regression2.png" alt="回归" title="回归"><br><img src="/images/classfication1.png" alt="分类"><br><img src="/images/classfication2.png" alt="分类" title="分类"><br><img src="/images/cocluster1.png" alt="聚类"><br><img src="/images/cocluster2.png" alt="聚类" title="聚类"><br>最后，<a href="https://elitedatascience.com/machine-learning-algorithms" target="_blank" rel="external">附原文链接</a>，欢迎纠错。<br><blockquote class="blockquote-center"><p>Of course, the algorithms you try must be appropriate for your problem, which is where picking the right machine learning task comes in.</p>
</blockquote></p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote class=&quot;blockquote-center&quot;&gt;&lt;p&gt;&lt;center&gt;&lt;strong&gt;推荐理由&lt;/strong&gt;&lt;/center&gt;&lt;br&gt;对于机器学习算法的盘点，网上有很多。但本文亮点在于结合使用场景来把问题说明白，作者结合他的实际经验，细致剖析每种算法在实践中的优势和不足。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Machine Learning" scheme="http://phoebepan.cn/categories/Machine-Learning/"/>
    
    
      <category term="ML" scheme="http://phoebepan.cn/tags/ML/"/>
    
      <category term="Reading" scheme="http://phoebepan.cn/tags/Reading/"/>
    
  </entry>
  
  <entry>
    <title>Pandas杂碎</title>
    <link href="http://phoebepan.cn/2017/05/12/pandas/"/>
    <id>http://phoebepan.cn/2017/05/12/pandas/</id>
    <published>2017-05-12T07:30:16.000Z</published>
    <updated>2017-05-29T05:14:14.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote class="blockquote-center"><p>本文主要是平时运用Pandas的小积累，涉及到读写文件，格式转换、缺失值填充，简单统计等多个方面。</p>
</blockquote>
<a id="more"></a>
<h3 id="读写csv文件到DataFrame"><a href="#读写csv文件到DataFrame" class="headerlink" title="读写csv文件到DataFrame"></a>读写csv文件到DataFrame</h3><p><code>df=pd.read_csv(&#39;filename&#39;,encoding=&#39;utf-8&#39;)</code><br>读入csv文本，编码为utf-8<br><code>df.to_csv(&#39;filename&#39;,sep=&#39;\t&#39;,index=False)</code><br>‘\t’切分df，写入csv，不包含行索引</p>
<h3 id="格式转换、值填充、删除"><a href="#格式转换、值填充、删除" class="headerlink" title="格式转换、值填充、删除"></a>格式转换、值填充、删除</h3><p> <code>df.to_dict(outtype=&#39;dict&#39;)</code><br>将DataFrame转换成其他结构类型，outtype的参数为‘dict’、‘list’、‘series’和‘records’<br> <code>df[&#39;A&#39;].astype(float)</code><br>将DataFrame的A列类型更改成float<br><code>df.rename(columns={&#39;oldname&#39;: &#39;newname&#39;}, inplace=True)</code>   #修改列名<br><code>df.fillna(0)</code>  #NaN用0填充，处理缺失值<br><code>df.drop_duplicates(subset=[&#39;A&#39;]，keep=&#39;first&#39;)</code><br>按A列去重，保留第一行，keep（’first’,’last’,False）</p>
<h3 id="查看DataFrame概要"><a href="#查看DataFrame概要" class="headerlink" title="查看DataFrame概要"></a>查看DataFrame概要</h3><p><code>df.head()</code>     #前几行<br><code>df.tail()</code>     #末几行<br><code>df.index</code>      #行标签<br><code>df.columns</code>    #列标签<br><code>df.dtypes</code>     #每一列数据类型<br><code>df[&#39;column&#39;].count()</code>    #column列非空条数<br><code>df[&#39;column&#39;].isnull()</code>   #column列是否有NaN的数据<br><code>df[&#39;column&#39;].unique()</code>    #column列所有值</p>
<h3 id="简单统计"><a href="#简单统计" class="headerlink" title="简单统计"></a>简单统计</h3><p><code>df.describe()</code>   #各列基本描述统计值<br><code>df[&#39;A&#39;].value_counts()</code>  #计算A列每个值的频率</p>
<h3 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h3><p><code>df.sort_index(axis=1,ascending=False)</code><br>对DataFrame的axis=0(行)，1(列)索引排序（ascending=True(升)，False(降)）<br><code>df.sort_index(by=[&#39;A&#39;, &#39;B&#39;], ascending=[True, False])</code>&lt;==&gt;<code>df.sort_values(by=[&#39;A&#39;, &#39;B&#39;], ascending=[True, False])</code>&lt;==&gt;<code>df.sort(columns=[&#39;A&#39;,&#39;B&#39;],ascending=[1,0])</code><br>对DataFrame先按’A’升排序, 再按’B’降排序</p>
<h3 id="分组"><a href="#分组" class="headerlink" title="分组"></a>分组</h3><p><code>df.groupby(subset=[&#39;A&#39;,&#39;B&#39;],as_index=True)</code>    #以列A，B对df进行分组，默认A，B作为分组索引<br><code>df.groupby(by=[&#39;A&#39;],as_index=True).get_group(&#39;a&#39;)</code> #按A列分组后获取’a’组<br><code>df.groupby([&#39;col1&#39;,&#39;col2&#39;]).size().to_frame(name =&#39;count&#39;)</code><br>&lt;==&gt;<code>df.groupby([&#39;col1&#39;,&#39;col2&#39;]).size().reset_index(name =&#39;count&#39;)</code><br>按col1,col2对df进行分组，<code>size()</code>统计每一分组成员个数(<code>count()</code>也可以，<a href="https://stackoverflow.com/documentation/pandas/1822/grouping-data/6874/aggregating-by-size-and-count#t=201607220906502658034" target="_blank" rel="external">区别</a>就是count()过滤了NaN，size()包含)，命名为’count’</p>
<h3 id="选择DataFrame行列"><a href="#选择DataFrame行列" class="headerlink" title="选择DataFrame行列"></a>选择DataFrame行列</h3><p><a href="http://www.shanelynn.ie/select-pandas-dataframe-rows-and-columns-using-iloc-loc-and-ix/" target="_blank" rel="external">示例参考</a><br><code>df.iloc[&lt;row selection&gt;,&lt;col selection&gt;]</code>  #基于行列索引选择（Selecting rows by label/index）<br><code>df.loc[&lt;row selection&gt;,&lt;col selection&gt;]</code>   #基于条件选择（Selecting rows with a boolean / conditional lookup）<br><code>ix[]</code>  #索引，条件混合选择</p>
<p><code>df[df[&#39;A&#39;].isin(li)]</code>  #选择A列值在列表li中的行<br><code>df.saple(n=3)</code> #随机抽取3行数据，</p>
<h3 id="归一化处理"><a href="#归一化处理" class="headerlink" title="归一化处理"></a>归一化处理</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">from sklearn import preprocessing</div><div class="line">df=preprocessing.scale(df,axis=0)   #df每一个feature归一化(列)</div><div class="line">df=preprocessing.scale(df,axis=1)   #df每一个sample归一化(行)</div></pre></td></tr></table></figure>
<h3 id="离散特征one-hot编码"><a href="#离散特征one-hot编码" class="headerlink" title="离散特征one-hot编码"></a>离散特征one-hot编码</h3><p><code>df = pd.get_dummies(df[&#39;A&#39;], prefix=&#39;A&#39;)</code>  #对A列重新编码，编码后的列前缀加上’A’<br><code>df = pd.get_dummies(df)</code>   #对df所有离散特征进行one-hot编码</p>
<h3 id="合并——merge、concat、append"><a href="#合并——merge、concat、append" class="headerlink" title="合并——merge、concat、append"></a>合并——merge、concat、append</h3><p><code>df1.append(df2,ignore_index=True)</code> #在df1下面追加df2，行索引重排序<br><code>pd.concat([df1[&#39;A&#39;],df2],axis=1)</code>  #列方向合并<br><code>pd.merge(df1, df2, how=&#39;inner&#39;, on=None, left_on=None, right_on=None,left_index=False, right_index=False)</code><br>how=[‘inner’,’left’,’right’,’outer’]对应内，左，右，外连接,on指定连接key</p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote class=&quot;blockquote-center&quot;&gt;&lt;p&gt;本文主要是平时运用Pandas的小积累，涉及到读写文件，格式转换、缺失值填充，简单统计等多个方面。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Python" scheme="http://phoebepan.cn/categories/Python/"/>
    
    
      <category term="Python" scheme="http://phoebepan.cn/tags/Python/"/>
    
      <category term="pandas" scheme="http://phoebepan.cn/tags/pandas/"/>
    
  </entry>
  
  <entry>
    <title>如何决定K-Means聚类个数——silhouette analysis</title>
    <link href="http://phoebepan.cn/2017/05/05/silhouette%20analysis/"/>
    <id>http://phoebepan.cn/2017/05/05/silhouette analysis/</id>
    <published>2017-05-05T07:30:16.000Z</published>
    <updated>2017-06-12T23:44:18.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote class="blockquote-center"><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>在K-Means聚类时，我们常常会纠结，K该取多大呢？今天无意当中查看Sklearn时，发现了<code>silhouette analysis</code>，翻译过来，就是轮廓分析，具体来说，就是通过结果簇之间的分隔距离来辅助决定K的取值。偷个懒，直接参照手册，学习下。</p>
</blockquote>
<a id="more"></a>
<h3 id="数据集分布"><a href="#数据集分布" class="headerlink" title="数据集分布"></a>数据集分布</h3><p>下图是500个样本含有2个feature的数据分布情况：<br><img src="/images/scatter.png" alt="scatter"></p>
<h3 id="轮廓系数"><a href="#轮廓系数" class="headerlink" title="轮廓系数"></a>轮廓系数</h3><p>接下来看下，n_clusters 分别为 2，3，4，5，6时，平均的轮廓分值（结果簇之间平均的分隔距离）如下，这个轮廓分值是介于[-1,1]之间的度量指标。每次聚类后，每个样本都会得到一个轮廓系数，当它为1时，说明这个点与周围簇距离较远，结果非常好，当它为0，说明这个点可能处在两个簇的边界上，当值为负时，暗含该点可能被误分了。<br>从平均轮廓分值结果来看，K取3，5，6是不明智的。对于2,4的选择还是有点纠结的，因为它们值相差并不大。</p>
<blockquote>
<p>For n_clusters = 2 The average silhouette_score is : 0.704978749608<br>For n_clusters = 3 The average silhouette_score is : 0.588200401213<br>For n_clusters = 4 The average silhouette_score is : 0.650518663273<br>For n_clusters = 5 The average silhouette_score is : 0.563764690262<br>For n_clusters = 6 The average silhouette_score is : 0.450466629437</p>
</blockquote>
<h3 id="轮廓宽度"><a href="#轮廓宽度" class="headerlink" title="轮廓宽度"></a>轮廓宽度</h3><p>下面是簇为2,3,4,5,6相对应的轮廓图，左图可以看出，当n_clusters = 2时，第0簇的宽度远宽于第1簇，但n_clusters = 4时，所聚的簇宽度相差不大，这样分析下来，自然而然会选择K=4，作为最终聚类个数。<br><img src="/images/figure_1.png" alt="figure1"><br><img src="/images/figure_2.png" alt="figure2"><br><img src="/images/figure_3.png" alt="figure3"><br><img src="/images/figure_4.png" alt="figure4"><br><img src="/images/figure_5.png" alt="figure5"></p>
<p>本例参考官方手册，<a href="http://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html#sphx-glr-auto-examples-cluster-plot-kmeans-silhouette-analysis-py" target="_blank" rel="external">详情戳这</a></p>
<h3 id="附脚本"><a href="#附脚本" class="headerlink" title="附脚本"></a>附脚本</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_blobs</div><div class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</div><div class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> silhouette_samples, silhouette_score</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">import</span> matplotlib.cm <span class="keyword">as</span> cm</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="comment"># Generating the sample data from make_blobs</span></div><div class="line"><span class="comment"># This particular setting has one distinct cluster and 3 clusters placed close</span></div><div class="line"><span class="comment"># together.</span></div><div class="line">X, y = make_blobs(n_samples=<span class="number">500</span>,</div><div class="line">                  n_features=<span class="number">2</span>,</div><div class="line">                  centers=<span class="number">4</span>,</div><div class="line">                  cluster_std=<span class="number">1</span>,</div><div class="line">                  center_box=(<span class="number">-10.0</span>, <span class="number">10.0</span>),</div><div class="line">                  shuffle=<span class="keyword">True</span>,</div><div class="line">                  random_state=<span class="number">1</span>)  <span class="comment"># For reproducibility</span></div><div class="line"></div><div class="line">range_n_clusters = [<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]</div><div class="line"></div><div class="line"><span class="keyword">for</span> n_clusters <span class="keyword">in</span> range_n_clusters:</div><div class="line">    <span class="comment"># Create a subplot with 1 row and 2 columns</span></div><div class="line">    fig, (ax1, ax2) = plt.subplots(<span class="number">1</span>, <span class="number">2</span>)</div><div class="line">    fig.set_size_inches(<span class="number">18</span>, <span class="number">7</span>)</div><div class="line"></div><div class="line">    <span class="comment"># The 1st subplot is the silhouette plot</span></div><div class="line">    <span class="comment"># The silhouette coefficient can range from -1, 1 but in this example all</span></div><div class="line">    <span class="comment"># lie within [-0.1, 1]</span></div><div class="line">    ax1.set_xlim([<span class="number">-0.1</span>, <span class="number">1</span>])</div><div class="line">    <span class="comment"># The (n_clusters+1)*10 is for inserting blank space between silhouette</span></div><div class="line">    <span class="comment"># plots of individual clusters, to demarcate them clearly.</span></div><div class="line">    ax1.set_ylim([<span class="number">0</span>, len(X) + (n_clusters + <span class="number">1</span>) * <span class="number">10</span>])</div><div class="line"></div><div class="line">    <span class="comment"># Initialize the clusterer with n_clusters value and a random generator</span></div><div class="line">    <span class="comment"># seed of 10 for reproducibility.</span></div><div class="line">    clusterer = KMeans(n_clusters=n_clusters, random_state=<span class="number">10</span>)</div><div class="line">    cluster_labels = clusterer.fit_predict(X)</div><div class="line"></div><div class="line">    <span class="comment"># The silhouette_score gives the average value for all the samples.</span></div><div class="line">    <span class="comment"># This gives a perspective into the density and separation of the formed</span></div><div class="line">    <span class="comment"># clusters</span></div><div class="line">    silhouette_avg = silhouette_score(X, cluster_labels)</div><div class="line">    print(<span class="string">"For n_clusters ="</span>, n_clusters,</div><div class="line">          <span class="string">"The average silhouette_score is :"</span>, silhouette_avg)</div><div class="line"></div><div class="line">    <span class="comment"># Compute the silhouette scores for each sample</span></div><div class="line">    sample_silhouette_values = silhouette_samples(X, cluster_labels)</div><div class="line"></div><div class="line">    y_lower = <span class="number">10</span></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n_clusters):</div><div class="line">        <span class="comment"># Aggregate the silhouette scores for samples belonging to</span></div><div class="line">        <span class="comment"># cluster i, and sort them</span></div><div class="line">        ith_cluster_silhouette_values = \</div><div class="line">            sample_silhouette_values[cluster_labels == i]</div><div class="line"></div><div class="line">        ith_cluster_silhouette_values.sort()</div><div class="line"></div><div class="line">        size_cluster_i = ith_cluster_silhouette_values.shape[<span class="number">0</span>]</div><div class="line">        y_upper = y_lower + size_cluster_i</div><div class="line"></div><div class="line">        color = cm.spectral(float(i) / n_clusters)</div><div class="line">        ax1.fill_betweenx(np.arange(y_lower, y_upper),</div><div class="line">                          <span class="number">0</span>, ith_cluster_silhouette_values,</div><div class="line">                          facecolor=color, edgecolor=color, alpha=<span class="number">0.7</span>)</div><div class="line"></div><div class="line">        <span class="comment"># Label the silhouette plots with their cluster numbers at the middle</span></div><div class="line">        ax1.text(<span class="number">-0.05</span>, y_lower + <span class="number">0.5</span> * size_cluster_i, str(i))</div><div class="line"></div><div class="line">        <span class="comment"># Compute the new y_lower for next plot</span></div><div class="line">        y_lower = y_upper + <span class="number">10</span>  <span class="comment"># 10 for the 0 samples</span></div><div class="line"></div><div class="line">    ax1.set_title(<span class="string">"The silhouette plot for the various clusters."</span>)</div><div class="line">    ax1.set_xlabel(<span class="string">"The silhouette coefficient values"</span>)</div><div class="line">    ax1.set_ylabel(<span class="string">"Cluster label"</span>)</div><div class="line"></div><div class="line">    <span class="comment"># The vertical line for average silhouette score of all the values</span></div><div class="line">    ax1.axvline(x=silhouette_avg, color=<span class="string">"red"</span>, linestyle=<span class="string">"--"</span>)</div><div class="line"></div><div class="line">    ax1.set_yticks([])  <span class="comment"># Clear the yaxis labels / ticks</span></div><div class="line">    ax1.set_xticks([<span class="number">-0.1</span>, <span class="number">0</span>, <span class="number">0.2</span>, <span class="number">0.4</span>, <span class="number">0.6</span>, <span class="number">0.8</span>, <span class="number">1</span>])</div><div class="line"></div><div class="line">    <span class="comment"># 2nd Plot showing the actual clusters formed</span></div><div class="line">    colors = cm.spectral(cluster_labels.astype(float) / n_clusters)</div><div class="line">    ax2.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], marker=<span class="string">'.'</span>, s=<span class="number">30</span>, lw=<span class="number">0</span>, alpha=<span class="number">0.7</span>,</div><div class="line">                c=colors)</div><div class="line"></div><div class="line">    <span class="comment"># Labeling the clusters</span></div><div class="line">    centers = clusterer.cluster_centers_</div><div class="line">    <span class="comment"># Draw white circles at cluster centers</span></div><div class="line">    ax2.scatter(centers[:, <span class="number">0</span>], centers[:, <span class="number">1</span>],</div><div class="line">                marker=<span class="string">'o'</span>, c=<span class="string">"white"</span>, alpha=<span class="number">1</span>, s=<span class="number">200</span>)</div><div class="line"></div><div class="line">    <span class="keyword">for</span> i, c <span class="keyword">in</span> enumerate(centers):</div><div class="line">        ax2.scatter(c[<span class="number">0</span>], c[<span class="number">1</span>], marker=<span class="string">'$%d$'</span> % i, alpha=<span class="number">1</span>, s=<span class="number">50</span>)</div><div class="line"></div><div class="line">    ax2.set_title(<span class="string">"The visualization of the clustered data."</span>)</div><div class="line">    ax2.set_xlabel(<span class="string">"Feature space for the 1st feature"</span>)</div><div class="line">    ax2.set_ylabel(<span class="string">"Feature space for the 2nd feature"</span>)</div><div class="line"></div><div class="line">    plt.suptitle((<span class="string">"Silhouette analysis for KMeans clustering on sample data "</span></div><div class="line">                  <span class="string">"with n_clusters = %d"</span> % n_clusters),</div><div class="line">                 fontsize=<span class="number">14</span>, fontweight=<span class="string">'bold'</span>)</div><div class="line"></div><div class="line">    plt.show()</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;blockquote class=&quot;blockquote-center&quot;&gt;&lt;h3 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h3&gt;&lt;p&gt;在K-Means聚类时，我们常常会纠结，K该取多大呢？今天无意当中查看Sklearn时，发现了&lt;code&gt;silhouette analysis&lt;/code&gt;，翻译过来，就是轮廓分析，具体来说，就是通过结果簇之间的分隔距离来辅助决定K的取值。偷个懒，直接参照手册，学习下。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Machine Learning" scheme="http://phoebepan.cn/categories/Machine-Learning/"/>
    
    
      <category term="ML" scheme="http://phoebepan.cn/tags/ML/"/>
    
  </entry>
  
  <entry>
    <title>Scikit-Learn如何做特征选择</title>
    <link href="http://phoebepan.cn/2017/04/30/feature%20selection/"/>
    <id>http://phoebepan.cn/2017/04/30/feature selection/</id>
    <published>2017-04-30T07:30:16.000Z</published>
    <updated>2017-07-08T11:38:42.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote class="blockquote-center"><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>特征选择是<a href="http://phoebepan.cn/2017/04/28/feature%20selection/">特征工程</a>相对重要的一环节，太多不相关的特征会降低模型的准确性，特征选择，可以有效降低过拟合、训练时间等问题。本文简单介绍使用Scikit-Learn做特征选择。</p>
</blockquote>
<a id="more"></a>
<p>Scikit-Learn提供了几种不同的特征选择方法，其一，单变量选择（Univariate Selection）；其二，主成分分析（Principal Component Analysis）；其三，递归特征排除法（Recursive Feature Elimination）；其四，特征重要性排名（feature importance ranking）。</p>
<h3 id="Univariate-Selection"><a href="#Univariate-Selection" class="headerlink" title="Univariate Selection"></a>Univariate Selection</h3><p>原理：使用统计检验方法选择与输出变量最相关的特征。<br>使用方法：Scikit-Learn库中的<a href="http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html#sklearn.feature_selection.SelectKBest" target="_blank" rel="external"><code>SelectKBest</code></a>类可用不同的统计检验方法挑选指定数量的重要特征。<br>举例：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Feature Extraction with Univariate Statistical Tests (Chi-squared for classification)</span></div><div class="line"><span class="keyword">import</span> pandas</div><div class="line"><span class="keyword">import</span> numpy</div><div class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectKBest</div><div class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> chi2</div><div class="line"><span class="comment"># load data</span></div><div class="line">url = <span class="string">"https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data"</span></div><div class="line">names = [<span class="string">'preg'</span>, <span class="string">'plas'</span>, <span class="string">'pres'</span>, <span class="string">'skin'</span>, <span class="string">'test'</span>, <span class="string">'mass'</span>, <span class="string">'pedi'</span>, <span class="string">'age'</span>, <span class="string">'class'</span>]</div><div class="line">dataframe = pandas.read_csv(url, names=names)</div><div class="line">array = dataframe.values</div><div class="line">X = array[:,<span class="number">0</span>:<span class="number">8</span>]</div><div class="line">Y = array[:,<span class="number">8</span>]</div><div class="line"><span class="comment"># feature extraction</span></div><div class="line">test = SelectKBest(score_func=chi2, k=<span class="number">4</span>)</div><div class="line">fit = test.fit(X, Y)</div><div class="line"><span class="comment"># summarize scores</span></div><div class="line">print(fit.scores_)  </div><div class="line"><span class="comment">#[111.52 1411.887 17.605 53.108 2175.565 127.669 5.393 181.304]</span></div><div class="line">X_new = fit.transform(X)</div><div class="line">print(X.shape)              <span class="comment">#(768,8)</span></div><div class="line">print(X_new.shape)          <span class="comment">#(768,4)</span></div></pre></td></tr></table></figure></p>
<h3 id="Principal-Component-Analysis"><a href="#Principal-Component-Analysis" class="headerlink" title="Principal Component Analysis"></a><a href="http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html" target="_blank" rel="external">Principal Component Analysis</a></h3><p>原理：使用线性代数的方式将数据集进行压缩，本质上，是一种降维方法。<br>举例：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Feature Extraction with PCA</span></div><div class="line"><span class="keyword">import</span> numpy</div><div class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> read_csv</div><div class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</div><div class="line"><span class="comment"># load data</span></div><div class="line">url = <span class="string">"https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data"</span></div><div class="line">names = [<span class="string">'preg'</span>, <span class="string">'plas'</span>, <span class="string">'pres'</span>, <span class="string">'skin'</span>, <span class="string">'test'</span>, <span class="string">'mass'</span>, <span class="string">'pedi'</span>, <span class="string">'age'</span>, <span class="string">'class'</span>]</div><div class="line">dataframe = read_csv(url, names=names)</div><div class="line">array = dataframe.values</div><div class="line">X = array[:,<span class="number">0</span>:<span class="number">8</span>]</div><div class="line">Y = array[:,<span class="number">8</span>]</div><div class="line"><span class="comment"># feature extraction</span></div><div class="line">pca = PCA(n_components=<span class="number">3</span>)</div><div class="line">fit = pca.fit(X)</div><div class="line"><span class="comment"># summarize components</span></div><div class="line">print(fit.explained_variance_ratio_)</div><div class="line">print(fit.components_)</div><div class="line">X_new = fit.transform(X)</div><div class="line">print(X_new.shape)      <span class="comment">#(768,3)</span></div></pre></td></tr></table></figure></p>
<h3 id="Recursive-Feature-Elimination-RFE"><a href="#Recursive-Feature-Elimination-RFE" class="headerlink" title="Recursive Feature Elimination (RFE)"></a><a href="http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html#sklearn.feature_selection.RFE" target="_blank" rel="external">Recursive Feature Elimination (RFE)</a></h3><p>原理：递归移除特征，剩余特征重新建模，通过模型准确性识别出贡献度最好的特征。<br>使用方法：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Recursive Feature Elimination</span></div><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</div><div class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> RFE</div><div class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</div><div class="line"><span class="comment"># load the iris datasets</span></div><div class="line">dataset = datasets.load_iris()</div><div class="line"><span class="comment"># create a base classifier used to evaluate a subset of attributes</span></div><div class="line">model = LogisticRegression()</div><div class="line"><span class="comment"># create the RFE model and select 3 attributes</span></div><div class="line">rfe = RFE(model, <span class="number">3</span>)</div><div class="line">rfe = rfe.fit(dataset.data, dataset.target)</div><div class="line"><span class="comment"># summarize the selection of the attributes</span></div><div class="line">print(rfe.support_)     <span class="comment">#[False  True  True  True]</span></div><div class="line">print(rfe.ranking_)     <span class="comment">#[2 1 1 1]</span></div></pre></td></tr></table></figure></p>
<h3 id="Feature-Importance"><a href="#Feature-Importance" class="headerlink" title="Feature Importance"></a>Feature Importance</h3><p>方法：Random Forest，Extra Trees等基于决策树的ensemble方法，可以直接得到每一个特征的重要性分值，这个分值可以用来做特征选择。查阅手册，了解更多<a href="http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html" target="_blank" rel="external">ExtraTreesClassifier</a>。<br>举例：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Feature Importance</span></div><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</div><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</div><div class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> ExtraTreesClassifier</div><div class="line"><span class="comment"># load the iris datasets</span></div><div class="line">dataset = datasets.load_iris()</div><div class="line"><span class="comment"># fit an Extra Trees model to the data</span></div><div class="line">model = ExtraTreesClassifier()</div><div class="line">model.fit(dataset.data, dataset.target)</div><div class="line"><span class="comment"># display the relative importance of each attribute</span></div><div class="line">print(model.feature_importances_)</div></pre></td></tr></table></figure></p>
<p>总之，特征选择主要有3大类方法，过滤(Filter)，重组(Wrapper)，正则化(如LASSO, Elastic Net and Ridge Regression)。</p>
<h3 id="番外篇"><a href="#番外篇" class="headerlink" title="番外篇"></a>番外篇</h3> <blockquote class="blockquote-center"><p>A mistake would be to perform feature selection first to prepare your data, then perform model selection and training on the selected features.</p>
</blockquote>
<p> 这是进行特征选择，可能会犯的错误，我们需要在交叉验证的内循环中嵌入特征选择，即，对每一折进行特征选择。</p>
<p> 另附一份特征选择清单(Checklist)：<br> <img src="/images/feature_selection.png" alt="checklist"><br> 文献阅读：<a href="http://jmlr.csail.mit.edu/papers/volume3/guyon03a/guyon03a.pdf" target="_blank" rel="external">An Introduction to Variable and Feature Selection</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote class=&quot;blockquote-center&quot;&gt;&lt;h3 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h3&gt;&lt;p&gt;特征选择是&lt;a href=&quot;http://phoebepan.cn/2017/04/28/feature%20selection/&quot;&gt;特征工程&lt;/a&gt;相对重要的一环节，太多不相关的特征会降低模型的准确性，特征选择，可以有效降低过拟合、训练时间等问题。本文简单介绍使用Scikit-Learn做特征选择。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Machine Learning" scheme="http://phoebepan.cn/categories/Machine-Learning/"/>
    
    
      <category term="ML FeatureSelection" scheme="http://phoebepan.cn/tags/ML-FeatureSelection/"/>
    
  </entry>
  
  <entry>
    <title>机器学习WorkFlow——Model training</title>
    <link href="http://phoebepan.cn/2017/04/29/train_model/"/>
    <id>http://phoebepan.cn/2017/04/29/train_model/</id>
    <published>2017-04-29T07:30:16.000Z</published>
    <updated>2017-06-27T03:51:47.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote class="blockquote-center"><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>经过了EDA，数据清洗，特征工程，终于可以聊聊建模型啦，本文简单介绍整个建模过程，最大限度提高性能，同时避免过拟合。</p>
</blockquote>
<a id="more"></a>
<h3 id="划分数据集"><a href="#划分数据集" class="headerlink" title="划分数据集"></a>划分数据集</h3><p><img src="/images/split_dataset.png" alt="split_dataset"></p>
<h3 id="超参数"><a href="#超参数" class="headerlink" title="超参数"></a>超参数</h3><p>调参，特指调超参，通常在机器学习中有两种类型的参数，其一，模型参数，如回归系数(regression coefficients)、决策树切分点，这些都是可以利用训练数据直接学习得到的；其二，超参，如随机森林中的树个数选择，L1，L2正则化选择等，这些参数是无法通过学习获得的，需要人为指定。</p>
<h3 id="拟合与调参"><a href="#拟合与调参" class="headerlink" title="拟合与调参"></a>拟合与调参</h3><p>通常的做法就是：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">for 每一算法(LR,RF,SVM,etc.):</div><div class="line">    for 每一组超参设置：</div><div class="line">        对训练集做交叉验证；</div><div class="line">        计算cross-validated分值</div></pre></td></tr></table></figure></p>
<p>这样就会得到，每一个算法，每一个超参集下的CV分值，然后：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">for 每一个算法：</div><div class="line">    CV值最大的超参集；</div><div class="line">    对整个训练集再次训练(不进行交叉验证)</div></pre></td></tr></table></figure></p>
<p>这就得到每个算法，一个代表性的训练结果。</p>
<h3 id="挑选最优模型"><a href="#挑选最优模型" class="headerlink" title="挑选最优模型"></a>挑选最优模型</h3><p>下面就需要依据评估指标，利用测试集（之前预留出的一部分训练集），挑选最优模型。<br>评估指标有很多，对回归问题，有均方误差(MSE)或均值绝对误差(MAE)。（值越低越好）；对分类问题，有AUC(值越高越好)，准确率，召回率等。</p>
<p>最后，再考虑你的模型，鲁棒性，一致性、可解释性如何~</p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote class=&quot;blockquote-center&quot;&gt;&lt;h3 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h3&gt;&lt;p&gt;经过了EDA，数据清洗，特征工程，终于可以聊聊建模型啦，本文简单介绍整个建模过程，最大限度提高性能，同时避免过拟合。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Machine Learning" scheme="http://phoebepan.cn/categories/Machine-Learning/"/>
    
    
      <category term="ML" scheme="http://phoebepan.cn/tags/ML/"/>
    
  </entry>
  
  <entry>
    <title>机器学习WorkFlow——Feature Engineering</title>
    <link href="http://phoebepan.cn/2017/04/28/feature_engineering/"/>
    <id>http://phoebepan.cn/2017/04/28/feature_engineering/</id>
    <published>2017-04-28T07:30:16.000Z</published>
    <updated>2017-07-08T11:39:26.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote class="blockquote-center"><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>特征工程，是机器学习过程中最富有想象空间的环节，你可以大胆开脑洞。业界广为流传的一句话：数据和特征决定机器学习上限，而模型和算法只是逼近这个上限而已。本文只是简单介绍特征工程打开思路的一般套路。</p>
</blockquote>
<a id="more"></a>
<p>提到特征工程，脑海中该有的框架，如下图所示：<br><img src="/images/feature.png" alt="feature_engineering"><br>具体特征工程做些什么，可参考这篇博文，查阅请点击<a href="http://www.cnblogs.com/jasonfreak/p/5448385.html" target="_blank" rel="external">这里</a>。<br><img src="/images/feature_engineering.jpg" alt="feature_engineering"></p>
<p>下面是目前自己在特征工程环节，经常考虑的几个方面：<br><img src="/images/feature_engineering_1.png" alt="feature_engineering"></p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote class=&quot;blockquote-center&quot;&gt;&lt;h3 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h3&gt;&lt;p&gt;特征工程，是机器学习过程中最富有想象空间的环节，你可以大胆开脑洞。业界广为流传的一句话：数据和特征决定机器学习上限，而模型和算法只是逼近这个上限而已。本文只是简单介绍特征工程打开思路的一般套路。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Machine Learning" scheme="http://phoebepan.cn/categories/Machine-Learning/"/>
    
    
      <category term="ML FeatureEngineering" scheme="http://phoebepan.cn/tags/ML-FeatureEngineering/"/>
    
  </entry>
  
  <entry>
    <title>机器学习WorkFlow——Data cleaning</title>
    <link href="http://phoebepan.cn/2017/04/27/data_clean/"/>
    <id>http://phoebepan.cn/2017/04/27/data_clean/</id>
    <published>2017-04-27T07:30:16.000Z</published>
    <updated>2017-06-27T02:00:05.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote class="blockquote-center"><p>Garbage in gets you garbage out.<br>Better data beats fancier algorithms.</p>
</blockquote>
<h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a><center>简介</center></h3><p>数据清洗是每个数据人的必备技能，诚然这不是机器学习最‘骨感’的地方，没有什么隐藏的技能值得来说，但这确是最耗时的环节。不同类型数据需要不同处理方式，本文是自己系统学习数据清洗的起点。</p>
<a id="more"></a>
<h3 id="删除不需观测的数据"><a href="#删除不需观测的数据" class="headerlink" title="删除不需观测的数据"></a>删除不需观测的数据</h3><p>第一步，从数据集中去除不需观测的数据，包括重复，或者不相关数据，所谓不相关，就是与当前解决的特定问题无关。</p>
<h3 id="结构错误"><a href="#结构错误" class="headerlink" title="结构错误"></a>结构错误</h3><p>结构错误，指在测量，数据传输或其他形式的内部管理中出现的错误。例如，数据格式，拼写错误，大小写不一致等等。</p>
<h3 id="异常值"><a href="#异常值" class="headerlink" title="异常值"></a>异常值</h3><p>识别连续变量异常值，通常可以用：</p>
<ul>
<li>箱形图</li>
<li>Z记分法（当变量符合正态分布，Z&gt;3通常标记为异常值）<br>有充分理由说明其是异常值，才可以将其删除，否则，尽量保留。</li>
</ul>
<h3 id="缺失值"><a href="#缺失值" class="headerlink" title="缺失值"></a>缺失值</h3><p>缺失值，在机器学习中是非常棘手的事情。最常规的2种套路，其一，当数据量很充足的时候，删除没太大影响，直接Dropping；其二，利用其它观测对象重新填补缺失，填补的方式有：</p>
<ul>
<li>特殊值填补（中位数、平均值）</li>
<li>聚类均值填补（找出有缺失值的观测所属的簇）</li>
</ul>
<p>最好的处理<strong>缺失类别数据</strong>的方式就是，直接归为<strong>缺失类</strong>。<br><strong>缺失数值型数据</strong>，要么填补它，要么flag它<strong>NaN</strong>，处理方式，还需要考虑你套用的算法，是否支持。</p>
<p>完成数据清洗步骤后，算是解决机器学习的一大麻烦啦~</p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote class=&quot;blockquote-center&quot;&gt;&lt;p&gt;Garbage in gets you garbage out.&lt;br&gt;Better data beats fancier algorithms.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;&lt;center&gt;简介&lt;/center&gt;&lt;/h3&gt;&lt;p&gt;数据清洗是每个数据人的必备技能，诚然这不是机器学习最‘骨感’的地方，没有什么隐藏的技能值得来说，但这确是最耗时的环节。不同类型数据需要不同处理方式，本文是自己系统学习数据清洗的起点。&lt;/p&gt;
    
    </summary>
    
      <category term="Machine Learning" scheme="http://phoebepan.cn/categories/Machine-Learning/"/>
    
    
      <category term="ML" scheme="http://phoebepan.cn/tags/ML/"/>
    
  </entry>
  
  <entry>
    <title>机器学习WorkFlow——EDA</title>
    <link href="http://phoebepan.cn/2017/04/26/ML_EDA/"/>
    <id>http://phoebepan.cn/2017/04/26/ML_EDA/</id>
    <published>2017-04-26T07:30:16.000Z</published>
    <updated>2017-06-09T00:02:52.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote class="blockquote-center"><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>机器学习想要获得很好的效果，就像做菜一样，离不开3个基本要素：好的厨师(human guidance)、干净的食材(clean, relevant data)、适量(avoid overfitting)。围绕这3要素，机器学习有下图5个核心步骤。本文先谈谈EDA过程。<br><img src="/images/machine_pipeline.JPG" alt="machine_pipeline"></p>
</blockquote>
<a id="more"></a>
<h3 id="Exploratory-Data-Analysis-EDA"><a href="#Exploratory-Data-Analysis-EDA" class="headerlink" title="Exploratory Data Analysis(EDA)"></a>Exploratory Data Analysis(EDA)</h3><p>探索性数据分析阶段，目的就是更好地了解你的数据，对你的数据有那么点 <strong>feel</strong>，这对下面的数据清洗、特征工程都是有帮助的。EDA对于ML来说，要<strong>快速，高效，决定性的</strong>。<br>这一步中，首先需要回答出这些问题：</p>
<ul>
<li>观测数据、特征有多少？</li>
<li>特征的数据类型？数值 or 类别？</li>
<li>是否有目标变量？</li>
<li>哪些列是有意义的？列中值是否有意义？值占比合适？</li>
<li>缺失值严重？</li>
</ul>
<h3 id="数值型特征分布"><a href="#数值型特征分布" class="headerlink" title="数值型特征分布"></a>数值型特征分布</h3><p><strong>直方图(histograms)</strong>就可以很好的观测出<strong>数值型features</strong>的分布。主要关注这几点：</p>
<ul>
<li>分布合理？</li>
<li>二值？</li>
<li>有潜在异常值？</li>
<li>有潜在测试误差？</li>
<li><p>边界合理？</p>
<p>如果发现数据有异常，可以咨询相关人士，从而更清楚的认识你的数据。</p>
</li>
</ul>
<h3 id="类别型特征分布"><a href="#类别型特征分布" class="headerlink" title="类别型特征分布"></a>类别型特征分布</h3><p><strong>条形图(Bar plot)</strong>可以有效观测<strong>类别features</strong>的分布。对于稀缺类别，后续可以考虑进行合并等等处理。</p>
<p><strong>盒图(Box plot)</strong>有效的观测<strong>类别feature</strong>与<strong>数值型feature</strong>之间的关系。</p>
<h3 id="协方差矩阵"><a href="#协方差矩阵" class="headerlink" title="协方差矩阵"></a>协方差矩阵</h3><p>数值型特征之间协方差矩阵，潜在的反应它们的关系。<strong>热图(heatmaps)</strong>可以很好的可视化，这样的相关性。在这你可以找出那些特征与目标变量相关性更强？强相关的特征有意义？</p>
<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>总之，EDA，能够让我们更好的了解数据集，给下面的数据清洗，特征工程提供思路。</p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote class=&quot;blockquote-center&quot;&gt;&lt;h3 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h3&gt;&lt;p&gt;机器学习想要获得很好的效果，就像做菜一样，离不开3个基本要素：好的厨师(human guidance)、干净的食材(clean, relevant data)、适量(avoid overfitting)。围绕这3要素，机器学习有下图5个核心步骤。本文先谈谈EDA过程。&lt;br&gt;&lt;img src=&quot;/images/machine_pipeline.JPG&quot; alt=&quot;machine_pipeline&quot;&gt;&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Machine Learning" scheme="http://phoebepan.cn/categories/Machine-Learning/"/>
    
    
      <category term="ML" scheme="http://phoebepan.cn/tags/ML/"/>
    
  </entry>
  
  <entry>
    <title>Python实现大文件分割</title>
    <link href="http://phoebepan.cn/2017/04/25/split_bigtxt/"/>
    <id>http://phoebepan.cn/2017/04/25/split_bigtxt/</id>
    <published>2017-04-25T07:30:16.000Z</published>
    <updated>2017-06-04T23:59:50.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote class="blockquote-center"><h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><p>最近处理数据，碰到有一个按行存储的文本文件，含有七百多万条数据，大小近7G，本地直接报出<code>MemoryError</code>，处理不了。</p>
<h3 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h3><p>用python写个脚本，将大文件拆分成小文件，对小文件进行处理，问题不就解决了么。</p>
</blockquote>
<a id="more"></a>
<h3 id="分割脚本"><a href="#分割脚本" class="headerlink" title="分割脚本"></a>分割脚本</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> os</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">split</span><span class="params">(fromfile,todir,chunksize=<span class="number">22</span>*<span class="number">10000</span>)</span>:</span></div><div class="line">	<span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(todir):<span class="comment">#check whether todir exists or not</span></div><div class="line">        os.mkdir(todir)</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        <span class="keyword">for</span> fname <span class="keyword">in</span> os.listdir(todir):</div><div class="line">            os.remove(os.path.join(todir,fname))</div><div class="line">    partnum = <span class="number">0</span></div><div class="line">    inputfile = open(fromfile,<span class="string">'rb'</span>)<span class="comment">#open the fromfile</span></div><div class="line">    <span class="keyword">while</span> <span class="keyword">True</span>:</div><div class="line">        partnum += <span class="number">1</span></div><div class="line">        filename = os.path.join(todir,(<span class="string">'part-%04d'</span> %partnum))</div><div class="line">        fileobj = open(filename,<span class="string">'wb'</span>)<span class="comment">#make partfile</span></div><div class="line">        linenum = <span class="number">0</span></div><div class="line">        <span class="keyword">while</span>( linenum&lt;= batchSize ):</div><div class="line">            read_content = inputfile.readline()</div><div class="line">            <span class="keyword">if</span>( read_content ):</div><div class="line">                fileobj.write(read_content)</div><div class="line">            <span class="keyword">else</span>:</div><div class="line">                <span class="keyword">break</span></div><div class="line">            linenum += <span class="number">1</span></div><div class="line">        fileobj.close()</div><div class="line">        <span class="keyword">if</span> (linenum &lt; batchSize): <span class="comment">#last part file</span></div><div class="line">            <span class="keyword">break</span></div><div class="line">    <span class="keyword">return</span> partnum</div></pre></td></tr></table></figure>
<p>上面的脚本，就能够就将大文件，分割成小文件，且每个小文件含有220001行记录，大小约为178M，在todir目录看到分割后的文件如下：<br><img src="/images/partfile.png" alt="partfile" title="分割后部分文件"></p>
<p>欢迎大神，推荐更棒的方法！</p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote class=&quot;blockquote-center&quot;&gt;&lt;h3 id=&quot;问题&quot;&gt;&lt;a href=&quot;#问题&quot; class=&quot;headerlink&quot; title=&quot;问题&quot;&gt;&lt;/a&gt;问题&lt;/h3&gt;&lt;p&gt;最近处理数据，碰到有一个按行存储的文本文件，含有七百多万条数据，大小近7G，本地直接报出&lt;code&gt;MemoryError&lt;/code&gt;，处理不了。&lt;/p&gt;
&lt;h3 id=&quot;解决方法&quot;&gt;&lt;a href=&quot;#解决方法&quot; class=&quot;headerlink&quot; title=&quot;解决方法&quot;&gt;&lt;/a&gt;解决方法&lt;/h3&gt;&lt;p&gt;用python写个脚本，将大文件拆分成小文件，对小文件进行处理，问题不就解决了么。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Python" scheme="http://phoebepan.cn/categories/Python/"/>
    
    
      <category term="Python" scheme="http://phoebepan.cn/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>魔力Python——pickle持久化对象</title>
    <link href="http://phoebepan.cn/2017/04/22/pickle/"/>
    <id>http://phoebepan.cn/2017/04/22/pickle/</id>
    <published>2017-04-22T07:30:16.000Z</published>
    <updated>2017-06-02T23:53:42.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote class="blockquote-center"><p><center><strong>简介</strong></center><br>本文主要介绍Python pickle模块的用法，实例分析<code>pickle</code>模块的功能与相关适用技巧。<code>pickle</code>提供了一个简单的<strong>持久化</strong>功能，可以将对象以文件的形式存放在磁盘上，方便多次读取与共享。</p>
</blockquote>
<a id="more"></a>
<h3 id="具体用法"><a href="#具体用法" class="headerlink" title="具体用法"></a>具体用法</h3><h4 id="pickle-dump-obj-file-protocol"><a href="#pickle-dump-obj-file-protocol" class="headerlink" title="pickle.dump(obj,file[,protocol])"></a>pickle.dump(obj,file[,protocol])</h4><p>这条语句序列化对象obj，并将结果数据流写入到文件file中。可选参数protocol是序列化模式，默认为0，表示以文本形式序列化，如果设置为 1 或 True，则以高压缩的二进制格式保存序列化后的对象，否则以ASCII格式保存。</p>
<h4 id="pickle-load-file"><a href="#pickle-load-file" class="headerlink" title="pickle.load(file)"></a>pickle.load(file)</h4><p>反序列化对象，将文件中的数据解析为一个python对象。</p>
<h3 id="基本用例"><a href="#基本用例" class="headerlink" title="基本用例"></a>基本用例</h3><p>下面这段代码，实现将4维矩阵obj对象持久化：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> pickle</div><div class="line"><span class="keyword">import</span> os</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">if</span> os.path.exists(<span class="string">'./test.pkl'</span>):    <span class="comment">#当前路径下是否已经存在序列化的test.pkl</span></div><div class="line">    obj=pickle.load(open(<span class="string">'./test.pkl'</span>,<span class="string">'rb'</span>))    <span class="comment">#如果已经存在直接load</span></div><div class="line"><span class="keyword">else</span>:   <span class="comment">#否则，将4维矩阵序列化到存储到当前路径下的test.pkl中</span></div><div class="line">    obj = np.ones((<span class="number">4</span>,<span class="number">4</span>))    </div><div class="line">    pickle.dump(obj,open(<span class="string">'./test.pkl'</span>,<span class="string">'wb'</span>))</div><div class="line">print(obj)</div></pre></td></tr></table></figure></p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote class=&quot;blockquote-center&quot;&gt;&lt;p&gt;&lt;center&gt;&lt;strong&gt;简介&lt;/strong&gt;&lt;/center&gt;&lt;br&gt;本文主要介绍Python pickle模块的用法，实例分析&lt;code&gt;pickle&lt;/code&gt;模块的功能与相关适用技巧。&lt;code&gt;pickle&lt;/code&gt;提供了一个简单的&lt;strong&gt;持久化&lt;/strong&gt;功能，可以将对象以文件的形式存放在磁盘上，方便多次读取与共享。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Python" scheme="http://phoebepan.cn/categories/Python/"/>
    
    
      <category term="Python" scheme="http://phoebepan.cn/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>初涉MapReduce</title>
    <link href="http://phoebepan.cn/2017/04/21/MapReduce/"/>
    <id>http://phoebepan.cn/2017/04/21/MapReduce/</id>
    <published>2017-04-21T07:30:16.000Z</published>
    <updated>2017-05-31T23:45:18.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote class="blockquote-center"><p>了解一件事是什么，可以帮助了解它不是什么。</p>
</blockquote>
<a id="more"></a>
<h3 id="产生根源"><a href="#产生根源" class="headerlink" title="产生根源"></a><center>产生根源</center></h3><p>解决大数据分布式存储、运算容错性问题。</p>
<h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a><center>原理</center></h3><p>MapReduce是一种算法和框架。Hadoop是MapReduce的开源实现。使用MapReduce需要两个函数，一个<strong>mapper函数</strong>，一个<strong>reducer函数</strong>，mapper函数将每个数据点作为输入，按排序输出形如（键，值）这样的二元组列表，然后框架会使用定向冒泡排序对输出排序，如果键相同，合并两个二元组。这些二元组会被送往执行reducer函数的机器，reducer函数使用聚合函数对值进行聚合，得到新的值，输出新的（键，新值）列表。</p>
<p><img src="/images/mapreduce.png" alt="示例图" title="抽象原理图"></p>
<h3 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a><center>适用场景</center></h3><p>能用MapReduce解决的问题有一个重要特征：数据可以被分布存储到各个计算机上，且算法可以在每台计算机上独立处理数据，即每台计算机之间是相互隔离的，他们不需要知道其他机器在处理什么。MapReduce<strong>不适合迭代式的算法</strong>，所谓迭代式算法就是，上一次的输出作为下一次的输入，这样的算法。</p>
<p><a href="http://blog.jobbole.com/1321/" target="_blank" rel="external">加深理解，请看这篇博文！</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote class=&quot;blockquote-center&quot;&gt;&lt;p&gt;了解一件事是什么，可以帮助了解它不是什么。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Architecture" scheme="http://phoebepan.cn/categories/Architecture/"/>
    
    
      <category term="MapReduce" scheme="http://phoebepan.cn/tags/MapReduce/"/>
    
  </entry>
  
  <entry>
    <title>并行化——multiprocessing</title>
    <link href="http://phoebepan.cn/2017/04/19/multiprocessing/"/>
    <id>http://phoebepan.cn/2017/04/19/multiprocessing/</id>
    <published>2017-04-19T07:30:16.000Z</published>
    <updated>2017-06-02T00:20:55.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote class="blockquote-center"><p><code>multiprocessing</code>是Python的标准模块，它既可以用来编写多进程，也可以用来编写多线程。<code>multiprocessing.dummy</code>实现多线程，<code>multiprocessing</code>实现多进程，本文主要介绍多进程的用法。</p>
</blockquote>
<a id="more"></a>
<h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a><center>问题</center></h3><p>最近在处理疾病数据时，遇到这样一个问题，需要计算同构的2000个文档加和平均值，为提高处理效率，使用<code>multiprocessing</code>库进行并行化，在此记录下。</p>
<h3 id="用法"><a href="#用法" class="headerlink" title="用法"></a><center>用法</center></h3><p><code>multiprocessing.pool</code>能自动管理进程任务，通过下面的语句初始化有10个进程数的pool，若<code>Pool()</code>未指定进程数，那么使用os.cpu_count()返回的数量。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> Pool</div><div class="line">processNum = <span class="number">10</span></div><div class="line">p = Pool(processNum)</div></pre></td></tr></table></figure></p>
<p>假定我们需要并行执行的任务是如下函数：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">func</span><span class="params">(parameter)</span>:</span></div><div class="line">    <span class="comment"># do something</span></div><div class="line">    <span class="keyword">return</span> result</div></pre></td></tr></table></figure></p>
<p>主函数调用：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">results = []</div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(processNum):</div><div class="line">    result = p.apply_async(func, args=(i,))</div><div class="line">    results.append(result)</div></pre></td></tr></table></figure></p>
<p><code>p.apply_async</code>采用异步方式调用函数func，<code>p.apply</code>采用同步方式调用，即串行方式，下一个func要等待上一个func运行完成才开始运行。针对我的问题，只需要异步操作即可。<br>最后，使用以下语句回收进程池：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">p.close()</div><div class="line">p.join()</div></pre></td></tr></table></figure></p>
<h3 id="附上完成使用代码"><a href="#附上完成使用代码" class="headerlink" title="附上完成使用代码"></a>附上完成使用代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> Pool</div><div class="line">processNum = <span class="number">10</span></div><div class="line">p = Pool(processNum)</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">func</span><span class="params">(parameter)</span>:</span></div><div class="line">    <span class="comment"># do something</span></div><div class="line">    <span class="keyword">return</span> result</div><div class="line">results = []</div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(processNum):</div><div class="line">    result = p.apply_async(func, args=(i,))</div><div class="line">    results.append(result)</div><div class="line">p.close()</div><div class="line">p.join()</div></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote class=&quot;blockquote-center&quot;&gt;&lt;p&gt;&lt;code&gt;multiprocessing&lt;/code&gt;是Python的标准模块，它既可以用来编写多进程，也可以用来编写多线程。&lt;code&gt;multiprocessing.dummy&lt;/code&gt;实现多线程，&lt;code&gt;multiprocessing&lt;/code&gt;实现多进程，本文主要介绍多进程的用法。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Python" scheme="http://phoebepan.cn/categories/Python/"/>
    
    
      <category term="Python" scheme="http://phoebepan.cn/tags/Python/"/>
    
      <category term="Parallelization" scheme="http://phoebepan.cn/tags/Parallelization/"/>
    
  </entry>
  
  <entry>
    <title>Linux——后台运行、查看和关闭</title>
    <link href="http://phoebepan.cn/2017/04/17/linux_backstage/"/>
    <id>http://phoebepan.cn/2017/04/17/linux_backstage/</id>
    <published>2017-04-17T07:30:16.000Z</published>
    <updated>2017-05-29T04:57:34.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote class="blockquote-center"><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>用Xshell/ssh登录了Linux服务器，运行一些耗时长的程序，结果不小心断网了，白白花了时间却没出结果。如何让命令提交不受本地关闭终端、断网等干扰呢？</p>
</blockquote>
<blockquote class="blockquote-center"><h2 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h2><p>让进程在后台运行，相关命令：<code>&amp;、nohup、jobs、fg、ctrl+z、bg、ctrl+c、kill</code></p>
</blockquote>
<a id="more"></a>
<h3 id="amp"><a href="#amp" class="headerlink" title="&amp;"></a>&amp;</h3><p>命令末尾加上&amp;，相当于把这条命令放在后台执行，如：<code>python3.4 test.py &amp;</code></p>
<h3 id="nohup"><a href="#nohup" class="headerlink" title="nohup"></a>nohup</h3><p>若想要终端关闭，程序依旧执行，nohup无疑是首选方式，用法：<code>nohup &lt;command&gt; &amp;</code></p>
<h3 id="jobs"><a href="#jobs" class="headerlink" title="jobs"></a>jobs</h3><p>查看当前在后台运行的命令状态，<code>jobs -l</code>可显示所有任务得PID</p>
<h3 id="fg"><a href="#fg" class="headerlink" title="fg"></a>fg</h3><p>后台命令调入前台运行。用法：<code>fg %jobnumber</code>（jobnumber通过<code>jobs</code>命令查看）</p>
<h3 id="ctrl-z"><a href="#ctrl-z" class="headerlink" title="ctrl+z"></a>ctrl+z</h3><p>可以将一个正在前台运行的命令放入后台，并处于暂停状态</p>
<h3 id="bg"><a href="#bg" class="headerlink" title="bg"></a>bg</h3><p>后台暂停的命令，变成在后台继续执行，用法：<code>bg %jobnumber</code></p>
<h3 id="ctrl-c"><a href="#ctrl-c" class="headerlink" title="ctrl+c"></a>ctrl+c</h3><p>前台终止进程</p>
<h3 id="kill"><a href="#kill" class="headerlink" title="kill"></a>kill</h3><p>终止后台进程继续运行，</p>
<ul>
<li>通过job号，执行：<code>kill %jobnumber</code></li>
<li><code>ps xw</code>查看进程号(PID)，执行：<code>kill PID</code></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote class=&quot;blockquote-center&quot;&gt;&lt;h2 id=&quot;问题&quot;&gt;&lt;a href=&quot;#问题&quot; class=&quot;headerlink&quot; title=&quot;问题&quot;&gt;&lt;/a&gt;问题&lt;/h2&gt;&lt;p&gt;用Xshell/ssh登录了Linux服务器，运行一些耗时长的程序，结果不小心断网了，白白花了时间却没出结果。如何让命令提交不受本地关闭终端、断网等干扰呢？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote class=&quot;blockquote-center&quot;&gt;&lt;h2 id=&quot;解决方法&quot;&gt;&lt;a href=&quot;#解决方法&quot; class=&quot;headerlink&quot; title=&quot;解决方法&quot;&gt;&lt;/a&gt;解决方法&lt;/h2&gt;&lt;p&gt;让进程在后台运行，相关命令：&lt;code&gt;&amp;amp;、nohup、jobs、fg、ctrl+z、bg、ctrl+c、kill&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Daily Accumulation" scheme="http://phoebepan.cn/categories/Daily-Accumulation/"/>
    
    
      <category term="linux" scheme="http://phoebepan.cn/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>《新商业文明》摘录</title>
    <link href="http://phoebepan.cn/2017/04/16/New%20Commercial%20civilization/"/>
    <id>http://phoebepan.cn/2017/04/16/New Commercial civilization/</id>
    <published>2017-04-16T07:30:16.000Z</published>
    <updated>2017-05-29T05:05:36.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote class="blockquote-center"><h3 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a><center>作者简介</center></h3><p>乌麦尔·哈克，全球领先的管理思想家，被Thinkers 50评为全球最具影响力的管理学家之一。在《哈佛商业评论》的博客上发表多篇文章，主要关注领域为经济、领导力、创新等。</p>
<h3 id="本书核心"><a href="#本书核心" class="headerlink" title="本书核心"></a><center>本书核心</center></h3><p>《新商业文明：从利润到价值》，这本书勾画了一幅未来商业的蓝图，在这样的商业图景下，企业被顾客所爱戴，被竞争者所羡慕，被所有关心我们这个星球未来的人们所尊重。旧商业文明关注利润和股东利益最大化，新商业文明格局下企业更关注与社会、顾客、员工、环境的关系。企业为追求发展，以牺牲环境、社会、大众、后代利益为代价，获得高额利润的同时，却忽略了商业精神的实质。作者本书中提到，商业精神的内涵是企业应该掌握“建设型优势”，即关注真实的价值创造而非仅仅关注股东利益，这要求企业做到几个转变：从价值链到价值循环，从价值主张到价值对话，从战略到哲学，从市场保护到市场完善，从产品到幸福，从盲目增长到智慧增长。基于建设型优势，企业将成为有责任、有担当、有领导力的组织，而一种具备更长远、更开放视角的新商业文明也将形成。</p>
</blockquote>
<a id="more"></a>
<h3 id="脉络"><a href="#脉络" class="headerlink" title="脉络"></a><center>脉络</center></h3><p><img src="/images/New Commercial civilization.jpg" width="150%" height="70%" align="center/"></p>
<h3 id="对比"><a href="#对比" class="headerlink" title="对比"></a><center>对比</center></h3><table>
<thead>
<tr>
<th style="text-align:left">比较竞争优势来源</th>
<th style="text-align:center">建设型优势来源</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><strong>成本优势：</strong>来自攫取资源的价值链，直至资源耗尽</td>
<td style="text-align:center"><strong>损耗优势：</strong>来自可以使资源再生、废物得到利用的循环价值体系</td>
</tr>
<tr>
<td style="text-align:left"><strong>品牌：</strong>传达单方价值主张所带来的利益</td>
<td style="text-align:center"><strong>响应性：</strong>流动的、不间断的、多方面价值对话</td>
</tr>
<tr>
<td style="text-align:left"><strong>市场主导：</strong>通过战略魔化阻止竞争发生的零和游戏</td>
<td style="text-align:center">弹性：通过持久运营哲学在竞争中逐渐产生的优势</td>
</tr>
<tr>
<td style="text-align:left"><strong>束缚：</strong>当公司为防止竞争者进入市场进行自我保护时，对客户、供应商和监管者将加以控制</td>
<td style="text-align:center"><strong>创造力：</strong>当公司努力完善市场时，会创造新的竞争舞台，从而产生创造力</td>
</tr>
<tr>
<td style="text-align:left"><strong>差异化：</strong>对几乎相似的物品所呈现的特征进行表面的（甚至是想象当中的）细分</td>
<td style="text-align:center"><strong>意义：</strong>当公司寻找有意义的回报时将看到差异；当公司真正开始生产对人类有意义的产品时，就已经在创造差异</td>
</tr>
</tbody>
</table>
<h3 id="笔记"><a href="#笔记" class="headerlink" title="笔记"></a><center>笔记</center></h3><ul>
<li>取势、明道、优术</li>
<li>方舟上的经济繁荣取决于最大限度的降低伤害，因为你所攫取的所有利益、转嫁的所有伤害都会造成永久的、可能无法扭转的损失，最终造成一连串无法预知的恶果。</li>
<li>这就是全球经济今天所处的困境。我们现在正在使用狩猎时期的规则来管理这艘方舟，这种经济发展的方法已经过期了。</li>
<li>菲茨帕特里克最重要的一条经验是：在别人挑战你并开始行动之前，突破自己。</li>
<li>每种类型的进步都需要选择。生物学家谈的是自然选择，经济学家谈的是社会选择。经济进步需要竞争性选择，顾客、买方、供货方都必须能自由、公平地在一家公司和他的竞争对手之间做选择。自由、公平的交换是进步的根基，因为这推动了竞争性选择。</li>
<li>这就是我的看法：过去商业社会已经触及了幸福的天花板——从长远来看，其基本理念所能产生的幸福感以及幸福人群的数量都遭遇了瓶颈。最能带来收益的厚价值，也是真正的价值所在——从人性角度出发，对公众、社区、社会有益——反映的是长久的、可见的幸福。</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote class=&quot;blockquote-center&quot;&gt;&lt;h3 id=&quot;作者简介&quot;&gt;&lt;a href=&quot;#作者简介&quot; class=&quot;headerlink&quot; title=&quot;作者简介&quot;&gt;&lt;/a&gt;&lt;center&gt;作者简介&lt;/center&gt;&lt;/h3&gt;&lt;p&gt;乌麦尔·哈克，全球领先的管理思想家，被Thinkers 50评为全球最具影响力的管理学家之一。在《哈佛商业评论》的博客上发表多篇文章，主要关注领域为经济、领导力、创新等。&lt;/p&gt;
&lt;h3 id=&quot;本书核心&quot;&gt;&lt;a href=&quot;#本书核心&quot; class=&quot;headerlink&quot; title=&quot;本书核心&quot;&gt;&lt;/a&gt;&lt;center&gt;本书核心&lt;/center&gt;&lt;/h3&gt;&lt;p&gt;《新商业文明：从利润到价值》，这本书勾画了一幅未来商业的蓝图，在这样的商业图景下，企业被顾客所爱戴，被竞争者所羡慕，被所有关心我们这个星球未来的人们所尊重。旧商业文明关注利润和股东利益最大化，新商业文明格局下企业更关注与社会、顾客、员工、环境的关系。企业为追求发展，以牺牲环境、社会、大众、后代利益为代价，获得高额利润的同时，却忽略了商业精神的实质。作者本书中提到，商业精神的内涵是企业应该掌握“建设型优势”，即关注真实的价值创造而非仅仅关注股东利益，这要求企业做到几个转变：从价值链到价值循环，从价值主张到价值对话，从战略到哲学，从市场保护到市场完善，从产品到幸福，从盲目增长到智慧增长。基于建设型优势，企业将成为有责任、有担当、有领导力的组织，而一种具备更长远、更开放视角的新商业文明也将形成。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Reading Nodes" scheme="http://phoebepan.cn/categories/Reading-Nodes/"/>
    
    
      <category term="Reading" scheme="http://phoebepan.cn/tags/Reading/"/>
    
      <category term="Thinking" scheme="http://phoebepan.cn/tags/Thinking/"/>
    
  </entry>
  
  <entry>
    <title>Dynamic programming</title>
    <link href="http://phoebepan.cn/2017/04/13/Dynamic%20programming/"/>
    <id>http://phoebepan.cn/2017/04/13/Dynamic programming/</id>
    <published>2017-04-13T07:30:16.000Z</published>
    <updated>2017-05-29T05:01:51.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote class="blockquote-center"><h3 id="基本思想"><a href="#基本思想" class="headerlink" title="基本思想"></a>基本思想</h3><p>动态规划（Dynamic programming，DP），通过把原问题分解为相对简单的子问题的方式分解复杂问题的方法。</p>
</blockquote>
<a id="more"></a>
<h3 id="使用的情况"><a href="#使用的情况" class="headerlink" title="使用的情况"></a>使用的情况</h3><p>能采用动态规划求解的问题一般具有3个性质：</p>
<ul>
<li>最优化原理：如果问题的最优解所包含的子问题的解也是最优的，就称该问题具有最优子结构；</li>
<li>无后效性：某状态以后的过程不会影响以前的状态，只与当前状态有关；</li>
<li>有重叠子问题：子问题之间不独立，一个字问题在下一阶段中可能被多次使用。（这一性质是动态规划与其他算法相比所具备的优势）</li>
</ul>
<h3 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h3><p>LeetCode: <a href="https://leetcode.com/problems/wildcard-matching/#/description" target="_blank" rel="external">Wildcard Matching</a><br>这道题其实就是Regular Expression Matching的简化版，下面主要说一下动态规划的解法。<br>输入两个字符串s,p，用一个布尔数组dp，dp[n]值表示字符串s前n个字符是否符合模式p。这就将原问题拆分成很多子问题，要想知道s是否匹配p，只需要知道之前匹配结果及当前位匹配情况就可以ok了。<br>具体代码如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">isMatch</span><span class="params">(self, s, p)</span>:</span></div><div class="line">        <span class="string">"""</span></div><div class="line">        :type s: str</div><div class="line">        :type p: str</div><div class="line">        :rtype: bool</div><div class="line">        """</div><div class="line">        length = len(s)</div><div class="line">        <span class="keyword">if</span> len(p)-p.count(<span class="string">'*'</span>) &gt; length:</div><div class="line">            <span class="keyword">return</span> <span class="keyword">False</span></div><div class="line">        dp = [<span class="keyword">True</span>]+[<span class="keyword">False</span>]*length</div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> p:</div><div class="line">            <span class="keyword">if</span> i != <span class="string">'*'</span>:</div><div class="line">                <span class="keyword">for</span> n <span class="keyword">in</span> reversed(range(length)):</div><div class="line">                    dp[n+<span class="number">1</span>]=dp[n] <span class="keyword">and</span> (i==s[n] <span class="keyword">or</span> i == <span class="string">'?'</span>)</div><div class="line">            <span class="keyword">else</span>:</div><div class="line">                <span class="keyword">for</span> n <span class="keyword">in</span> range(<span class="number">1</span>,length+<span class="number">1</span>):</div><div class="line">                    dp[n]=dp[n<span class="number">-1</span>] <span class="keyword">or</span> dp[n]</div><div class="line">            dp[<span class="number">0</span>]=dp[<span class="number">0</span>] <span class="keyword">and</span> i==<span class="string">'*'</span></div><div class="line">        <span class="keyword">return</span> dp[<span class="number">-1</span>]</div><div class="line"><span class="comment">#test</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>isMatch(<span class="string">'aa'</span>,<span class="string">'*'</span>)</div><div class="line"><span class="keyword">True</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>isMatch(<span class="string">"ab"</span>, <span class="string">"?*"</span>)</div><div class="line"><span class="keyword">True</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>isMatch(<span class="string">"aab"</span>, <span class="string">"c*a*b"</span>)</div><div class="line"><span class="keyword">False</span></div></pre></td></tr></table></figure></p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote class=&quot;blockquote-center&quot;&gt;&lt;h3 id=&quot;基本思想&quot;&gt;&lt;a href=&quot;#基本思想&quot; class=&quot;headerlink&quot; title=&quot;基本思想&quot;&gt;&lt;/a&gt;基本思想&lt;/h3&gt;&lt;p&gt;动态规划（Dynamic programming，DP），通过把原问题分解为相对简单的子问题的方式分解复杂问题的方法。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Algorithms" scheme="http://phoebepan.cn/categories/Algorithms/"/>
    
    
      <category term="LeetCode" scheme="http://phoebepan.cn/tags/LeetCode/"/>
    
      <category term="Algorithms" scheme="http://phoebepan.cn/tags/Algorithms/"/>
    
  </entry>
  
  <entry>
    <title>读《好好学习》</title>
    <link href="http://phoebepan.cn/2017/04/09/goodstudy/"/>
    <id>http://phoebepan.cn/2017/04/09/goodstudy/</id>
    <published>2017-04-09T07:30:16.000Z</published>
    <updated>2017-05-29T05:04:31.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote class="blockquote-center"><p>简介：被罗辑思维评为十位“全国最会学习的人之一”，“得到”最受欢迎的说书人成甲，为你解开学习迷思，讲授“学习的方法”，帮助你将零碎的知识体系打造为高效的知识管理体系，让所学知识真正变成你的资产，让学习成为你财富积累的过程！</p>
</blockquote>
<a id="more"></a>
<p>知识和知识是不一样的，有些知识比其他知识的威力更大。少数的知识能够给我们带来关键的影响，这就是临界知识。</p>
<blockquote>
<p><strong>我</strong>    这是作者给出的临界知识的定义，通读全书，我觉得所谓临界知识，更接近一般的底层规律，从小学到大学，我们不断地在学习知识，信息爆炸的互联网时代，知识的数量更大，知识的获取更便捷，而人的时间精力是有限的，如何将知识内化，提升认知效率，加强个人知识深度那真可谓是“磨刀石”，就自身而言，maybe我也入了“低水平勤奋陷阱”，看似不断学习，但大多数只是停留在知道层面，没有内化为自己的能力，二八原理有说，20%的知识比80%的知识要有用，这20%的关键知识就是撬动效能的杠杆点，我们要做的是花80%的时间，用在这20%的关键问题上，而不是平均地把时间花在各种知识上。</p>
</blockquote>
<p>我们所谓的专业，比如市场营销、法律、政治、历史、文学，其实只是人为制造的分类标签罢了，但是，这个世界不是按照你划分的标签在各个专业之内单独运行的。一个市场营销的问题，背后往往涉及法律、政治、历史和文化的因素。可是我们所谓的专业，并不管这些：你学好4P（产品、价格、渠道、促销）、市场细分等概念，就可以毕业了。这种认识，会极大地阻碍我们学习真正应该学的知识。</p>
<blockquote>
<p><strong>我</strong>    对于专业的解说，很符合自己的反思过程，以前自己读书总是读文学名著，专业书籍，至于其他领域，基本不会深入阅读，也许可归因于曾经浮躁的状态，想了解更多，但又觉得无用，受制于自己给贴的标签。但渐渐的我发现，很多时候，知识是相通的，想要在某一方面做到极致，不是说只学习某个专业知识就够了，也不是简单地这也学学，那也学学，而是要学习与解决某一类问题相关的所有核心能力。这一点，一定是突破专业限制的。</p>
</blockquote>
<p>生命有限，不要把有限的生命浪费在那些“低水平勤奋陷阱”里。现在的我，在读书时既不追求数量，也不要求读完。我的做法是：当我要解决某个问题的时候，主动去寻找可能会讨论这个问题的文章和书籍，去观察——作者用什么样的思路解决这个问题？在解决方案背后，是否有我熟悉的知识？我还能把这个解决方案的原理应用在什么领域？</p>
<blockquote>
<p><strong>我</strong>    这点挺启发我的，我拿起一本书要看的时候，总是，从前言，目录一直到结尾，生怕落下什么重要的细节，而且我总想尽快读完，然后去读更多的书，但maybe这真的是低效的表现，读书不在于多少，而在于有没有通过读书重新认识这个世界，发现深度知识并把它运用到自己的生活当中，举一反三，学习这样的检视阅读，把书当做自己的一个私人顾问，让自己以后能更高效解决问题。</p>
</blockquote>
<p>区分“我”和“我的观点/行为”，不再把对自己观点的质疑与自己这个人绑定起来。乔布斯在生前说过一句很著名的话：“我特别喜欢和聪明人在一起工作，因为最大的好处是不用考虑他们的尊严”</p>
<blockquote>
<p><strong>我</strong>    深有感触，以前实习的时候，两个老师之间意见不一致，其中一个的威信明显受到挑衅，当时就很困惑，难道老师不担心自己丢面子？不害怕没有尊严？其实不是，聪明人他们知道尊严不是在别人驳倒自己时去维护面子，真正的尊严是发现改进和成长的机会，成为更好的自己，这才是真正的老司机啊，哈哈。</p>
</blockquote>
<p>学习临界知识其实也就是用更合理的假设来替代我们过去不合理的假设，从而让我们的决策质量更高。<br>做事的顺序：做出假设——&gt;采取行动——&gt;产生结果<br>反思的顺序：观察结果（现象）——&gt;研究原先假设——&gt;反思校正假设</p>
<blockquote>
<p><strong>我</strong>    学习的本质，就是改变我们假设的过程，这讲清楚了学习的目的，因为，我们做出的所有决策都是在自己的假设下做出的，如果自己的假设不正确，不合适，那么必然产生不好的结果，所以学习，能够帮助我们更好的应对这个变化的世界。</p>
</blockquote>
<p>而我个人也是从事广告的6年间每天保持着阅读10个以上广告案例的习惯。正是这些背后看不见的可以练习，才铸就了今天小马宋举重若轻的广告能力。</p>
<blockquote>
<p><strong>我</strong>    真的没有谁，是随随便便成功的，台上十分钟，台下十年功，保持足够的好奇，寻找自己的热情所在，戒骄戒躁，在如今尤为重要，想想自己浪费的一年多生活，有些惋惜，但浪子回头，什么时候都不会晚，我坚信可以变成更好的自己。</p>
</blockquote>
<p>复利的本质？做事情A会导致结果B，而结果B又会加强A，不断循环。生活中，凡是符合这一规律的事情，都可以视为复利效应。比如，网站的访问量越多，在搜索引擎的排名就越靠前，那么网站访问量就越多。</p>
<blockquote>
<p><strong>我</strong>    复利，这个概念来源自我们小学就接触到的利息模型。近年来，读书无用论盛行，家长们会说，孩子学习这些数学有什么用，生活中也用不到，你看，这个复利，我们简单的停留在求出利息的层面，那它的用途的确有限，但是如果把它抽象出来，结合二八原理，书中提到我们想要向前20%靠近的话，就要充分利用复利效应，而这就需要我们做到：首先，我们要在生活中发现“A导致B，B加强A”这样的事情；其次，我们要尽可能地提高这件事情的利率；最后，我们要加强这件事情重复发生的可能性。</p>
</blockquote>
<p>所以拓展人脉的关键，首先是不断地提升自己的价值，让自己变得对他人有帮助；其次，才是让别人知道自己的价值。</p>
<blockquote>
<p><strong>我</strong>    来沪也快两年了，参加过一些活动，认识了一些朋友，虽然有些只是一面之交，但真的特别感谢每次的相遇，让我的眼界更加开阔。印象比较深的是，有一次参加一个英语角活动，活动后我们几个年龄相仿的，聊得特别嗨，一眨眼二三个小时过去了，但仍然意犹未尽，互加了微信，回去过后，有一个程序员哥哥，每次看到可能对我有帮助的，都会分享给我，我这个人么，属于能不麻烦别人就不麻烦别人的，但渐渐我发现，朋友其实就是在这样互相帮助下，联系的越紧密的，现在的我特别喜欢，有事就联系，没事各忙各的这样的相处方式。</p>
</blockquote>
<p>我不是说老司机的经验没有价值。我是说，你要意识到老司机的经验，只是众多可能性中的一个可能性，千万不能把它当成真理。它只是这个世界各种概率下的一个，甚至可能是小概率下的那一个。</p>
<blockquote>
<p><strong>我</strong>    这里讲的就是概率模型，这也是为什么我讨厌别人给我灌鸡汤，跟我讲大道理的原因，我始终都认为，一个人的成功，天时地利人和，缺一不可，老司机的经验，并不能保证在你所处的场景下也发生，只能规避你的风险，这也是我看好罗胖的内容创业，但是不会成为得到的深度用户。</p>
</blockquote>
<p>“与鬼共舞”其大意是说一个物种在适应过去的环境时，会形成一种行为A；当环境发生变化不需要行为A了，可物种仍然会延续过去的做法，就像与鬼魂共舞一样。</p>
<blockquote>
<p><strong>我</strong>    书里面提到的例子说，父母让女儿远离一线城市高房价，高压力的生活，回到自己的家乡县城，做稳定的银行柜员。我一直都坚信，没有所谓的稳定，环境在不断的变化，但是如果我们行动跟不上这样的变化，就会在新环境中“与鬼共舞”。我呢，天生爱自由，喜欢变化的世界，厌倦一层不变，这也是我渴望进入互联网这个行业的原因。</p>
</blockquote>
<p>夫夷以近，则游者众；险以远，则至者少。让我们一起好好学习，成为更好的自己~~</p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote class=&quot;blockquote-center&quot;&gt;&lt;p&gt;简介：被罗辑思维评为十位“全国最会学习的人之一”，“得到”最受欢迎的说书人成甲，为你解开学习迷思，讲授“学习的方法”，帮助你将零碎的知识体系打造为高效的知识管理体系，让所学知识真正变成你的资产，让学习成为你财富积累的过程！&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Thinking" scheme="http://phoebepan.cn/categories/Thinking/"/>
    
    
      <category term="Reading" scheme="http://phoebepan.cn/tags/Reading/"/>
    
      <category term="Thinking" scheme="http://phoebepan.cn/tags/Thinking/"/>
    
  </entry>
  
</feed>
