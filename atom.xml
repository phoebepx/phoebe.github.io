<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>技忆</title>
  <subtitle>Phoebe&#39;s little progress</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://www.phoebepan.cn/"/>
  <updated>2017-08-13T07:58:45.000Z</updated>
  <id>http://www.phoebepan.cn/</id>
  
  <author>
    <name>Phoebe</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>定向广告到实时竞价广告</title>
    <link href="http://www.phoebepan.cn/2017/08/03/rtb/"/>
    <id>http://www.phoebepan.cn/2017/08/03/rtb/</id>
    <published>2017-08-03T07:30:16.000Z</published>
    <updated>2017-08-13T07:58:45.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote class="blockquote-center"><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>相比较于搜索广告，凡是浏览者没有主动输入搜索词的场景里面的广告，都可以叫做“非搜索广告”，即情景广告。本篇笔记包含非搜索广告的几种场景，以及针对定向广告的痛点发展而来的实时竞价广告。</p>
</blockquote>
<a id="more"></a>
<h3 id="定向广告"><a href="#定向广告" class="headerlink" title="定向广告"></a>定向广告</h3><p><img src="/images/dingxiangad.png" alt="dingxiangad"></p>
<p><strong>痛点：</strong>定向广告下，广告主的广告无法找到与其最相匹配的流量进行投放，大量媒体流量也无法找到最能实现其真实价值的广告和广告主，互联网的流量资源得不到合理和有效的配置。</p>
<h3 id="实时广告竞价-RTB"><a href="#实时广告竞价-RTB" class="headerlink" title="实时广告竞价(RTB)"></a>实时广告竞价(RTB)</h3><p>核心：建立一种流量交换的协议，使得媒体和广告联盟可以向全网范围的广告主提供其尚未售出的流量，为自己带来更高收益的同时，也为广告主提供了更多的选择，提高了他们的广告投放效果与投资回报率。<br>实时广告竞价从根本上解决了展示广告需求和供给方之间的矛盾，用市场化的规则使得资源达到了最优化的配置。</p>
<p><img src="/images/rtb.png" alt="rtb"></p>
<p>参考书目：《互联网广告算法和系统实践》</p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote class=&quot;blockquote-center&quot;&gt;&lt;h3 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h3&gt;&lt;p&gt;相比较于搜索广告，凡是浏览者没有主动输入搜索词的场景里面的广告，都可以叫做“非搜索广告”，即情景广告。本篇笔记包含非搜索广告的几种场景，以及针对定向广告的痛点发展而来的实时竞价广告。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="ComputationalAdvertising" scheme="http://www.phoebepan.cn/categories/ComputationalAdvertising/"/>
    
    
      <category term="计算广告" scheme="http://www.phoebepan.cn/tags/%E8%AE%A1%E7%AE%97%E5%B9%BF%E5%91%8A/"/>
    
  </entry>
  
  <entry>
    <title>搜索广告</title>
    <link href="http://www.phoebepan.cn/2017/08/02/searchad/"/>
    <id>http://www.phoebepan.cn/2017/08/02/searchad/</id>
    <published>2017-08-02T07:30:16.000Z</published>
    <updated>2017-08-12T03:11:02.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote class="blockquote-center"><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>搜索广告指，在搜索过程中，搜索引擎推送给我们的互联网广告。参考Google财报，绝大部分收入来自于搜索广告。一般来说，当用户输入一个查询后，广告系统会经过：广告检索、广告排序、流量分配，三个模块为用户提供广告。</p>
</blockquote>
<a id="more"></a>
<h3 id="思维导图"><a href="#思维导图" class="headerlink" title="思维导图"></a>思维导图</h3><p><img src="/images/searchad.png" alt="searchad"></p>
<h3 id="在线学习"><a href="#在线学习" class="headerlink" title="在线学习"></a>在线学习</h3><p>模型获得一个训练样本<x,y>，利用一个迭代方法更新模型变量，使得当前期望loss最小。</x,y></p>
<blockquote>
<p>实际使用中，特征向量高维稀疏性，需要采用特征缩减技术进行特征稀疏化处理，可使用L1泛数加入目标函数。<br>工业界需要CTR预估模型具有自适应性，能够迅速适应数据变化。如，逻辑回归模型采用随机梯度下降法就具备在线学习能力。</p>
</blockquote>
<p>SGD简单易行，但很难得到特征向量稀疏结果，且精度低，收敛慢，Google提出的FTRL-Proximal方法可以得到稀疏性更好地训练结果。FTRL算法融合了RDA算法能产生稀疏模型的特性和SGD算法能产生更有效模型的特性，在处理诸如LR之类的非光滑正则化项的凸优化问题上性能更出色。算法详细理解参考博文<sup>1</sup>。<br><img src="/images/ftrl.png" alt="ftrl"></p>
<p>除了运用L1正则化降低特征维度，其他常见的方法也可以降低特征维度，比如，</p>
<ul>
<li>泊松选择法，不同特征表中的新特征以P的概率接纳其进入特征表。</li>
</ul>
<p>参考文献：</p>
<ol>
<li><a href="http://vividfree.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2015/12/05/understanding-FTRL-algorithm" target="_blank" rel="external">理解FTRL算法</a></li>
<li>《互联网广告算法和系统实践》</li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote class=&quot;blockquote-center&quot;&gt;&lt;h3 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h3&gt;&lt;p&gt;搜索广告指，在搜索过程中，搜索引擎推送给我们的互联网广告。参考Google财报，绝大部分收入来自于搜索广告。一般来说，当用户输入一个查询后，广告系统会经过：广告检索、广告排序、流量分配，三个模块为用户提供广告。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="ComputationalAdvertising" scheme="http://www.phoebepan.cn/categories/ComputationalAdvertising/"/>
    
    
      <category term="计算广告" scheme="http://www.phoebepan.cn/tags/%E8%AE%A1%E7%AE%97%E5%B9%BF%E5%91%8A/"/>
    
  </entry>
  
  <entry>
    <title>互联网广告简介</title>
    <link href="http://www.phoebepan.cn/2017/08/01/AdvertisingSummary/"/>
    <id>http://www.phoebepan.cn/2017/08/01/AdvertisingSummary/</id>
    <published>2017-08-01T07:30:16.000Z</published>
    <updated>2017-08-13T08:24:07.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote class="blockquote-center"><p>广告是由已确定的出资人通过各种媒介进行的有关产品（商品、服务和观点）的、有偿的、有组织的、综合的、劝服性的非人员的信息传播活动。<br>——William F.Arens</p>
</blockquote>
<p><code>Stay Hungry, Stay Foolish.</code> 从这篇笔记开始学习计算广告。<br><a id="more"></a></p>
<h3 id="角色"><a href="#角色" class="headerlink" title="角色"></a>角色</h3><p>广告主、媒体、受众；三者博弈的生态系统。</p>
<h3 id="广告类型"><a href="#广告类型" class="headerlink" title="广告类型"></a>广告类型</h3><ul>
<li>条幅广告</li>
<li>邮件直接营销广告</li>
<li>富媒体广告</li>
<li>视频广告</li>
<li>文字链广告</li>
<li>社交广告</li>
<li>移动端广告</li>
</ul>
<h3 id="系统架构"><a href="#系统架构" class="headerlink" title="系统架构"></a>系统架构</h3><ul>
<li>前端引擎</li>
<li>检索引擎</li>
<li>实时点击率预估服务</li>
<li>广告主操作消息更新服务</li>
<li>用户行为数据收集和更新系统</li>
<li>特征提取和行为分析</li>
<li>反作弊系统</li>
<li>广告主后台(建立投放计划、增加投放创意、出价、设定投放参数、阅读报表等)</li>
<li>存储系统</li>
<li>计算系统(人群属性、意图挖掘；多特征任务)</li>
</ul>
<h3 id="机制设计"><a href="#机制设计" class="headerlink" title="机制设计"></a>机制设计</h3><blockquote>
<p>在经济学中，机制设计所讨论的问题是：在给定一个社会目标或者经济目标，以及自由选择、自愿交换的分散化决策条件下，能否并且怎样设计一个经济机制（包括制约条件、资源配置等），使得参与者的个人利益和设计者既定的目标一致。</p>
</blockquote>
<h4 id="广告机制设计"><a href="#广告机制设计" class="headerlink" title="广告机制设计"></a>广告机制设计</h4><blockquote>
<p>主要研究的是，如何针对不同广告受众，将广告平台上有限的展现位置分配给不同的广告，以达到某种既定的利益目标。</p>
</blockquote>
<h3 id="优化目标"><a href="#优化目标" class="headerlink" title="优化目标"></a>优化目标</h3><p>互联网广告算法的核心问题，是根据用户、环境、广告的全部有效信息，找到最合适的投放策略和模型，兼顾浏览者、广告主、广告平台的最大利益，并不断调整。</p>
<h3 id="思维导图"><a href="#思维导图" class="headerlink" title="思维导图"></a>思维导图</h3><p><img src="/images/advertising.png" alt="advertising"></p>
<h3 id="广告系统的架构"><a href="#广告系统的架构" class="headerlink" title="广告系统的架构"></a>广告系统的架构</h3><p><img src="/images/ad_challenge.png" alt="ad_challenge"></p>
<p>参考书目：《互联网广告算法和系统实践》</p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote class=&quot;blockquote-center&quot;&gt;&lt;p&gt;广告是由已确定的出资人通过各种媒介进行的有关产品（商品、服务和观点）的、有偿的、有组织的、综合的、劝服性的非人员的信息传播活动。&lt;br&gt;——William F.Arens&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;Stay Hungry, Stay Foolish.&lt;/code&gt; 从这篇笔记开始学习计算广告。&lt;br&gt;
    
    </summary>
    
      <category term="ComputationalAdvertising" scheme="http://www.phoebepan.cn/categories/ComputationalAdvertising/"/>
    
    
      <category term="计算广告" scheme="http://www.phoebepan.cn/tags/%E8%AE%A1%E7%AE%97%E5%B9%BF%E5%91%8A/"/>
    
  </entry>
  
  <entry>
    <title>python中time模块</title>
    <link href="http://www.phoebepan.cn/2017/07/16/time/"/>
    <id>http://www.phoebepan.cn/2017/07/16/time/</id>
    <published>2017-07-16T07:30:16.000Z</published>
    <updated>2017-07-16T04:40:44.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote class="blockquote-center"><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>在日常数据处理中，常常需要与时间打交道，python中与时间处理有关的模块有：<code>time</code>，<code>datetime</code>，<code>calendar</code>。本文主要介绍<strong>time</strong>模块。<br><img src="/images/time_convert.png" alt="time"></p>
</blockquote>
<a id="more"></a>
<p>Python中，表示时间的方式有：</p>
<ul>
<li>时间戳：通常来说，表示的是从<strong>1970年1月1日00:00:00</strong>开始按秒计算的偏移量；</li>
<li>格式化的时间字符串；</li>
<li>元组(struct_time)。</li>
</ul>
<p>time模块常用的几个函数：</p>
<h3 id="time-localtime"><a href="#time-localtime" class="headerlink" title="time.localtime()"></a>time.localtime()</h3><p>将一个时间戳转换成当前时区的struct_time。</p>
<h3 id="time-time"><a href="#time-time" class="headerlink" title="time.time()"></a>time.time()</h3><p>返回当前时间的时间戳。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt;time.time()</div><div class="line"><span class="number">1500176454.689554</span></div></pre></td></tr></table></figure></p>
<h3 id="time-mktime"><a href="#time-mktime" class="headerlink" title="time.mktime()"></a>time.mktime()</h3><p>将一个struct_time转化为时间戳<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt;time.mktime(time.localtime())</div><div class="line"><span class="number">1500176622.0</span></div></pre></td></tr></table></figure></p>
<h3 id="time-sleep"><a href="#time-sleep" class="headerlink" title="time.sleep()"></a>time.sleep()</h3><p>线程推迟运行，单位为秒</p>
<h3 id="time-strftime"><a href="#time-strftime" class="headerlink" title="time.strftime()"></a>time.strftime()</h3><p>把一个代表时间的元组转化为格式化的时间字符串。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt;time.strftime(<span class="string">'%Y-%m-%d %X'</span>,time.localtime())</div><div class="line"><span class="string">'2017-07-16 11:58:07'</span></div></pre></td></tr></table></figure></p>
<h3 id="time-strptime"><a href="#time-strptime" class="headerlink" title="time.strptime()"></a>time.strptime()</h3><p>格式化时间字符串转化成struct_time。与strftime()操作互逆。<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt;time.strptime('2017-07-16 11:58:07','%Y-%m-%d %X'')</div><div class="line">time.struct_time(tm_year=2017, tm_mon=7, tm_mday=16, tm_hour=11, tm_min=58, tm_sec=7, tm_wday=6, tm_yday=197, tm_isdst=-1)</div></pre></td></tr></table></figure></p>
<p>了解更多，请参考<a href="https://docs.python.org/3/library/time.html" target="_blank" rel="external">time模块的官方文档</a>。</p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote class=&quot;blockquote-center&quot;&gt;&lt;h3 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h3&gt;&lt;p&gt;在日常数据处理中，常常需要与时间打交道，python中与时间处理有关的模块有：&lt;code&gt;time&lt;/code&gt;，&lt;code&gt;datetime&lt;/code&gt;，&lt;code&gt;calendar&lt;/code&gt;。本文主要介绍&lt;strong&gt;time&lt;/strong&gt;模块。&lt;br&gt;&lt;img src=&quot;/images/time_convert.png&quot; alt=&quot;time&quot;&gt;&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Python" scheme="http://www.phoebepan.cn/categories/Python/"/>
    
    
      <category term="Python" scheme="http://www.phoebepan.cn/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Combination Sum</title>
    <link href="http://www.phoebepan.cn/2017/07/05/CombinationSum/"/>
    <id>http://www.phoebepan.cn/2017/07/05/CombinationSum/</id>
    <published>2017-07-05T07:30:16.000Z</published>
    <updated>2017-08-19T14:28:45.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote class="blockquote-center"><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>本篇笔记主要记录，运用DFS或DP算法求解组合数相关题目。</p>
</blockquote>
<a id="more"></a>
<h3 id="Combination-Sum"><a href="#Combination-Sum" class="headerlink" title="Combination Sum"></a>Combination Sum</h3><p>题目来源：<a href="https://leetcode.com/problems/combination-sum/description/" target="_blank" rel="external">LeetCode 39</a></p>
<blockquote>
<p>For example, given candidate set [2, 3, 6, 7] and target 7,<br>A solution set is:<br>[<br>  [7],<br>  [2, 2, 3]<br>]<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">combinationSum</span><span class="params">(self, candidates, target)</span>:</span></div><div class="line">        <span class="string">"""</span></div><div class="line">        :type candidates: List[int]</div><div class="line">        :type target: int</div><div class="line">        :rtype: List[List[int]]</div><div class="line">        """</div><div class="line">        res=[]</div><div class="line">        candidates.sort()</div><div class="line">        self.dfs(candidates,target,<span class="number">0</span>,[],res)</div><div class="line">        <span class="keyword">return</span>  res</div><div class="line">        </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">dfs</span><span class="params">(self,nums,target,index,path,res)</span>:</span></div><div class="line">        <span class="keyword">if</span> target&lt;<span class="number">0</span>:</div><div class="line">            <span class="keyword">return</span></div><div class="line">        <span class="keyword">if</span> target==<span class="number">0</span>:</div><div class="line">            res.append(path)</div><div class="line">            <span class="keyword">return</span></div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(index,len(nums)):</div><div class="line">            self.dfs(nums,target-nums[i],i,path+[nums[i]],res)</div></pre></td></tr></table></figure></p>
</blockquote>
<h3 id="Combination-Sum-II"><a href="#Combination-Sum-II" class="headerlink" title="Combination Sum II"></a>Combination Sum II</h3><p>题目来源：<a href="https://leetcode.com/problems/combination-sum-ii/description/" target="_blank" rel="external">LeetCode 40</a></p>
<blockquote>
<p>For example, given candidate set [10, 1, 2, 7, 6, 1, 5] and target 8,<br>A solution set is:<br>[<br>  [1, 7],<br>  [1, 2, 5],<br>  [2, 6],<br>  [1, 1, 6]<br>]</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">combinationSum2</span><span class="params">(self, candidates, target)</span>:</span></div><div class="line">        <span class="string">"""</span></div><div class="line">        :type candidates: List[int]</div><div class="line">        :type target: int</div><div class="line">        :rtype: List[List[int]]</div><div class="line">        """</div><div class="line">        candidates.sort()</div><div class="line">        <span class="keyword">return</span> self.search(candidates, <span class="number">0</span> ,target)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">search</span><span class="params">(self, candidates, start, target)</span>:</span></div><div class="line">        <span class="keyword">if</span> target==<span class="number">0</span>:</div><div class="line">            <span class="keyword">return</span> [[]]</div><div class="line">        res=[]</div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> xrange(start,len(candidates)):</div><div class="line">            <span class="keyword">if</span> i!=start <span class="keyword">and</span> candidates[i]==candidates[i<span class="number">-1</span>]:</div><div class="line">                <span class="keyword">continue</span></div><div class="line">            <span class="keyword">if</span> candidates[i]&gt;target:</div><div class="line">                <span class="keyword">break</span></div><div class="line">            <span class="keyword">for</span> r <span class="keyword">in</span> self.search(candidates, i+<span class="number">1</span>, target-candidates[i]):</div><div class="line">                res.append([candidates[i]]+r)</div><div class="line">        <span class="keyword">return</span> res</div></pre></td></tr></table></figure>
<h3 id="Combination-Sum-III"><a href="#Combination-Sum-III" class="headerlink" title="Combination Sum III"></a>Combination Sum III</h3><p>题目来源：<a href="https://leetcode.com/problems/combination-sum-iii/discuss/" target="_blank" rel="external">LeetCode 216</a></p>
<blockquote>
<p>Input: k = 3, n = 9<br>Output:[[1,2,6], [1,3,5], [2,3,4]]</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">combinationSum3</span><span class="params">(self, k, n)</span>:</span></div><div class="line">        <span class="string">"""</span></div><div class="line">        :type k: int</div><div class="line">        :type n: int</div><div class="line">        :rtype: List[List[int]]</div><div class="line">        """</div><div class="line">        ans = []</div><div class="line">        <span class="function"><span class="keyword">def</span> <span class="title">search</span><span class="params">(start, cnt, sums, nums)</span>:</span></div><div class="line">            <span class="keyword">if</span> cnt &gt; k <span class="keyword">or</span> sums &gt; n:</div><div class="line">                <span class="keyword">return</span></div><div class="line">            <span class="keyword">if</span> cnt == k <span class="keyword">and</span> sums == n:</div><div class="line">                ans.append(nums)</div><div class="line">                <span class="keyword">return</span></div><div class="line">            <span class="keyword">for</span> x <span class="keyword">in</span> range(start + <span class="number">1</span>, <span class="number">10</span>):</div><div class="line">                search(x, cnt + <span class="number">1</span>, sums + x, nums + [x])</div><div class="line">        search(<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, [])</div><div class="line">        <span class="keyword">return</span> ans</div></pre></td></tr></table></figure>
<h3 id="Combination-Sum-IV"><a href="#Combination-Sum-IV" class="headerlink" title="Combination Sum IV"></a>Combination Sum IV</h3><p>题目来源：<a href="https://leetcode.com/problems/combination-sum-iv/description/" target="_blank" rel="external">LeetCode 377</a></p>
<blockquote>
<p>nums = [1, 2, 3]<br>target = 4<br>The possible combination ways are:<br>(1, 1, 1, 1)<br>(1, 1, 2)<br>(1, 2, 1)<br>(1, 3)<br>(2, 1, 1)<br>(2, 2)<br>(3, 1)</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">combinationSum4</span><span class="params">(self, nums, target)</span>:</span></div><div class="line">        <span class="string">"""</span></div><div class="line">        :type nums: List[int]</div><div class="line">        :type target: int</div><div class="line">        :rtype: int</div><div class="line">        """</div><div class="line">        nums, combs = sorted(nums), [<span class="number">1</span>] + [<span class="number">0</span>] * (target)</div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(target + <span class="number">1</span>):</div><div class="line">            <span class="keyword">for</span> num <span class="keyword">in</span> nums:</div><div class="line">                <span class="keyword">if</span> num  &gt; i: <span class="keyword">break</span></div><div class="line">                <span class="keyword">if</span> num == i: combs[i] += <span class="number">1</span></div><div class="line">                <span class="keyword">if</span> num  &lt; i: combs[i] += combs[i - num]</div><div class="line">        <span class="keyword">return</span> combs[target]</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;blockquote class=&quot;blockquote-center&quot;&gt;&lt;h3 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h3&gt;&lt;p&gt;本篇笔记主要记录，运用DFS或DP算法求解组合数相关题目。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Algorithms" scheme="http://www.phoebepan.cn/categories/Algorithms/"/>
    
    
      <category term="LeetCode" scheme="http://www.phoebepan.cn/tags/LeetCode/"/>
    
      <category term="Algorithms" scheme="http://www.phoebepan.cn/tags/Algorithms/"/>
    
  </entry>
  
  <entry>
    <title>Python——map()</title>
    <link href="http://www.phoebepan.cn/2017/07/01/python_mapreduce/"/>
    <id>http://www.phoebepan.cn/2017/07/01/python_mapreduce/</id>
    <published>2017-07-01T07:30:16.000Z</published>
    <updated>2017-08-19T08:11:34.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote class="blockquote-center"><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>本篇笔记简单记录Python内建函数<code>map()</code>和<code>reduce()</code>函数几种使用示例。</p>
</blockquote>
<a id="more"></a>
<h3 id="map"><a href="#map" class="headerlink" title="map()"></a>map()</h3><p>函数接收两个参数，一是函数，一是待处理的序列，<code>map</code>将传入的函数一次作用到序列的每一个元素，并把结果作为新的list返回。如：</p>
<h4 id="e-g-1"><a href="#e-g-1" class="headerlink" title="e.g. 1"></a>e.g. 1</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">add10</span><span class="params">(x)</span>:</span></div><div class="line">    <span class="keyword">return</span> x+<span class="number">10</span></div><div class="line">temp = [<span class="number">2</span>,<span class="number">4</span>,<span class="number">8</span>,<span class="number">9</span>,<span class="number">1</span>]</div><div class="line">map(add10,temp)</div><div class="line">print(temp)</div><div class="line"><span class="comment">#[12,14,18,19,11]</span></div></pre></td></tr></table></figure>
<h4 id="e-g-2"><a href="#e-g-2" class="headerlink" title="e.g. 2"></a>e.g. 2</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>map(str,[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>])</div><div class="line">[<span class="string">'1'</span>,<span class="string">'2'</span>,<span class="string">'3'</span>,<span class="string">'4'</span>]</div></pre></td></tr></table></figure>
<h4 id="e-g-3"><a href="#e-g-3" class="headerlink" title="e.g. 3"></a>e.g. 3</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">abc</span><span class="params">(a, b, c)</span>:</span></div><div class="line">    <span class="keyword">return</span> a*<span class="number">10000</span> + b*<span class="number">100</span> + c</div><div class="line">list1 = [<span class="number">11</span>,<span class="number">22</span>,<span class="number">33</span>]</div><div class="line">list2 = [<span class="number">44</span>,<span class="number">55</span>,<span class="number">66</span>]</div><div class="line">list3 = [<span class="number">77</span>,<span class="number">88</span>,<span class="number">99</span>]</div><div class="line">map(abc,list1,list2,list3)</div><div class="line"><span class="comment">#[114477, 225588, 336699]</span></div></pre></td></tr></table></figure>
<p>如果函数参数为<code>None</code>，自动假定一个<code>identity</code>函数，如：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">list1 = [<span class="number">11</span>,<span class="number">22</span>,<span class="number">33</span>]</div><div class="line">map(<span class="keyword">None</span>,list1)</div><div class="line"><span class="comment">#[11, 22, 33]</span></div><div class="line">list1 = [<span class="number">11</span>,<span class="number">22</span>,<span class="number">33</span>]</div><div class="line">list2 = [<span class="number">44</span>,<span class="number">55</span>,<span class="number">66</span>]</div><div class="line">list3 = [<span class="number">77</span>,<span class="number">88</span>,<span class="number">99</span>]</div><div class="line">map(<span class="keyword">None</span>,list1,list2,list3)</div><div class="line"><span class="comment">#[(11, 44, 77), (22, 55, 88), (33, 66, 99)]</span></div></pre></td></tr></table></figure></p>
<h3 id="reduce"><a href="#reduce" class="headerlink" title="reduce()"></a>reduce()</h3><p>reduce把一个函数<code>f</code>作用在一个序列上，函数<code>f</code>必须接受两个参数，reduce把结果继续和序列下一个元素做累积计算，功效等价于：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">reduce(f, [x1, x2, x3, x4]) = f(f(f(x1, x2), x3), x4)</div></pre></td></tr></table></figure></p>
<h4 id="e-g-1-1"><a href="#e-g-1-1" class="headerlink" title="e.g. 1"></a>e.g. 1</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> reduce</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">add</span><span class="params">(x, y)</span>:</span></div><div class="line">    <span class="keyword">return</span> x*<span class="number">10</span> + y</div><div class="line"></div><div class="line">reduce(add, [<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">9</span>])</div><div class="line"><span class="comment">#13579</span></div></pre></td></tr></table></figure>
<h3 id="map-reduce实现str2int"><a href="#map-reduce实现str2int" class="headerlink" title="map reduce实现str2int"></a>map reduce实现str2int</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">str2int</span><span class="params">(s)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fn</span><span class="params">(x, y)</span>:</span></div><div class="line">        <span class="keyword">return</span> x * <span class="number">10</span> + y</div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">char2num</span><span class="params">(s)</span>:</span></div><div class="line">        temp=&#123;<span class="string">'0'</span>: <span class="number">0</span>, <span class="string">'1'</span>: <span class="number">1</span>, <span class="string">'2'</span>: <span class="number">2</span>, <span class="string">'3'</span>: <span class="number">3</span>, <span class="string">'4'</span>: <span class="number">4</span>, <span class="string">'5'</span>: <span class="number">5</span>, <span class="string">'6'</span>: <span class="number">6</span>, <span class="string">'7'</span>: <span class="number">7</span>, <span class="string">'8'</span>: <span class="number">8</span>, <span class="string">'9'</span>: <span class="number">9</span>&#125;</div><div class="line">        <span class="keyword">return</span> temp[s]</div><div class="line">    <span class="keyword">return</span> reduce(fn, map(char2num, s))</div></pre></td></tr></table></figure>
<p>进一步使用lambda函数简化成：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">char2num</span><span class="params">(s)</span>:</span></div><div class="line">    <span class="keyword">return</span> &#123;<span class="string">'0'</span>: <span class="number">0</span>, <span class="string">'1'</span>: <span class="number">1</span>, <span class="string">'2'</span>: <span class="number">2</span>, <span class="string">'3'</span>: <span class="number">3</span>, <span class="string">'4'</span>: <span class="number">4</span>, <span class="string">'5'</span>: <span class="number">5</span>, <span class="string">'6'</span>: <span class="number">6</span>, <span class="string">'7'</span>: <span class="number">7</span>, <span class="string">'8'</span>: <span class="number">8</span>, <span class="string">'9'</span>: <span class="number">9</span>&#125;[s]</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">str2int</span><span class="params">(s)</span>:</span></div><div class="line">    <span class="keyword">return</span> reduce(<span class="keyword">lambda</span> x,y: x*<span class="number">10</span>+y, map(char2num, s))</div></pre></td></tr></table></figure></p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote class=&quot;blockquote-center&quot;&gt;&lt;h3 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h3&gt;&lt;p&gt;本篇笔记简单记录Python内建函数&lt;code&gt;map()&lt;/code&gt;和&lt;code&gt;reduce()&lt;/code&gt;函数几种使用示例。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Python" scheme="http://www.phoebepan.cn/categories/Python/"/>
    
    
      <category term="Python" scheme="http://www.phoebepan.cn/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>ROC &amp; AUC</title>
    <link href="http://www.phoebepan.cn/2017/06/17/ROC/"/>
    <id>http://www.phoebepan.cn/2017/06/17/ROC/</id>
    <published>2017-06-17T07:30:16.000Z</published>
    <updated>2017-08-13T09:22:45.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote class="blockquote-center"><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>ROC曲线和AUC常常被用来评价二分类模型的优劣，本篇笔记介绍ROC和AUC的特点，以及如何作出ROC曲线图并计算AUC。</p>
</blockquote>
<a id="more"></a>
<h3 id="ROC曲线"><a href="#ROC曲线" class="headerlink" title="ROC曲线"></a>ROC曲线</h3><p>针对二分类问题，ROC曲线的横坐标为<code>false positive rate(FPR)</code>，纵坐标为<code>true positive rate(TPR)</code>。</p>
<h4 id="FPR和TPR定义"><a href="#FPR和TPR定义" class="headerlink" title="FPR和TPR定义"></a>FPR和TPR定义</h4><p>下图这一混淆矩阵详细说明了FPR和TPR是如何定义的。<br><img src="/images/fpr-and-tpr.png" alt="fpr-and-tpr"><br>对于一个特定的分类器和测试集，只能得到一个分类结果，即只有一组FPR和TPR结果，要得到一曲线，需要一系列的FPR和TPR的值对，<a href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic" target="_blank" rel="external">wikipedia</a>上对ROC曲线的定义：<br><blockquote class="blockquote-center"><p>In statistics, a receiver operating characteristic curve, i.e. ROC curve, is a graphical plot that illustrates the diagnostic ability of a binary classifier system as its discrimination threshold is varied.</p>
</blockquote><br>“discrimination threshold”如何理解呢？，对于一个二分类器的“概率输出”，即表示分类器认为样本属于正样本的概率多大，我们从高到低依次将这一概率输出作为阈值threshold，得到测试集的正负样本划分，这样每次选取一个不同的threshold，就得到一组FPR和TPR，即ROC曲线上一点，将这些(FPR,TPR)对连接起来，就得到了ROC曲线，当threshold取值越多，ROC曲线越平滑。</p>
<h3 id="AUC的计算"><a href="#AUC的计算" class="headerlink" title="AUC的计算"></a>AUC的计算</h3><p>AUC的含义是？ROC曲线下面积，作为一个数值，AUC越大分类器效果越好。</p>
<blockquote>
<p>可以理解为，所有正负样本对中，正样本score大于负样本score的概率值。</p>
</blockquote>
<h3 id="使用ROC曲线好处"><a href="#使用ROC曲线好处" class="headerlink" title="使用ROC曲线好处"></a>使用ROC曲线好处</h3><p>当测试集中正负样本的分布变化或者类别不平衡的时候，相比于Precision-Recall曲线，ROC曲线能够保持不变。</p>
<h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><ul>
<li><a href="http://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html" target="_blank" rel="external">sklearn.metrics.roc_curve</a></li>
<li><a href="http://scikit-learn.org/stable/modules/generated/sklearn.metrics.auc.html" target="_blank" rel="external">sklearn.metrics.auc</a></li>
</ul>
<p>参考文献：</p>
<ol>
<li><a href="http://alexkong.net/2013/06/introduction-to-auc-and-roc/" target="_blank" rel="external">ROC和AUC介绍以及如何计算AUC</a></li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote class=&quot;blockquote-center&quot;&gt;&lt;h3 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h3&gt;&lt;p&gt;ROC曲线和AUC常常被用来评价二分类模型的优劣，本篇笔记介绍ROC和AUC的特点，以及如何作出ROC曲线图并计算AUC。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Machine Learning" scheme="http://www.phoebepan.cn/categories/Machine-Learning/"/>
    
    
      <category term="ML" scheme="http://www.phoebepan.cn/tags/ML/"/>
    
  </entry>
  
  <entry>
    <title>调超参神器——GridSearchCV</title>
    <link href="http://www.phoebepan.cn/2017/06/16/GridSearchCV/"/>
    <id>http://www.phoebepan.cn/2017/06/16/GridSearchCV/</id>
    <published>2017-06-16T07:30:16.000Z</published>
    <updated>2017-07-19T02:41:47.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote class="blockquote-center"><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>所谓超参，就是机器学习算法中，不能通过自身学习设定的参数，如SVM的惩罚因子C，核函数kernel，gamma参数等，参数间的组合很是繁琐，人工调节这些超参数时间成本太高，易出错。本文主要介绍sklearn模块的调参神器<code>GridSearchCV</code>模块，它能够在指定范围内自动搜索具有不同超参数的不同模型组合，寻找最佳参数，大大提高调参效率。</p>
</blockquote>
<a id="more"></a>
<h3 id="缘起"><a href="#缘起" class="headerlink" title="缘起"></a>缘起</h3><p>这两天，闲来参加下Ctrip的一个数据竞赛，model选择的是XGboost，好用是自然，但是参数有很多，最迫切需要一个自动调节参数工具，于是接触到GridSearchCV模块。</p>
<h3 id="官方手册"><a href="#官方手册" class="headerlink" title="官方手册"></a>官方手册</h3><p><a href="http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html#sklearn.grid_search.GridSearchCV" target="_blank" rel="external">手册链接</a></p>
<h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><p>自己训练的代码如下(XGboost+5-fold Cross Validation)，清晰易懂，无须解释。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</div><div class="line"><span class="keyword">from</span> sklearn.grid_search <span class="keyword">import</span> GridSearchCV</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">xgbmodel_train</span><span class="params">(train)</span>:</span></div><div class="line">    xgb_model = xgb.XGBClassifier()</div><div class="line">    train_feature, train_label = train.drop(<span class="string">'orderlabel'</span>, axis=<span class="number">1</span>), train[<span class="string">'orderlabel'</span>]</div><div class="line"></div><div class="line">    parameters = &#123;<span class="string">'nthread'</span>: [<span class="number">4</span>],</div><div class="line">                  <span class="string">'objective'</span>: [<span class="string">'binary:logistic'</span>],</div><div class="line">                  <span class="string">'learning_rate'</span>: [<span class="number">0.05</span>,<span class="number">0.06</span>,<span class="number">0.1</span>],</div><div class="line">                  <span class="string">'max_depth'</span>: [<span class="number">5</span>, <span class="number">6</span>],</div><div class="line">                  <span class="string">'min_child_weight'</span>: [<span class="number">1</span>, <span class="number">3</span>],</div><div class="line">                  <span class="string">'silent'</span>: [<span class="number">1</span>],</div><div class="line">                  <span class="string">'gamma'</span>: [<span class="number">0</span>, <span class="number">0.1</span>],</div><div class="line">                  <span class="string">'subsample'</span>: [<span class="number">0.6</span>, <span class="number">0.7</span>, <span class="number">0.8</span>],</div><div class="line">                  <span class="string">'colsample_bytree'</span>: [<span class="number">0.7</span>, <span class="number">0.5</span>, <span class="number">0.6</span>],</div><div class="line">                  <span class="string">'n_estimators'</span>: [<span class="number">5</span>],</div><div class="line">                  <span class="string">'missing'</span>: [<span class="number">-999</span>],</div><div class="line">                  <span class="string">'seed'</span>: [<span class="number">12455</span>]&#125;</div><div class="line"></div><div class="line">    clf = GridSearchCV(xgb_model, parameters, n_jobs=<span class="number">1</span>,</div><div class="line">                       cv=StratifiedKFold(train[<span class="string">'orderlabel'</span>], n_folds=<span class="number">5</span>, shuffle=<span class="keyword">True</span>),</div><div class="line">                       scoring=<span class="string">'roc_auc'</span>,</div><div class="line">                       verbose=<span class="number">2</span>, refit=<span class="keyword">True</span>)</div><div class="line"></div><div class="line"></div><div class="line">    clf.fit(train_feature, train_label)</div><div class="line">   </div><div class="line">    best_parameters, score, _ = max(clf.grid_scores_, key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>])</div><div class="line">    print(<span class="string">'AUC score:'</span>, score)</div><div class="line">    <span class="keyword">for</span> param_name <span class="keyword">in</span> sorted(best_parameters.keys()):</div><div class="line">        print(<span class="string">'%s: %r'</span> % (param_name, best_parameters[param_name]))</div></pre></td></tr></table></figure></p>
<h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p><img src="/images/process.png" alt="process"><br><img src="/images/best_score.png" alt="best para"></p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote class=&quot;blockquote-center&quot;&gt;&lt;h3 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h3&gt;&lt;p&gt;所谓超参，就是机器学习算法中，不能通过自身学习设定的参数，如SVM的惩罚因子C，核函数kernel，gamma参数等，参数间的组合很是繁琐，人工调节这些超参数时间成本太高，易出错。本文主要介绍sklearn模块的调参神器&lt;code&gt;GridSearchCV&lt;/code&gt;模块，它能够在指定范围内自动搜索具有不同超参数的不同模型组合，寻找最佳参数，大大提高调参效率。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Machine Learning" scheme="http://www.phoebepan.cn/categories/Machine-Learning/"/>
    
    
      <category term="ML" scheme="http://www.phoebepan.cn/tags/ML/"/>
    
      <category term="Tune" scheme="http://www.phoebepan.cn/tags/Tune/"/>
    
  </entry>
  
  <entry>
    <title>两个数列的第K大数</title>
    <link href="http://www.phoebepan.cn/2017/06/15/kth/"/>
    <id>http://www.phoebepan.cn/2017/06/15/kth/</id>
    <published>2017-06-15T07:30:16.000Z</published>
    <updated>2017-08-19T14:46:11.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote class="blockquote-center"><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>本篇笔记主要记录，运用递归求解两个有序数列第K大数问题。</p>
</blockquote>
<a id="more"></a>
<h3 id="Median-of-Two-Sorted-Arrays"><a href="#Median-of-Two-Sorted-Arrays" class="headerlink" title="Median of Two Sorted Arrays"></a>Median of Two Sorted Arrays</h3><p>题目来源：<a href="https://leetcode.com/problems/median-of-two-sorted-arrays/discuss/" target="_blank" rel="external">LeetCode 4</a></p>
<blockquote>
<p>方案一：用merge sort思路排序，排序后取k-1的元素；<br>方案二：两个指针，分别指向两个序列的开头，逐次比较元素；<br>方案三：二分剔除</p>
</blockquote>
<p>方案三解法：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getKth</span><span class="params">(self, A, B, k)</span>:</span></div><div class="line">        lenA = len(A); lenB = len(B)</div><div class="line">        <span class="keyword">if</span> lenA &gt; lenB: <span class="keyword">return</span> self.getKth(B, A, k)</div><div class="line">        <span class="keyword">if</span> lenA == <span class="number">0</span>: <span class="keyword">return</span> B[k - <span class="number">1</span>]</div><div class="line">        <span class="keyword">if</span> k == <span class="number">1</span>: <span class="keyword">return</span> min(A[<span class="number">0</span>], B[<span class="number">0</span>])</div><div class="line">        pa = min(k/<span class="number">2</span>, lenA); pb = k - pa</div><div class="line">        <span class="keyword">if</span> A[pa - <span class="number">1</span>] &lt;= B[pb - <span class="number">1</span>]:</div><div class="line">            <span class="keyword">return</span> self.getKth(A[pa:], B, pb)</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            <span class="keyword">return</span> self.getKth(A, B[pb:], pa)</div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">findMedianSortedArrays</span><span class="params">(self, A, B)</span>:</span></div><div class="line">        lenA = len(A); lenB = len(B)</div><div class="line">        <span class="keyword">if</span> (lenA + lenB) % <span class="number">2</span> == <span class="number">1</span>: </div><div class="line">            <span class="keyword">return</span> self.getKth(A, B, (lenA + lenB)/<span class="number">2</span> + <span class="number">1</span>)</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            <span class="keyword">return</span> (self.getKth(A, B, (lenA + lenB)/<span class="number">2</span>) + self.getKth(A, B, (lenA + lenB)/<span class="number">2</span> + <span class="number">1</span>)) * <span class="number">0.5</span></div></pre></td></tr></table></figure></p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote class=&quot;blockquote-center&quot;&gt;&lt;h3 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h3&gt;&lt;p&gt;本篇笔记主要记录，运用递归求解两个有序数列第K大数问题。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Algorithms" scheme="http://www.phoebepan.cn/categories/Algorithms/"/>
    
    
      <category term="LeetCode" scheme="http://www.phoebepan.cn/tags/LeetCode/"/>
    
      <category term="Algorithms" scheme="http://www.phoebepan.cn/tags/Algorithms/"/>
    
  </entry>
  
  <entry>
    <title>XGBoost调参指南</title>
    <link href="http://www.phoebepan.cn/2017/06/14/xgb_paras/"/>
    <id>http://www.phoebepan.cn/2017/06/14/xgb_paras/</id>
    <published>2017-06-14T07:30:16.000Z</published>
    <updated>2017-07-21T05:17:53.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote class="blockquote-center"><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>在预测分析建模时，如果结果不理想，那么不妨试试XGBoost，可以说，XGBoost已经成为许多数据科学家的秘密武器，，本文翻译自<a href="https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/" target="_blank" rel="external">Complete Guide to Parameter Tuning in XGBoost (with codes in Python)</a>，它详细介绍了XGBoost中参数的含义以及通过实例说明调参的技艺。在此，记下自己的学习笔记。</p>
</blockquote>
<a id="more"></a>
<h3 id="XGBoost"><a href="#XGBoost" class="headerlink" title="XGBoost"></a>XGBoost</h3><p>XGBoost是Gradient Boosting算法的一个优化版本，由于XGBoost算法的内部复杂性，涉及很多超参数，相比于建立一个XGBoost model，提高该model的性能需要花费很大的精力，但这又是必须做的。</p>
<h4 id="优势"><a href="#优势" class="headerlink" title="优势"></a>优势</h4><ul>
<li><strong>正则化</strong>，在GBM基础之上，增加了正则化，有效降低过拟合风险；</li>
<li><strong>并行处理</strong>，Boosting算法是顺序处理的，比起GBM，它快的惊人，另外，XGBoost也支持Hadoop实现；</li>
<li><strong>高度灵活性</strong>，允许自定义优化目标和评价标准；</li>
<li><strong>缺失值处理</strong>，内置处理缺失值的规则，提供一个特殊值作为参数传进去；</li>
<li><strong>剪枝</strong>，GBM实则是一贪心算法，遇到负损失，就停止分裂，XGBoost根据指定最大深度(max_depth)，回过头来剪枝。如果某节点之后没有正值，它会去除这一分裂；</li>
<li><strong>内置交叉验证</strong>，允许在每一轮boosting迭代中使用交叉验证，方便获得最优迭代次数；</li>
<li><strong>上一轮结果基础上继续训练</strong></li>
</ul>
<h3 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h3><p>XGBoost的作者把所有参数分成3类：通用参数、Booster参数、学习目标参数。</p>
<h4 id="通用参数"><a href="#通用参数" class="headerlink" title="通用参数"></a>通用参数</h4><p>控制XGBoost的宏观功能。有：</p>
<ul>
<li><code>booster</code>，选择每次迭代的模型，默认gbtree；</li>
<li><code>silent</code>，默认为0，设为1，则不会输出任何信息；</li>
<li><code>nthread</code>，最大可能的线程数，用来进行多线程控制。</li>
</ul>
<h4 id="Booster参数"><a href="#Booster参数" class="headerlink" title="Booster参数"></a>Booster参数</h4><p>这里只介绍tree booster参数，有：</p>
<ul>
<li><code>eta</code>，学习率，每一步减少权重，提高模型鲁棒性。通常设置在0.01-0.2范围内；</li>
<li><code>min_child_weight</code>，最小叶子节点样本权重和，避免过拟合，值过高会导致欠拟合，可以通过CV调节该参数；</li>
<li><code>max_depth</code>，树最大深度，避免过拟合，值越大，模型可学到更具体更局部样本，CV调节该参数，通常设在3-10区间内；</li>
<li><code>max_leaf_nodes</code>，树上叶子节点最大数量；</li>
<li><code>gamma</code>，默认为0，节点分裂时，只有分裂后损失函数值下降了，才会分裂该节点，该参数指定节点分裂损失函数最小下降值，值越大，越保守；</li>
<li><code>subsample</code>，控制每棵树随机采样比例，值越小越保守，避免过拟合，值过小，可能欠拟合，通常取值范围，0.5-1；</li>
<li><code>colsample_bytree</code>，默认1，对列数采样比例；</li>
<li><code>lambda</code>，默认1，L2正则化的权重，控制正则化部分，减少过拟合；</li>
<li><code>scale_pos_weight</code>，默认1，在类别十分不均衡时，该参数设置成正值，可以是model更快收敛。</li>
</ul>
<h4 id="学习目标参数"><a href="#学习目标参数" class="headerlink" title="学习目标参数"></a>学习目标参数</h4><p>控制理想的优化目标，和每一步结果的度量，有：</p>
<ul>
<li><code>objective</code>，最小化的损失函数，常用值有binary:logistic（二分类的逻辑回归） 、multi:softmax （softmax多分类器，返回预测的类别）、multi:softprob（softmax多分类器，返回属于各个类别的概率）</li>
<li><code>eval_metric</code>，对于回归默认rmse，分类默认error，常用值，rmse，mae，logloss，error，merror，mlogloss，auc</li>
<li><code>seed</code>，随机数种子，复现随机数据结果。</li>
</ul>
<p>最后，还有两个重要参数<code>num_boosting_rounds</code>，<code>early_stopping_rounds</code>，可以控制迭代次数。<br>更多参数参考：<br><a href="http://xgboost.readthedocs.io/en/latest/model.html" target="_blank" rel="external">XGBoost Guide – Introduction to Boosted Trees</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote class=&quot;blockquote-center&quot;&gt;&lt;h3 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h3&gt;&lt;p&gt;在预测分析建模时，如果结果不理想，那么不妨试试XGBoost，可以说，XGBoost已经成为许多数据科学家的秘密武器，，本文翻译自&lt;a href=&quot;https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/&quot;&gt;Complete Guide to Parameter Tuning in XGBoost (with codes in Python)&lt;/a&gt;，它详细介绍了XGBoost中参数的含义以及通过实例说明调参的技艺。在此，记下自己的学习笔记。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Machine Learning" scheme="http://www.phoebepan.cn/categories/Machine-Learning/"/>
    
    
      <category term="ML" scheme="http://www.phoebepan.cn/tags/ML/"/>
    
      <category term="Tune" scheme="http://www.phoebepan.cn/tags/Tune/"/>
    
      <category term="Python" scheme="http://www.phoebepan.cn/tags/Python/"/>
    
      <category term="XGBoost" scheme="http://www.phoebepan.cn/tags/XGBoost/"/>
    
  </entry>
  
  <entry>
    <title>基于分布式计算的大数据系统</title>
    <link href="http://www.phoebepan.cn/2017/06/10/distributed_sys/"/>
    <id>http://www.phoebepan.cn/2017/06/10/distributed_sys/</id>
    <published>2017-06-10T07:30:16.000Z</published>
    <updated>2017-08-13T15:49:56.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote class="blockquote-center"><p>工欲善其事，必先利其器。</p>
</blockquote>
<h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>单机计算机的能力是有限的，而需要处理的问题规模不断增加，为此，人们开始探索使用多台计算机组成一个系统进行协调处理。多机系统复杂程度远高于单机系统，多机系统统称分布式系统，为解决分布式系统的可扩展性，可靠性，易用性等问题，方便处理互联网海量数据，控制成本，出现了很多解决方案。本篇笔记简单介绍几种解决方案。<br><a id="more"></a></p>
<h3 id="Hadoop生态系统"><a href="#Hadoop生态系统" class="headerlink" title="Hadoop生态系统"></a>Hadoop生态系统</h3><p>Hadoop，主要Java编写，较好平台移植性。在Hadoop系统中，每种服务一般都有若干种角色，分布式环境下负责不同功能，每种角色的实例都是一个进程，不同进程可以在同一台机器上运行，也可以根据配置运行在不同机器上。</p>
<h4 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h4><p>Hadoop的分布式文件系统。设计目标，存储那些一次写入多次读取的大量数据，如，搜索引擎会用爬虫抓取大量web页面。</p>
<p><code>名字节点(Name Node)</code>，全局只有一台。</p>
<h4 id="YARN和MapReduce"><a href="#YARN和MapReduce" class="headerlink" title="YARN和MapReduce"></a>YARN和MapReduce</h4><p>YARN，Hadoop的计算资源管理和调度系统，接受任务请求，根据请求分配资源，调度任务执行。可执行，MapReduce和MPI等传统并行程序。<br><code>资源管理器(Resource Manager)</code>，全局资源分配。</p>
<p>MapReduce，Google提出的并行程序编程模型，把任务的处理流程分为map和reduce两个阶段。详情参考我的这篇<a href="http://phoebepan.cn/2017/04/21/MapReduce/" target="_blank" rel="external">博文</a>。适合对数据进行统计、分类等处理，最大的好处在于当用户实现MapReduce任务后，该框架能自动把任务在成千上万台机器上调度运行，并处理机器故障，非常适合大规模数据处理。</p>
<h4 id="HBase"><a href="#HBase" class="headerlink" title="HBase"></a>HBase</h4><p>基于列的分布式存储。数据以表(Table)的形式组织，每个表可以有很多行，每行可以有若干个列族(需要事先定义)，每个列族可以包含多个列(使用时随时添加，无需事先定义)。每行每列对应一个单元(Cell)，每个单元值可以有多个版本，用时间戳区分。每个值是一个任意长度的字符串。每行有一自定义主键。</p>
<ul>
<li><code>HBase不能基于非id列的随机访问</code>；</li>
<li><code>compact操作</code>；</li>
<li>可作为数据仓库存储有一定结构的海量数据，数据可修改，但最好不频繁；</li>
<li>HBase的实现以HDFS为基础，每个表的每一列族都会对应HDFS上的一个或多个文件；</li>
</ul>
<h4 id="Hadoop其他组件"><a href="#Hadoop其他组件" class="headerlink" title="Hadoop其他组件"></a>Hadoop其他组件</h4><p><code>Hive</code>，<code>Pig</code>，让用户更简便方式查询保存在HDFS和HBase中的数据。查询最终都会转换成MapReduce任务来执行。<br><code>ZooKeeper</code>，编写分布式软件所需的常用工具，包括，消息队列，配置管理等。<br><code>Tez</code>，比MapReduce更一般化的数据流编程框架，推广为任意的有向无环图(DAG)。<br><code>Storm</code>，<code>S4</code>，建立在Hadoop上的流式处理引擎。流式处理(streaming)指待处理数据会源源不断从数据源过来，处理引擎需要不断对新的数据进行处理，并随时输出具体时效性的结果。<br><code>Mahout</code>，Hadoop实现的机器学习算法库，包括聚类，分类，推荐，以及线性代数中的常用算法。直接调用Mahout提供的算法，不必自己再用MapReduce实现。<br><code>Giraph</code>，图计算引擎。处理社交网络等类型的数据。<br><code>Sqoop</code>，命令行工具，用于Hadoop和传统的关系型数据库之间传输数据。MySQL与HDFS或HBase之间交换数据。<br><code>Chukwa</code>，<code>Flume</code>，<code>Kafka</code>，<code>Scribe</code>，进行日志收集，结果导出到HDFS。</p>
<h3 id="Spark"><a href="#Spark" class="headerlink" title="Spark"></a>Spark</h3><p>MapReduce程序运行过程中，中间结果会写入磁盘，而且很多应用需要多个MapReduce任务来完成，任务之间的数据也要通过磁盘来交换，没有充分利用机器内存。Spark充分利用机器内存资源，使得大数据计算性能得到了进一步提升。</p>
<h4 id="核心"><a href="#核心" class="headerlink" title="核心"></a>核心</h4><p>可靠分布式数据集(RDD)的数据结构。一个RDD是一组数据项的集合，可以是普通的列表，也可以是由键值对构成的字典。RDD操作分为动作和交换。<br>Spark的操作都是对RDD整体进行的。变换操作执行时懒惰的，操作会被记录下来，直到遇到下一个动作时产生一个完整的执行计划。动作操作直接生效，产生新的RDD。</p>
<h4 id="Spark特点："><a href="#Spark特点：" class="headerlink" title="Spark特点："></a>Spark特点：</h4><ul>
<li>Spark中的RDD可以由框架自动或人为指定缓存在<strong>内存</strong>中；</li>
<li>Spark可以独立运行，也可以在Hadoop系统上运行；</li>
<li>支持HDFS的读/写；</li>
<li>核心功能涵盖了Hadoop的大部分内容，并且可以在Hadoop生态系统内使用，具有性能上的优势。</li>
</ul>
<h3 id="NoSQL-Not-only-SQL"><a href="#NoSQL-Not-only-SQL" class="headerlink" title="NoSQL(Not only SQL)"></a>NoSQL(Not only SQL)</h3><p>常用的NoSQL数据库分为：</p>
<ul>
<li>基于列的存储，可扩展性较好，如HBase，Cassandra；</li>
<li>基于文档的存储，数据形式比较灵活，适用于需求变化快速的Web应用程序等场景，如MongoDB、CouchDB；</li>
<li>键值对存储，细分成：单机磁盘型、单机内存型、分布式；</li>
<li>图数据库，如Neo4j；</li>
<li>多模型。</li>
</ul>
<p>参考文献：</p>
<ol>
<li>刘知远.《大数据智能》</li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote class=&quot;blockquote-center&quot;&gt;&lt;p&gt;工欲善其事，必先利其器。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h3&gt;&lt;p&gt;单机计算机的能力是有限的，而需要处理的问题规模不断增加，为此，人们开始探索使用多台计算机组成一个系统进行协调处理。多机系统复杂程度远高于单机系统，多机系统统称分布式系统，为解决分布式系统的可扩展性，可靠性，易用性等问题，方便处理互联网海量数据，控制成本，出现了很多解决方案。本篇笔记简单介绍几种解决方案。&lt;br&gt;
    
    </summary>
    
      <category term="Distributed Systems" scheme="http://www.phoebepan.cn/categories/Distributed-Systems/"/>
    
    
      <category term="Distributed Systems" scheme="http://www.phoebepan.cn/tags/Distributed-Systems/"/>
    
  </entry>
  
  <entry>
    <title>单机安装Spark开发环境</title>
    <link href="http://www.phoebepan.cn/2017/06/07/spark_1/"/>
    <id>http://www.phoebepan.cn/2017/06/07/spark_1/</id>
    <published>2017-06-07T07:30:16.000Z</published>
    <updated>2017-08-13T16:07:43.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote class="blockquote-center"><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>MapReduce在迭代计算和交互计算的任务上表现得效率低下，Spark从一开始就是为交互式查询和迭代算法设计的，同时还支持内存式存储和高效的容错机制，Spark的核心是一个对由很多计算任务组成的、运行在多个工作机器或者是一个计算集群上的应用进行调度、分发以及监控的计算引擎。<br>因Spark支持java、python等语言，尝试安装了python语言环境下的spark开发环境。本篇笔记是win10下配置过程记录。</p>
</blockquote>
<a id="more"></a>
<p>机器：Win10 64bit</p>
<h3 id="jdk安装"><a href="#jdk安装" class="headerlink" title="jdk安装"></a>jdk安装</h3><p>从Oracle网站上下载JDK。我装的<a href="http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html" target="_blank" rel="external">JDK 1.8版本</a>。安装完新建系统环境变量<strong>JAVA_HOME</strong>，值为<code>D:\program files\Java\jdk1.8.0_144</code>(根据自己安装路径来)，系统变量<strong>Path</strong>下添加<code>%JAVA_HOME%\bin</code>和<code>%JAVA_HOME%\jre\bin</code>。</p>
<h3 id="spark环境变量配置"><a href="#spark环境变量配置" class="headerlink" title="spark环境变量配置"></a>spark环境变量配置</h3><p>从<a href="https://spark.apache.org/downloads.html" target="_blank" rel="external">spark网站</a>上下载最新版本spark，我下载的了与Hadoop2.6匹配的spark，文件名spark-2.2.0-bin-hadoop2.6.tgz，将安装文件解压到本地文件夹中（如：D:\spark，<strong>路径中不能有空格</strong>）。将<code>D:\spark\spark-2.2.0-bin-hadoop2.6\bin</code>添加到系统<strong>Path</strong>变量，同时新建<strong>SPARK_HOME</strong>变量，变量值为：<code>D:\spark\spark-2.2.0-bin-hadoop2.6</code>。</p>
<h3 id="hadoop工具包安装"><a href="#hadoop工具包安装" class="headerlink" title="hadoop工具包安装"></a>hadoop工具包安装</h3><p>spark是基于hadoop之上的，运行过程中会调用相关hadoop库，下载hadoop 2.6编译好的包，<a href="https://www.barik.net/archive/2015/01/19/172716/" target="_blank" rel="external">hadoop-2.6.0.tar.gz</a>。将安装文件解压到本地文件夹中(如：D:\program files\hadoop)，系统变量<strong>Path</strong>中添加<code>D:\program files\hadoop\hadoop-2.6.0\bin</code>；新建<strong>HADOOP_HOME</strong>系统变量,值为：<code>D:\program files\hadoop\hadoop-2.6.0</code>。</p>
<h3 id="python下spark开发环境搭建"><a href="#python下spark开发环境搭建" class="headerlink" title="python下spark开发环境搭建"></a>python下spark开发环境搭建</h3><p>将spark目录下的pyspark文件夹(D:\spark\spark-2.2.0-bin-hadoop2.6\python\pyspark)复制到python安装目录(D:\Program Files (x86)\python3\Lib\site-packages)里。</p>
<h3 id="验证spark安装正确性"><a href="#验证spark安装正确性" class="headerlink" title="验证spark安装正确性"></a>验证spark安装正确性</h3><p>cmd中输入：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">d:</div><div class="line">cd D:\spark\spark-2.2.0-bin-hadoop2.6</div><div class="line">bin\spark-shell</div></pre></td></tr></table></figure></p>
<p>运行如下命令启动Spark python shell，<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">d:</div><div class="line">cd D:\spark\spark-2.2.0-bin-hadoop2.6</div><div class="line">bin\pyshark</div></pre></td></tr></table></figure></p>
<p><strong>Tip：</strong>将目录<code>D:\spark\spark-2.2.0-bin-hadoop2.6\bin\pyspark2.cmd</code>的<code>PYSPARK_DRIVER_PYTHON=ipython</code>更改成ipython，就可以用ipython开始交互啦~<br>如果正确，控制台会输出如下信息：<br><img src="/images/success_spark.png" alt="success_spark"></p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote class=&quot;blockquote-center&quot;&gt;&lt;h3 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h3&gt;&lt;p&gt;MapReduce在迭代计算和交互计算的任务上表现得效率低下，Spark从一开始就是为交互式查询和迭代算法设计的，同时还支持内存式存储和高效的容错机制，Spark的核心是一个对由很多计算任务组成的、运行在多个工作机器或者是一个计算集群上的应用进行调度、分发以及监控的计算引擎。&lt;br&gt;因Spark支持java、python等语言，尝试安装了python语言环境下的spark开发环境。本篇笔记是win10下配置过程记录。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Distributed Systems" scheme="http://www.phoebepan.cn/categories/Distributed-Systems/"/>
    
    
      <category term="Distributed Systems" scheme="http://www.phoebepan.cn/tags/Distributed-Systems/"/>
    
      <category term="Spark" scheme="http://www.phoebepan.cn/tags/Spark/"/>
    
  </entry>
  
  <entry>
    <title>数据可视化——Seaborn</title>
    <link href="http://www.phoebepan.cn/2017/06/06/learn_seaborn/"/>
    <id>http://www.phoebepan.cn/2017/06/06/learn_seaborn/</id>
    <published>2017-06-06T07:30:16.000Z</published>
    <updated>2017-06-28T15:14:42.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote class="blockquote-center"><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>EDA过程中，想要更了解你的数据，选择一个合适的可视化工具，可以说会让你的工作事半功倍。<br>本文主要介绍一个以matplotlib作为底层，更易上手的作图库<code>seaborn</code>。</p>
</blockquote>
<a id="more"></a>
<h3 id="Seaborn"><a href="#Seaborn" class="headerlink" title="Seaborn"></a>Seaborn</h3><p>基于matplotlib的可视化库，旨在使默认的数据可视化更加悦目，简化复杂图表创建，可以与pandas很好的集成。</p>
<h3 id="简易用法"><a href="#简易用法" class="headerlink" title="简易用法"></a>简易用法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns <span class="comment">#一旦导入了seaborn，matplotlib的默认作图风格就会被覆盖成seaborn的格式</span></div><div class="line">%matplotlib inline </div><div class="line"><span class="comment">#在jupyter notebook里作图，需要用到这个命令</span></div></pre></td></tr></table></figure>
<h4 id="读取原始数据（这是一份红酒成分与口感评分数据）"><a href="#读取原始数据（这是一份红酒成分与口感评分数据）" class="headerlink" title="读取原始数据（这是一份红酒成分与口感评分数据）"></a>读取原始数据（这是一份红酒成分与口感评分数据）</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">winedata=pd.read_csv(<span class="string">'winequality-red.csv'</span>)</div><div class="line">winedata.head()</div></pre></td></tr></table></figure>
<p><img src="/images/winedata.png" alt="png"></p>
<h4 id="直方图——seaborn-distplot"><a href="#直方图——seaborn-distplot" class="headerlink" title="直方图——seaborn.distplot()"></a><strong>直方图</strong>——seaborn.distplot()</h4><p>如对上面的quality列做直方图，保留概率密度曲线<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">sns.distplot(winedata[<span class="string">'quality'</span>])   <span class="comment"># 不需要概率密度曲线直接将 kde=False 即可</span></div><div class="line">sns.set_style(<span class="string">'dark'</span>)    <span class="comment">#设置背景色</span></div><div class="line">sns.utils.axlabel(<span class="string">'Quality'</span>, <span class="string">'Frequency'</span>) <span class="comment">#设置X,Y坐标名</span></div><div class="line">sns.plt.show()</div></pre></td></tr></table></figure></p>
<p><img src="/images/output_5_0.png" alt="png"></p>
<h4 id="折线图"><a href="#折线图" class="headerlink" title="折线图"></a>折线图</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">sns.factorplot(data=winedata, x=<span class="string">'quality'</span>, y=<span class="string">'total sulfur dioxide'</span>,size=<span class="number">3</span>)</div><div class="line">sns.plt.show()</div></pre></td></tr></table></figure>
<p><img src="/images/output_7_0.png" alt="png"></p>
<h4 id="柱状图——seaborn-barplot"><a href="#柱状图——seaborn-barplot" class="headerlink" title="柱状图——seaborn.barplot()"></a>柱状图——seaborn.barplot()</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">sns.factorplot(data=winedata, x=<span class="string">'quality'</span>, y=<span class="string">'total sulfur dioxide'</span>,kind=<span class="string">'bar'</span>,size=<span class="number">3</span>)</div><div class="line"><span class="comment">#ax = sns.barplot(data=winedata, x='quality', y='total sulfur dioxide',ci=0)</span></div><div class="line">sns.plt.show()</div></pre></td></tr></table></figure>
<p><img src="/images/output_9_0.png" alt="png"></p>
<h4 id="散点图——seaborn-stripplot"><a href="#散点图——seaborn-stripplot" class="headerlink" title="散点图——seaborn.stripplot()"></a>散点图——seaborn.stripplot()</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">temp=sns.FacetGrid(winedata, hue=<span class="string">'quality'</span>, size=<span class="number">3</span>)   <span class="comment">#hue参数设置区分色彩列</span></div><div class="line">temp.map(plt.scatter, <span class="string">'volatile acidity'</span>, <span class="string">'alcohol'</span>)</div><div class="line">temp.add_legend()</div><div class="line">sns.plt.show()</div><div class="line"><span class="comment">#ax = sns.stripplot(x='quality', y='alcohol', data=winedata) #普通散点图</span></div><div class="line"><span class="comment">#ax = sns.stripplot(x='quality', y='alcohol', data=winedata, jitter=True) #带抖动的散点图</span></div><div class="line"><span class="comment">#sns.plt.show()</span></div></pre></td></tr></table></figure>
<p><img src="/images/output_11_0.png" alt="png"></p>
<h4 id="箱型图——seaborn-boxplot"><a href="#箱型图——seaborn-boxplot" class="headerlink" title="箱型图——seaborn.boxplot()"></a>箱型图——seaborn.boxplot()</h4><p>以quality为X轴，alcohol为Y轴，做出箱线图，可以看出异常值<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">ax=sns.boxplot(x=<span class="string">'quality'</span>, y=<span class="string">'alcohol'</span>, data=winedata)</div><div class="line">ax=sns.stripplot(x=<span class="string">'quality'</span>, y=<span class="string">'alcohol'</span>, data=winedata, jitter=<span class="keyword">True</span>, color=<span class="string">'.3'</span>)  <span class="comment">#加上点，jitter=True 使各个散点分开，要不然会是一条直线</span></div><div class="line">sns.plt.show()</div></pre></td></tr></table></figure></p>
<p><img src="/images/output_13_0.png" alt="png"></p>
<h4 id="小提琴图——seaborn-violinplot"><a href="#小提琴图——seaborn-violinplot" class="headerlink" title="小提琴图——seaborn.violinplot()"></a>小提琴图——seaborn.violinplot()</h4><p>可以看出密度分布<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">ax = sns.violinplot(x=<span class="string">'quality'</span>, y=<span class="string">'alcohol'</span>, data=winedata, size=<span class="number">5</span>)</div><div class="line">ax = sns.swarmplot(x=<span class="string">'quality'</span>, y=<span class="string">'alcohol'</span>, data=winedata,color=<span class="string">'.9'</span>)</div><div class="line">sns.plt.show()</div></pre></td></tr></table></figure></p>
<p><img src="/images/output_15_0.png" alt="png"></p>
<h4 id="多变量作图——seaborn-pairplot"><a href="#多变量作图——seaborn-pairplot" class="headerlink" title="多变量作图——seaborn.pairplot()"></a>多变量作图——seaborn.pairplot()</h4><p>seaborn可以一次性两两组合多个变量做出多个对比图，有n个变量，就会做出一个n × n个格子的图，相同的两个变量之间以直方图展示，不同的变量则以散点图展示，<strong>要注意的是数据中不能有NaN（缺失的数据），否则会报错。</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">sns.pairplot(winedata, vars=[<span class="string">'quality'</span>, <span class="string">'residual sugar'</span>,<span class="string">'alcohol'</span>],hue=<span class="string">'quality'</span>)</div><div class="line">sns.plt.show()</div></pre></td></tr></table></figure></p>
<p><img src="/images/output_17_0.png" alt="png"></p>
<h4 id="回归图——seaborn-lmplot-、seaborn-regplot"><a href="#回归图——seaborn-lmplot-、seaborn-regplot" class="headerlink" title="回归图——seaborn.lmplot()、seaborn.regplot()"></a>回归图——seaborn.lmplot()、seaborn.regplot()</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">sns.lmplot(x=<span class="string">'volatile acidity'</span>, y=<span class="string">'alcohol'</span>, data=winedata)   <span class="comment"># hue参数进行分组拟合，markers=['o', 'x']，col参数不同组的子图</span></div><div class="line">sns.plt.show()</div></pre></td></tr></table></figure>
<p><img src="/images/output_19_0.png" alt="png"><br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">sns.regplot(x=<span class="string">'fixed acidity'</span>, y=<span class="string">'alcohol'</span>, data=winedata)</div><div class="line">sns.plt.show()</div></pre></td></tr></table></figure></p>
<p><img src="/images/output_20_0.png" alt="png"></p>
<p><a href="http://seaborn.pydata.org/tutorial.html" target="_blank" rel="external">更多用法参考官方手册</a><br>点这查看本文<a href="https://github.com/phoebepx/normally-accumulate/blob/master/learn_seaborn.ipynb" target="_blank" rel="external">.ipynb文件</a>，欢迎纠错~</p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote class=&quot;blockquote-center&quot;&gt;&lt;h3 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h3&gt;&lt;p&gt;EDA过程中，想要更了解你的数据，选择一个合适的可视化工具，可以说会让你的工作事半功倍。&lt;br&gt;本文主要介绍一个以matplotlib作为底层，更易上手的作图库&lt;code&gt;seaborn&lt;/code&gt;。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Data Visualization" scheme="http://www.phoebepan.cn/categories/Data-Visualization/"/>
    
    
      <category term="ML" scheme="http://www.phoebepan.cn/tags/ML/"/>
    
      <category term="Visualization" scheme="http://www.phoebepan.cn/tags/Visualization/"/>
    
  </entry>
  
  <entry>
    <title>阅读笔记——7 Techniques to Handle Imbalanced Data</title>
    <link href="http://www.phoebepan.cn/2017/06/05/Imbalanced_data/"/>
    <id>http://www.phoebepan.cn/2017/06/05/Imbalanced_data/</id>
    <published>2017-06-05T07:30:16.000Z</published>
    <updated>2017-06-28T15:15:00.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote class="blockquote-center"><p>这篇阅读笔记，主要介绍处理不平衡数据的常见7种方法。所谓<strong>不平衡数据</strong>，指在网络入侵、癌症监测、银行信用卡检测等领域，出现如下图所示的数据集中，正负样本比例严重失调的情况。<br><img src="/images/imbalanced-data-1.png" alt="imbalanced-data-1" title="正负样本分布"></p>
</blockquote>
<a id="more"></a>
<p><a href="http://www.kdnuggets.com/2017/06/7-techniques-handle-imbalanced-data.html" target="_blank" rel="external">博客中</a>介绍了7种方法帮助我们训练一个分类器，来处理这些不平衡的数据。</p>
<h3 id="1-使用正确的评价指标"><a href="#1-使用正确的评价指标" class="headerlink" title="1.使用正确的评价指标"></a>1.使用正确的评价指标</h3><p>针对上图这样的数据集，如果我们还是采用准确度(accuracy)来评估模型训练结果，那么所有的分类器将所有的测试样本都分到“0”这一类，模型准确率无疑非常好，但显然，这样的model对我们来说，是没有价值的。<br>这种情况，其他适宜的评估指标有：<code>Precision/Specificity</code>、<code>Recall/Sensitivity</code>、<code>F1 score</code>、<code>MCC</code>、<code>AUC</code>、<code>G-Mean</code></p>
<h3 id="2-训练集重新采样-Resample"><a href="#2-训练集重新采样-Resample" class="headerlink" title="2.训练集重新采样(Resample)"></a>2.训练集重新采样(Resample)</h3><p>除了使用不同的评价指标，另外可以通过<strong>下采样</strong>和<strong>过采样</strong>在不平衡数据中得到平衡数据集。</p>
<h4 id="下采样-Under-sampling"><a href="#下采样-Under-sampling" class="headerlink" title="下采样(Under-sampling)"></a>下采样(Under-sampling)</h4><p>当数据量充足时，下采样通过减少负样本数量（即多数的类），即保留正样本和随机选择相同数量的负样本，得到新的平衡训练集。</p>
<h4 id="过采样-Over-sampling"><a href="#过采样-Over-sampling" class="headerlink" title="过采样(Over-sampling)"></a>过采样(Over-sampling)</h4><p>当数据量不够时，过采样通过增加正样本数来平衡数据集，可以采用<code>repetition</code>、<code>bootstrapping</code>、<code>SMOTE</code>得到新的正样本。<br><a href="https://github.com/scikit-learn-contrib/imbalanced-learn" target="_blank" rel="external">Python实现</a></p>
<p>下采样和过采样两者之间没有谁优谁劣，具体用哪种方式取决于数据集本身，有时两者结合使用可能效果更好。</p>
<h3 id="3-正确使用K折交叉验证"><a href="#3-正确使用K折交叉验证" class="headerlink" title="3.正确使用K折交叉验证"></a>3.正确使用K折交叉验证</h3><p>值得注意的是，当我们用过采样处理不平衡训练集时，通常需要在<strong>过采样之前应用交叉验证</strong>，这样做的好处就是避免模型过拟合。</p>
<h4 id="过拟合产生原因："><a href="#过拟合产生原因：" class="headerlink" title="过拟合产生原因："></a>过拟合产生原因：</h4><ul>
<li>模型的复杂度越高，越容易overfitting</li>
<li>数据的噪声越大，越容易overfitting</li>
<li>数据量越少，越容易overfitting</li>
</ul>
<h3 id="4-重采样训练集集成-Ensemble"><a href="#4-重采样训练集集成-Ensemble" class="headerlink" title="4.重采样训练集集成(Ensemble)"></a>4.重采样训练集集成(Ensemble)</h3><p><img src="/images/imbalanced-data-2.png" alt="imbalanced-data-2" title="Ensemble different resampled datasets"><br>如上面示例图所示，使用所有的正样本和 n 个不同的负样本建立 n 个models。比如你想得到10个models，如果正样本是1000个，那么你需要随机选择10000个负样本，然后将这10000个负样本分成10份，接下来训练这10个不同的models。<br>这种方法，简单方便，易扩展，更好的泛化能力。</p>
<h3 id="5-不同比例采样"><a href="#5-不同比例采样" class="headerlink" title="5.不同比例采样"></a>5.不同比例采样</h3><p>之前的方法，都是1:1调和样本，最佳的比例取决于数据和使用的模型。与其对所有models使用同样的比例进行ensemble，更值得尝试的是采用不同的比例进行ensemble。正如下图所示：<br><img src="/images/imbalanced-data-3.png" alt="imbalanced-data-3" title="Resample with different ratios"></p>
<h3 id="6-负样本进行聚类"><a href="#6-负样本进行聚类" class="headerlink" title="6.负样本进行聚类"></a>6.负样本进行聚类</h3><p>Sergey在Quora上提出一个更完美的<a href="www.quora.com/In-classification-how-do-you-handle-an-unbalanced-training-set/answers/1144228?srid=h3G6o">方法</a>，对负样本进行聚类，只用负样本聚类的簇中心和正样本组成训练集。</p>
<h3 id="7-自己设计模型"><a href="#7-自己设计模型" class="headerlink" title="7.自己设计模型"></a>7.自己设计模型</h3><p>事实上，已经有一些models本身就可以处理非平衡数据集，无需进行重新采样，如XGBoost。<br>重设损失函数，比起负样本误分，对正样本误分设置更大的惩罚系数。</p>
<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>这些处理方法只是一个起点，没有一种方法可以解决所有问题，<code>多试才是王道</code>！</p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote class=&quot;blockquote-center&quot;&gt;&lt;p&gt;这篇阅读笔记，主要介绍处理不平衡数据的常见7种方法。所谓&lt;strong&gt;不平衡数据&lt;/strong&gt;，指在网络入侵、癌症监测、银行信用卡检测等领域，出现如下图所示的数据集中，正负样本比例严重失调的情况。&lt;br&gt;&lt;img src=&quot;/images/imbalanced-data-1.png&quot; alt=&quot;imbalanced-data-1&quot; title=&quot;正负样本分布&quot;&gt;&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Machine Learning" scheme="http://www.phoebepan.cn/categories/Machine-Learning/"/>
    
    
      <category term="ML" scheme="http://www.phoebepan.cn/tags/ML/"/>
    
      <category term="Reading" scheme="http://www.phoebepan.cn/tags/Reading/"/>
    
  </entry>
  
  <entry>
    <title>python——DFS+BFS</title>
    <link href="http://www.phoebepan.cn/2017/06/03/max_depth/"/>
    <id>http://www.phoebepan.cn/2017/06/03/max_depth/</id>
    <published>2017-06-03T07:30:16.000Z</published>
    <updated>2017-08-08T15:32:50.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote class="blockquote-center"><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>本篇笔记主要记录，运用DFS或BFS算法求解二叉树最大深度问题。</p>
</blockquote>
<a id="more"></a>
<h3 id="二叉树最大深度"><a href="#二叉树最大深度" class="headerlink" title="二叉树最大深度"></a>二叉树最大深度</h3><p> 题目来源：<a href="https://leetcode.com/problems/maximum-depth-of-binary-tree/description/" target="_blank" rel="external">LeeCode104: Maximum Depth of Binary Tree</a></p>
<h3 id="解法一"><a href="#解法一" class="headerlink" title="解法一"></a>解法一</h3><p>DFS(递归)<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Definition for a binary tree node.</span></div><div class="line"><span class="comment"># class TreeNode(object):</span></div><div class="line"><span class="comment">#     def __init__(self, x):</span></div><div class="line"><span class="comment">#         self.val = x</span></div><div class="line"><span class="comment">#         self.left = None</span></div><div class="line"><span class="comment">#         self.right = None</span></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">maxDepth</span><span class="params">(self, root)</span>:</span></div><div class="line">        <span class="string">"""</span></div><div class="line">        :type root: TreeNode</div><div class="line">        :rtype: int</div><div class="line">        """</div><div class="line">        <span class="keyword">return</span> <span class="number">1</span>+max(self.maxDepth(root.left),self.maxDepth(root.right)) <span class="keyword">if</span> root <span class="keyword">else</span> <span class="number">0</span></div></pre></td></tr></table></figure></p>
<h3 id="解法二"><a href="#解法二" class="headerlink" title="解法二"></a>解法二</h3><p>BFS、队列<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Definition for a binary tree node.</span></div><div class="line"><span class="comment"># class TreeNode(object):</span></div><div class="line"><span class="comment">#     def __init__(self, x):</span></div><div class="line"><span class="comment">#         self.val = x</span></div><div class="line"><span class="comment">#         self.left = None</span></div><div class="line"><span class="comment">#         self.right = None</span></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">maxDepth</span><span class="params">(self, root)</span>:</span></div><div class="line">        <span class="string">"""</span></div><div class="line">        :type root: TreeNode</div><div class="line">        :rtype: int</div><div class="line">        """</div><div class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root:</div><div class="line">            <span class="keyword">return</span> <span class="number">0</span></div><div class="line">        queue,h=[root],<span class="number">0</span></div><div class="line">        <span class="keyword">while</span> queue:</div><div class="line">            h+=<span class="number">1</span></div><div class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,len(queue)):</div><div class="line">                node=queue.pop(<span class="number">0</span>)</div><div class="line">                queue.extend(filter(<span class="keyword">None</span>,[node.left,node.right]))</div><div class="line">        <span class="keyword">return</span> h</div></pre></td></tr></table></figure></p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote class=&quot;blockquote-center&quot;&gt;&lt;h3 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h3&gt;&lt;p&gt;本篇笔记主要记录，运用DFS或BFS算法求解二叉树最大深度问题。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Algorithms" scheme="http://www.phoebepan.cn/categories/Algorithms/"/>
    
    
      <category term="LeetCode" scheme="http://www.phoebepan.cn/tags/LeetCode/"/>
    
      <category term="Algorithms" scheme="http://www.phoebepan.cn/tags/Algorithms/"/>
    
      <category term="Python" scheme="http://www.phoebepan.cn/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>降维——PCA和LDA</title>
    <link href="http://www.phoebepan.cn/2017/06/02/pca_lda/"/>
    <id>http://www.phoebepan.cn/2017/06/02/pca_lda/</id>
    <published>2017-06-02T07:30:16.000Z</published>
    <updated>2017-08-08T15:08:30.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote class="blockquote-center"><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>所有机器学习方法共同面临的，在高维情况下出现的数据样本稀疏、距离计算困难等问题，被称为“维度灾难”，李航老师在他的博客《机器学习新动向：从人机交互中》中提到，学习精度越高，学习确信度越高，学习模型越复杂，所需要的样本也就越多。特征太多会造成模型复杂，缓解这一问题的一个重要途径是<strong>降维</strong>，将原高维空间中的数据点映射到低维的空间。</p>
</blockquote>
<a id="more"></a>
<h3 id="降维"><a href="#降维" class="headerlink" title="降维"></a>降维</h3><p>原始高维空间数据表示中包含冗余以及噪音信息，而降低准确率，通过降维减少冗余信息，提高精度。基于线性变换来进行降维的方法称为线性降维方法，通过对变换矩阵施加不同的约束，对低维子空间的性质的不同要求，可以得到多种线性降维方法。<br>对降维效果的<strong>评估</strong>，通常是比较降维前后学习器的性能，若性能有所提高，则认为降维起作用了。若维度降至二或三维，则可以通过可视化技术直观地判断降维效果。</p>
<h3 id="PCA"><a href="#PCA" class="headerlink" title="PCA"></a>PCA</h3><p>目标：逐个寻找超平面，将样本投射到这个超平面后使得各样本点间方差最大。</p>
<blockquote>
<p>若存在这样的超平面，那么它大概要具有的性质：<br><strong>最近重构性</strong>，样本点到这个超平面的距离都足够近；<br><strong>最大可分性</strong>，样本点在这个超平面上的投影能尽可能分开。</p>
</blockquote>
<p>PCA追求的是在降维后能够最大化保持数据内在信息，并通过衡量在投影方向上的数据方差的大小来衡量该方向的重要性。</p>
<p>算法：</p>
<hr>
<p>输入：样本数据集D={x<sub>1</sub>,x<sub>2</sub>,…,x<sub>m</sub>};<br>: 低维空间维度d’ </p>
<p>输出：变换矩阵W=(w<sub>1</sub>,w<sub>2</sub>,…,w<sub>d’</sub>)<br>过程：</p>
<ol>
<li>对所有样本进行中心化；</li>
<li>计算样本的协方差矩阵XX<sup>T</sup>；</li>
<li>对协方差矩阵XX<sup>T</sup>做特征值分解；</li>
<li>取最大的d’个特征值所对应的特征向量w<sub>1</sub>,w<sub>2</sub>,…,w<sub>d’</sub>.</li>
</ol>
<hr>
<blockquote>
<p><strong>决定降维维度/主成分个数</strong><br>用户指定；<br>重构角度设定阈值；<br>不同d’维空间+学习器(开销较小)进行交叉验证选取；</p>
</blockquote>
<p><code>不要盲目PCA，当在原数据有了一个比较好的结果，想进一步提升速度时可考虑PCA。</code></p>
<h3 id="LDA"><a href="#LDA" class="headerlink" title="LDA"></a>LDA</h3><p>目标：找到一个超平面，样本点映射在超平面使得相同类别点尽可能靠近，不同类别数据尽可能远。</p>
<p>PCA是无监督线性降维方法，LDA是有监督的线性降维方法。</p>
<p>区别：如下图中两堆点是两类的话，LDA会选择轴1，PCA会是轴2<br><img src="/images/pca.jpg" alt="pca"></p>
<h3 id="核化线性降维"><a href="#核化线性降维" class="headerlink" title="核化线性降维"></a>核化线性降维</h3><p>非线性降维常用的方法，是基于核技巧对线性降维方法进行“核化”，将原数据映射到高维特征空间，再在特征空间实施降维。</p>
<p>参考文献：</p>
<ol>
<li>李航，<a href="http://blog.sina.com.cn/s/blog_7ad48fee01016d25.html" target="_blank" rel="external">《机器学习新动向：从人机交互中》</a></li>
<li>周志华，《机器学习》</li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote class=&quot;blockquote-center&quot;&gt;&lt;h3 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h3&gt;&lt;p&gt;所有机器学习方法共同面临的，在高维情况下出现的数据样本稀疏、距离计算困难等问题，被称为“维度灾难”，李航老师在他的博客《机器学习新动向：从人机交互中》中提到，学习精度越高，学习确信度越高，学习模型越复杂，所需要的样本也就越多。特征太多会造成模型复杂，缓解这一问题的一个重要途径是&lt;strong&gt;降维&lt;/strong&gt;，将原高维空间中的数据点映射到低维的空间。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Machine Learning" scheme="http://www.phoebepan.cn/categories/Machine-Learning/"/>
    
    
      <category term="ML" scheme="http://www.phoebepan.cn/tags/ML/"/>
    
  </entry>
  
  <entry>
    <title>稀疏表示与字典学习</title>
    <link href="http://www.phoebepan.cn/2017/06/01/SpaseL/"/>
    <id>http://www.phoebepan.cn/2017/06/01/SpaseL/</id>
    <published>2017-06-01T07:30:16.000Z</published>
    <updated>2017-08-03T23:07:13.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="稀疏表示"><a href="#稀疏表示" class="headerlink" title="稀疏表示"></a>稀疏表示</h3><p>文档分类时，每个文档当作一个样本，文档中的每个词作为一个特征，这往往会得到很高维的矩阵，而且矩阵中每一行都有大量的零元素，且每行零元素出现的列分布不同，具有这样的<strong>稀疏表达</strong>形式的矩阵，对学习任务来说是有好处的(可以当做线性可分问题处理)。<br><a id="more"></a></p>
<h3 id="字典学习"><a href="#字典学习" class="headerlink" title="字典学习"></a>字典学习</h3><p>如果将稠密的数据集转化成<strong>稀疏表示</strong>形式，使得数据集<strong>“恰当稀疏”</strong>，从而享受稀疏性的好处。那么问题来了，如何实现这种转化呢？<br>在上面的文本分类中提到的矩阵，常常是高维的，过度稀疏的，如果我们借鉴下“字典”的结构，将字的特征维度根据字典转化成合适的稀疏特征表示形式，就可以简化学习任务，模型复杂度大大降低，这样的过程称为<strong>“字典学习”</strong>。字典学习形式如下，<img src="/images/spase.png" alt="spase"><br>，样本x<sub>i</sub>通过字典矩阵B得到的稀疏表示$ \alpha $<sub>i</sub>。我们可以通过设置字典的维度，从而控制稀疏程度。<br>求解过程有很多，常用的有KSVD等</p>
<h3 id="压缩感知"><a href="#压缩感知" class="headerlink" title="压缩感知"></a>压缩感知</h3><p>我们常常希望根据部分信息来恢复全部信息，如，数据通信中要将数字信号还原成模拟信号，部分用户对电影的评价数据等，如何精确的重构出这样的信息呢？<br>针对这类问题，压缩感知提供了新的思路。<br>压缩感知关注的是如何利用数据本身的所具有的稀疏性，从部分观测样本中恢复原来缺失的信息。主要涉及两个过程，<strong>稀疏表示</strong>、<strong>矩阵补全</strong>。能够通过压缩感知技术恢复补全信息的前提条件之一是原始数据(部分信息)有稀疏表示。</p>
<h4 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h4><p>人脸识别的鲁棒主成分分析、基于矩阵补全的协同过滤……</p>
<p>[1]. 周志华.《机器学习》</p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;稀疏表示&quot;&gt;&lt;a href=&quot;#稀疏表示&quot; class=&quot;headerlink&quot; title=&quot;稀疏表示&quot;&gt;&lt;/a&gt;稀疏表示&lt;/h3&gt;&lt;p&gt;文档分类时，每个文档当作一个样本，文档中的每个词作为一个特征，这往往会得到很高维的矩阵，而且矩阵中每一行都有大量的零元素，且每行零元素出现的列分布不同，具有这样的&lt;strong&gt;稀疏表达&lt;/strong&gt;形式的矩阵，对学习任务来说是有好处的(可以当做线性可分问题处理)。&lt;br&gt;
    
    </summary>
    
      <category term="Machine Learning" scheme="http://www.phoebepan.cn/categories/Machine-Learning/"/>
    
    
      <category term="ML" scheme="http://www.phoebepan.cn/tags/ML/"/>
    
  </entry>
  
  <entry>
    <title>神经网络</title>
    <link href="http://www.phoebepan.cn/2017/05/25/neural%20network/"/>
    <id>http://www.phoebepan.cn/2017/05/25/neural network/</id>
    <published>2017-05-25T07:30:16.000Z</published>
    <updated>2017-08-08T15:38:08.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote class="blockquote-center"><p>神经网络是由具有适应性的简单单元组成的广泛并行互连的网络，它的组织能够模拟生物神经系统对真实世界物体所作出的交互反应。<br>——Kohonen</p>
</blockquote>
<a id="more"></a>
<h3 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h3><h4 id="神经元模型"><a href="#神经元模型" class="headerlink" title="神经元模型"></a>神经元模型</h4><blockquote>
<p>如下图，<strong>M-P神经元模型</strong></p>
<ul>
<li>连接权重</li>
<li>阈值</li>
<li>激活函数</li>
</ul>
</blockquote>
<p><img src="/images/MP_model.jpg" alt="MP_model"></p>
<h4 id="学习过程"><a href="#学习过程" class="headerlink" title="学习过程"></a>学习过程</h4><p>根据训练集来调整神经元之间的”连接权”以及每个功能神经元的阈值。</p>
<h4 id="感知机与多层网络"><a href="#感知机与多层网络" class="headerlink" title="感知机与多层网络"></a>感知机与多层网络</h4><p><strong>感知机</strong>由两层神经元组成，输入层接收输入信号后传递给输出层，输出层是M-P神经元，可处理<strong>线性可分数据集</strong>。</p>
<p><strong>多层网络</strong>，在输入层与输出层增加隐含层(一个或多个)，隐含层和输出层神经元都是拥有激活函数的功能神经元。</p>
<h4 id="误差逆传播-BP-算法"><a href="#误差逆传播-BP-算法" class="headerlink" title="误差逆传播(BP)算法"></a>误差逆传播(BP)算法</h4><p>迭代学习算法，基于梯度下降策略，以目标的负梯度方向对参数进行调整。</p>
<blockquote>
<p><strong>标准BP和累积BP</strong><br>标准BP，每次更新只针对单个样例，参数更新频繁；<br>累积BP，读取整个数据集后才对参数进行一次更新。</p>
</blockquote>
<p><strong>缓解BP过拟合的策略</strong></p>
<ul>
<li>早停，训练误差降低，验证误差升高，停止训练；</li>
<li>正则化，增加描述网络复杂度项(连接权与阈值的平方和)，交叉验证来估计。</li>
</ul>
<h3 id="全局最小和局部极小"><a href="#全局最小和局部极小" class="headerlink" title="全局最小和局部极小"></a>全局最小和局部极小</h3><p><code>参数寻优</code></p>
<h4 id="跳出局部最小策略"><a href="#跳出局部最小策略" class="headerlink" title="跳出局部最小策略"></a>跳出局部最小策略</h4><ul>
<li>多组不同参数值初始化多个神经网路，训练，选择更接近全局最小的结果；</li>
<li>模拟退火，每一步以一定概率接受比当前解更差的结果；</li>
<li>随机梯度下降，计算梯度时加入随机因素。</li>
</ul>
<h3 id="常见的神经网路"><a href="#常见的神经网路" class="headerlink" title="常见的神经网路"></a>常见的神经网路</h3><h4 id="RBF"><a href="#RBF" class="headerlink" title="RBF"></a>RBF</h4><ul>
<li>单隐层前馈神经网路</li>
<li>径向基函数作为隐层神经元激活函数</li>
<li>输出层对隐层神经元输出进行线性组合</li>
</ul>
<h4 id="ART"><a href="#ART" class="headerlink" title="ART"></a>ART</h4><p><code>胜者通吃</code>、<code>竞争型学习</code>、<code>无监督学习</code>、<code>增量学习</code></p>
<blockquote>
<p>比较层(输入)、识别层(模式)、<strong>识别阈值</strong>、重置模块；</p>
<blockquote>
<p> 当识别阈值较高，学习更细；较低，产生粗略的模式类。</p>
</blockquote>
</blockquote>
<h4 id="SOM"><a href="#SOM" class="headerlink" title="SOM"></a>SOM</h4><p>高维空间相似的样本点映射到网络输出层中的邻近神经元。<br>在聚类、高维数据可视化、图像分割中广泛应用。</p>
<h4 id="级联相关网络"><a href="#级联相关网络" class="headerlink" title="级联相关网络"></a>级联相关网络</h4><p><code>结构自适应网络</code><br>数据较少时易过拟合。</p>
<h4 id="Elman网络"><a href="#Elman网络" class="headerlink" title="Elman网络"></a>Elman网络</h4><p><code>递归神经网络</code>、<code>环型结构</code></p>
<h4 id="Boltzmann机"><a href="#Boltzmann机" class="headerlink" title="Boltzmann机"></a>Boltzmann机</h4><p><code>完全图</code></p>
<h4 id="RBM"><a href="#RBM" class="headerlink" title="RBM"></a>RBM</h4><p>受限Boltzmann机，<code>二部图</code></p>
<h3 id="深度学习"><a href="#深度学习" class="headerlink" title="深度学习"></a>深度学习</h3><p><code>多隐层神经网络</code>(通常有八九层隐层)<br>训练手段，有以下两种：</p>
<h4 id="无监督逐层训练"><a href="#无监督逐层训练" class="headerlink" title="无监督逐层训练"></a>无监督逐层训练</h4><p>预训练+微调</p>
<blockquote>
<p>大量参数分组，对每组先找到局部较好设置，在基于局部较优结果联合起来进行全局寻优。</p>
</blockquote>
<h4 id="权共享"><a href="#权共享" class="headerlink" title="权共享"></a>权共享</h4><p>每一组神经元使用相同的连接权。</p>
<blockquote>
<p>卷积神经网络CNN</p>
</blockquote>
<p>参考文献</p>
<ol>
<li>周志华，《机器学习》</li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote class=&quot;blockquote-center&quot;&gt;&lt;p&gt;神经网络是由具有适应性的简单单元组成的广泛并行互连的网络，它的组织能够模拟生物神经系统对真实世界物体所作出的交互反应。&lt;br&gt;——Kohonen&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Machine Learning" scheme="http://www.phoebepan.cn/categories/Machine-Learning/"/>
    
    
      <category term="ML" scheme="http://www.phoebepan.cn/tags/ML/"/>
    
  </entry>
  
  <entry>
    <title>机器学习经典算法优缺点总结</title>
    <link href="http://www.phoebepan.cn/2017/05/23/ML_good_bad/"/>
    <id>http://www.phoebepan.cn/2017/05/23/ML_good_bad/</id>
    <published>2017-05-23T07:30:16.000Z</published>
    <updated>2017-08-03T22:56:04.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote class="blockquote-center"><p>简介<br>机器学习大多数场景是搜索、广告、垃圾过滤、安全、推荐系统等等。本文是经典机器学习算法的优劣势比较，欢迎纠正。</p>
</blockquote>
<a id="more"></a>
<h3 id="朴素贝叶斯"><a href="#朴素贝叶斯" class="headerlink" title="朴素贝叶斯"></a>朴素贝叶斯</h3><p><code>生成模型</code>、<code>贝叶斯定理</code>、<code>特征条件独立</code>、<code>后验概率最大化</code></p>
<h4 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h4><blockquote>
<p>基于贝叶斯定理与特征条件独立假设的分类方法。对于给定的训练集首先基于特征条件独立假设学习输入/输出的联合概率分布，然后利用贝叶斯定理求出后验概率最大。</p>
</blockquote>
<h4 id="解决问题-适用场景"><a href="#解决问题-适用场景" class="headerlink" title="解决问题(适用场景)"></a>解决问题(适用场景)</h4><blockquote>
<p>分类问题<br>场景举例：文本主题分类、垃圾文本过滤</p>
</blockquote>
<h4 id="技术细节"><a href="#技术细节" class="headerlink" title="技术细节"></a>技术细节</h4><blockquote>
<p>概率估计方法：极大似然估计和贝叶斯估计(拉普拉斯平滑)</p>
</blockquote>
<h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><blockquote>
<p>实现简单；对小规模数据表现很好，适合多分类任务；适合增量式训练</p>
</blockquote>
<h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4><blockquote>
<p>对输入数据表达形式敏感(离散、连续、值极大极小等)；需要条件独立假设，会牺牲准确率，分类性能不一定高</p>
</blockquote>
<h3 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h3><p><code>对数线性模型</code>、<code>似然函数为目标函数</code>、<code>最优化问题</code></p>
<h4 id="原理-1"><a href="#原理-1" class="headerlink" title="原理"></a>原理</h4><blockquote>
<p>主要计算在某个样本特征下事件发生的概率。用sigmoid函数将线性回归进行了归一化，输出值压缩到0-1之间，这个值代表的是发生的概率。</p>
</blockquote>
<h4 id="解决问题-适用场景-1"><a href="#解决问题-适用场景-1" class="headerlink" title="解决问题(适用场景)"></a>解决问题(适用场景)</h4><blockquote>
<p>分类问题(二分类推广到多分类)<br>场景举例：根据用户浏览情况预测是否购买商品</p>
</blockquote>
<h4 id="技术细节-1"><a href="#技术细节-1" class="headerlink" title="技术细节"></a>技术细节</h4><blockquote>
<ul>
<li>LogReg中，输出Y=1的对数几率是输入x的线性函数；</li>
<li>极大似然估计法估计模型参数；</li>
<li>softmax和k个LR的选择，<strong>类别之间互斥，softmax</strong>、类别之前有联系，K个LR</li>
<li>优化：梯度下降、拟牛顿法、BFGS、改进的迭代尺度法<br>梯度下降会陷入局部最优，改用随机梯度下降，收敛速度更快，且易并行。</li>
</ul>
</blockquote>
<h4 id="优点-1"><a href="#优点-1" class="headerlink" title="优点"></a>优点</h4><blockquote>
<p>简单高效；概率值输出；多重共线性可以通过L2正则化应对</p>
</blockquote>
<h4 id="缺点-1"><a href="#缺点-1" class="headerlink" title="缺点"></a>缺点</h4><blockquote>
<p>欠拟合，精度不高；<br>必须线性可分；<br>特征空间太大时表现不太好；<br>大量分类变量性能较差；</p>
</blockquote>
<h3 id="k-近邻"><a href="#k-近邻" class="headerlink" title="k-近邻"></a>k-近邻</h3><p><code>判别模型</code>、<code>多分类与回归</code>、<code>不具有显式学习过程</code></p>
<h4 id="原理-2"><a href="#原理-2" class="headerlink" title="原理"></a>原理</h4><blockquote>
<p>利用训练数据集对特征向量空间进行划分，根据k个最近邻的训练样本的类别，通过多数表决进行预测。</p>
</blockquote>
<h4 id="解决问题-适用场景-2"><a href="#解决问题-适用场景-2" class="headerlink" title="解决问题(适用场景)"></a>解决问题(适用场景)</h4><blockquote>
<p>分类与回归</p>
</blockquote>
<h4 id="技术细节-2"><a href="#技术细节-2" class="headerlink" title="技术细节"></a>技术细节</h4><blockquote>
<p>三要素：K的选择、距离度量、决策规则</p>
<blockquote>
<p><strong>交叉验证，取最优k值</strong><br>K小，模型变得复杂，过拟合；估计误差增大；<br>K大，模型变得简单，近似误差增大</p>
</blockquote>
<p><strong>kd 树</strong></p>
<blockquote>
<p>X的K个特征，一一个切分，使得每个数据最终都在切分点上(中位数)，对输入的数据搜索kd树，找到K近邻。</p>
</blockquote>
</blockquote>
<h4 id="优点-2"><a href="#优点-2" class="headerlink" title="优点"></a>优点</h4><blockquote>
<p>简单，分类与回归，可用于非线性，复杂度为O(n)，对噪声不敏感</p>
</blockquote>
<h4 id="缺点-2"><a href="#缺点-2" class="headerlink" title="缺点"></a>缺点</h4><blockquote>
<p>K需要人为设定，对大小不平衡数据易偏向大容量数据；计算量大，大量内存</p>
</blockquote>
<h3 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h3><p><code>判别模型</code>、<code>多分类与回归</code>、<code>正则化的极大似然估计</code></p>
<h4 id="原理-3"><a href="#原理-3" class="headerlink" title="原理"></a>原理</h4><blockquote>
<p>决策树实际上是将空间用超平面进行划分的一种方法，每次分割的时候，都将当前的空间一分为二，这样使得每一个叶子节点都是在空间中的一个不相交的区域，在进行决策的时候，会根据输入样本每一维feature的值，一步一步往下，最后使得样本落入N个区域中的一个。</p>
</blockquote>
<h4 id="解决问题-适用场景-3"><a href="#解决问题-适用场景-3" class="headerlink" title="解决问题(适用场景)"></a>解决问题(适用场景)</h4><blockquote>
<p>适用于小数据集<br>场景举例：基于规则的信用评估</p>
</blockquote>
<h4 id="技术细节-3"><a href="#技术细节-3" class="headerlink" title="技术细节"></a>技术细节</h4><blockquote>
<p><strong>特征选择</strong>准则：信息增益或信息增益比<br><strong>决策树生成</strong>，ID3、C4.5、CART(Gini index，平方误差)<br><strong>剪枝</strong>，减小模型复杂度，设定$ \alpha $ ，相当于正则化的极大似然估计；动态规划实现</p>
<blockquote>
<p><strong>CART</strong><br>通过递归方式建立决策二叉树，基尼指数最小化的特征(分类)，平方误差最小化(回归)作为划分特征</p>
</blockquote>
</blockquote>
<h4 id="优点-3"><a href="#优点-3" class="headerlink" title="优点"></a>优点</h4><blockquote>
<p>训练时间复杂度低，预测过程快速；可读性好；适合处理有缺失属性值得样本，能够处理不相关特征</p>
</blockquote>
<h4 id="缺点-3"><a href="#缺点-3" class="headerlink" title="缺点"></a>缺点</h4><blockquote>
<p>容易过拟合</p>
<blockquote>
<p>解决过拟合：剪枝、交叉验证、随机森林</p>
</blockquote>
<p>单棵树分类能力弱，对连续变量难以处理</p>
</blockquote>
<h3 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h3><p><code>判别模型</code>、<code>多分类与回归</code>、<code>正则化的极大似然估计</code>、<code>Random Future</code>、<code>Bagging</code></p>
<h4 id="原理-4"><a href="#原理-4" class="headerlink" title="原理"></a>原理</h4><blockquote>
<p>很多随机生成的决策树组成，预测时，每颗决策树进行判断，最后通过Bagging思想进行结果的输出。<br>RF被证明对大规模数据集和存在大量且有时不相关特征的项来说很有用。</p>
</blockquote>
<h4 id="解决问题-适用场景-4"><a href="#解决问题-适用场景-4" class="headerlink" title="解决问题(适用场景)"></a>解决问题(适用场景)</h4><blockquote>
<p>场景举例：用户流失分析、风险评估、检测离群点</p>
</blockquote>
<h4 id="技术细节-4"><a href="#技术细节-4" class="headerlink" title="技术细节"></a>技术细节</h4><blockquote>
<p>行(有放回)列(节点分裂时)采样，每个决策树使用相同参数<br>完全分裂，叶节点特征(样本特征相同、样本类别相同、样本数=1)<br>超参：树的数量、列采样特征数(通常取总特征的平方根)<br>泛化误差估计，oob(out-of-bag)</p>
</blockquote>
<h4 id="优点-4"><a href="#优点-4" class="headerlink" title="优点"></a>优点</h4><blockquote>
<ol>
<li>适合多分类问题，训练和预测速度快</li>
<li>对训练数据容错能力强，有效的估计缺失数据的方法</li>
<li>可以处理高维数据且不用特征选择</li>
<li>训练过程中检测到特征间相互影响及特征重要性</li>
<li>数据集上表现良好，避免过拟合</li>
<li>实现简单且容易并行化</li>
<li>在创建随机森林的时候，对generlization error使用的是无偏估计，所以在随机森林算法中不需要再进行交叉验证或者单独的测试集来获取测试集误差的无偏估计</li>
</ol>
</blockquote>
<h4 id="缺点-4"><a href="#缺点-4" class="headerlink" title="缺点"></a>缺点</h4><blockquote>
<p>噪声较大的分类和回归问题上会过拟合。对于类别特征的属性值较多时，RF产生的属性权重不可信。</p>
</blockquote>
<h3 id="支持向量机"><a href="#支持向量机" class="headerlink" title="支持向量机"></a>支持向量机</h3><p><code>间隔最大</code>、<code>凸二次规划</code>、<code>核函数</code></p>
<h4 id="原理-5"><a href="#原理-5" class="headerlink" title="原理"></a>原理</h4><blockquote>
<p>低维空间映射到高维空间，实现线性可分，求解正确划分训练集并(几何)间隔最大化的分离超平面。</p>
</blockquote>
<h4 id="技术细节-5"><a href="#技术细节-5" class="headerlink" title="技术细节"></a>技术细节</h4><blockquote>
<p>函数间隔，几何间隔<br>应用拉格朗日对偶性，求解对偶问题(更易求解、自然引用核函数)<br>正则化的合页损失函数最优化问题<br>核函数</p>
<blockquote>
<p>表示将输入从输入空间映射到特征空间得到的特征向量之间的内积。</p>
</blockquote>
<p>序列最小最优化算法(不断分解，对子问题求解，每个子问题中选择两个变量优化，其中一个变量是违反KKT条件的，直到所有变量都满足KKT条件为止)</p>
</blockquote>
<h4 id="优点-5"><a href="#优点-5" class="headerlink" title="优点"></a>优点</h4><blockquote>
<p>可以处理高维特征；使用核函数可以向高维空间进行映射，可以解决非线性分类；分类思想简单(间隔最大化)；分类效果好</p>
</blockquote>
<h4 id="缺点-5"><a href="#缺点-5" class="headerlink" title="缺点"></a>缺点</h4><blockquote>
<p>核函数及参数敏感；无法直接支持多分类；大量观测样本，效率低</p>
</blockquote>
<h3 id="集成学习"><a href="#集成学习" class="headerlink" title="集成学习"></a>集成学习</h3><h4 id="关键点"><a href="#关键点" class="headerlink" title="关键点"></a>关键点</h4><ol>
<li><code>差异性基分类器</code>:数据集(bagging、boosting)、数据特征、改变基分类器参数</li>
<li><code>基分类器整合</code>，回归(简单平均、加权平均)、分类(简单/加权投票、概率投票)</li>
</ol>
<p><code>Notes</code>：分类问题，每个分类器的分类精度大于0.5</p>
<h3 id="Boosting"><a href="#Boosting" class="headerlink" title="Boosting"></a>Boosting</h3><p><code>三个臭皮匠顶个诸葛亮</code>、<code>改变样本权重</code>、<code>分而治之</code>、<code>加法模型</code>、<code>前向分布算法</code>、<code>Shrinkage</code></p>
<h4 id="原理-6"><a href="#原理-6" class="headerlink" title="原理"></a>原理</h4><blockquote>
<p>在分类问题中，通过改变训练样本的权重，学习多个基分类器，最终进行线性组合。</p>
</blockquote>
<h4 id="技术细节-6"><a href="#技术细节-6" class="headerlink" title="技术细节"></a>技术细节</h4><blockquote>
<p>概念强可学习充要条件概念弱可学习</p>
<blockquote>
<ul>
<li>AdaBoost，提高前一轮弱分类器错分的<strong>样本权重</strong>，降低分对的样本权重；<strong>组合</strong>时，加大分类错误率低的基分类器权值，减小分类错误率大的权重。</li>
<li>AdaBoost二分类学习时是加法模型、损失函数为指数函数、学习算法为前向分布算法</li>
</ul>
</blockquote>
<p>boosting tree<br>基分类器，分类树或回归树，不同的问题的提升树主要区别在于<strong>损失函数</strong>不同。</p>
<blockquote>
<ul>
<li>梯度提升(gradient boosting)，每一轮计算为了减少上一次的残差，加入新的model是在之前model损失函数梯度下降方向。</li>
<li>GBDT精髓，在于训练都以上一棵树的残差为目标去提升。</li>
</ul>
</blockquote>
<p>调参：树的个数、树深度、学习速率、叶子上最大节点树、训练采样比例、训练特征采样比例……</p>
</blockquote>
<h4 id="优点-6"><a href="#优点-6" class="headerlink" title="优点"></a>优点</h4><blockquote>
<p>精度高；能处理非线性数据；能处理多特征类型；适合低维稠密数据</p>
</blockquote>
<h4 id="缺点-6"><a href="#缺点-6" class="headerlink" title="缺点"></a>缺点</h4><blockquote>
<p>并行麻烦；多分类时，复杂度大</p>
</blockquote>
<h3 id="EM"><a href="#EM" class="headerlink" title="EM"></a>EM</h3><p><code>含隐变量的概率模型</code>、<code>极大似然估计</code></p>
<h4 id="原理-7"><a href="#原理-7" class="headerlink" title="原理"></a>原理</h4><blockquote>
<p>从不完全数据或有数据丢失的数据集（存在隐含变量）中求解概率模型参数的最大似然估计方法。</p>
</blockquote>
<h4 id="解决问题-适用场景-5"><a href="#解决问题-适用场景-5" class="headerlink" title="解决问题(适用场景)"></a>解决问题(适用场景)</h4><blockquote>
<p>含有隐变量、非监督学习<br>高斯混合模型学习中的应用</p>
</blockquote>
<h4 id="技术细节-7"><a href="#技术细节-7" class="headerlink" title="技术细节"></a>技术细节</h4><blockquote>
<p>E步，求期望，根据上一步迭代的模型参数计算隐变量的后验概率；M步，求极大，似然函数最大化获得新的参数值</p>
</blockquote>
<h4 id="优点-7"><a href="#优点-7" class="headerlink" title="优点"></a>优点</h4><blockquote>
<p>思想简单，普适</p>
</blockquote>
<h4 id="缺点-7"><a href="#缺点-7" class="headerlink" title="缺点"></a>缺点</h4><blockquote>
<p>EM算法与初值的选择有关，不同初值，得到不同参数估计；</p>
</blockquote>
<h3 id="归一化使梯度下降收敛更好？"><a href="#归一化使梯度下降收敛更好？" class="headerlink" title="归一化使梯度下降收敛更好？"></a>归一化使梯度下降收敛更好？</h3><blockquote>
<p>如果不归一化，各维特征的跨度差距很大，梯度下降时，目标函数梯度方向就会偏离最小值的方向，走很多弯路，如下方左图。<br>如果归一化了，每一步梯度的方向都指向最小值，收敛更快，如下方右图。</p>
</blockquote>
<p><img src="/images/descend.png" alt="descend"></p>
<h3 id="算法横向比较"><a href="#算法横向比较" class="headerlink" title="算法横向比较"></a>算法横向比较</h3><h4 id="LR与Linear-SVM"><a href="#LR与Linear-SVM" class="headerlink" title="LR与Linear SVM"></a>LR与Linear SVM</h4><ul>
<li>都是线性分类器；</li>
<li>都会受到异常点影响；</li>
<li>本质不同——损失函数，一个hinge loss，一个logistical loss</li>
<li>Linear SVM只受支持向量影响(部分样本)，LR则受所有数据点影响；</li>
<li>Linear SVM需要归一化数据，LR不受影响；</li>
<li>Linear SVM自带正则，而LR需另加；</li>
<li>海量数据LR使用更广泛，Linear SVM内存消耗大</li>
</ul>
<h4 id="LR与朴素贝叶斯"><a href="#LR与朴素贝叶斯" class="headerlink" title="LR与朴素贝叶斯"></a>LR与朴素贝叶斯</h4><ul>
<li>判别/生成model；</li>
<li>朴素贝叶斯条件独立假设；</li>
<li>当数据集小时，首选朴素贝叶斯，数据集大时，考虑LR</li>
</ul>
<h3 id="附两份cheat-sheet"><a href="#附两份cheat-sheet" class="headerlink" title="附两份cheat sheet"></a>附两份cheat sheet</h3><p><img src="/images/sk-learn.png" alt="sk-learn"><br><img src="/images/cheat sheet.png" alt="cheat sheet"></p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote class=&quot;blockquote-center&quot;&gt;&lt;p&gt;简介&lt;br&gt;机器学习大多数场景是搜索、广告、垃圾过滤、安全、推荐系统等等。本文是经典机器学习算法的优劣势比较，欢迎纠正。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Machine Learning" scheme="http://www.phoebepan.cn/categories/Machine-Learning/"/>
    
    
      <category term="ML" scheme="http://www.phoebepan.cn/tags/ML/"/>
    
  </entry>
  
  <entry>
    <title>推荐系统实战——架构</title>
    <link href="http://www.phoebepan.cn/2017/05/22/recsys/"/>
    <id>http://www.phoebepan.cn/2017/05/22/recsys/</id>
    <published>2017-05-22T07:30:16.000Z</published>
    <updated>2017-07-20T07:40:50.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote class="blockquote-center"><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>推荐系统的核心任务可拆解成两部分，一个是如何为给定用户生成特征，另一个是如何根据特征找到物品。用户特征包括，<code>人口统计学特征</code>，<code>用户行为特征</code>，<code>用户话题特征</code>。本文是具体的基于物品的推荐算法系统的架构学习笔记。</p>
</blockquote>
<a id="more"></a>
<h3 id="推荐系统架构图"><a href="#推荐系统架构图" class="headerlink" title="推荐系统架构图"></a>推荐系统架构图</h3><p><img src="/images/recsys_arich.png" alt="recsys_arich" title="基于物品的推荐算法架构图"></p>
<h3 id="生成用户特征向量"><a href="#生成用户特征向量" class="headerlink" title="生成用户特征向量"></a>生成用户特征向量</h3><ul>
<li><strong>用户行为的种类</strong>，一般的标准就是用户付出代价越大的行为权重越高；</li>
<li><strong>用户行为产生的时间</strong>，一般来说，用户近期的行为比较重要，而用户很久之前的行为相对比较次要；</li>
<li><strong>用户行为的次数</strong>，用户对同一个物品的同一种行为发生的次数也反映了用户对物品的兴趣，行为次数多的物品对应的特征权重越高；</li>
<li><strong>物品的热门程度</strong>，加重不热门物品对应的特征的权重。</li>
</ul>
<h3 id="特征—物品相关推荐"><a href="#特征—物品相关推荐" class="headerlink" title="特征—物品相关推荐"></a>特征—物品相关推荐</h3><p>可以离线计算很多相关表，在线服务启动时会将这些相关表按照配置的权<br>重相加，得到最终的相关表保存在内存中，而在给用户进行推荐时，用的是加权后的相关表。</p>
<h3 id="过滤模块"><a href="#过滤模块" class="headerlink" title="过滤模块"></a>过滤模块</h3><ul>
<li>用户已经产生过行为物品</li>
<li>候选物品以外的物品</li>
<li>某些质量很差的物品</li>
</ul>
<h3 id="排名模块"><a href="#排名模块" class="headerlink" title="排名模块"></a>排名模块</h3><ul>
<li>新颖性排名，尽量推荐他们不知道的、长尾中的物品，热门的物品进行降权；</li>
<li>多样性；</li>
<li>时间多样性；</li>
<li>用户反馈，点击率预测。</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote class=&quot;blockquote-center&quot;&gt;&lt;h3 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h3&gt;&lt;p&gt;推荐系统的核心任务可拆解成两部分，一个是如何为给定用户生成特征，另一个是如何根据特征找到物品。用户特征包括，&lt;code&gt;人口统计学特征&lt;/code&gt;，&lt;code&gt;用户行为特征&lt;/code&gt;，&lt;code&gt;用户话题特征&lt;/code&gt;。本文是具体的基于物品的推荐算法系统的架构学习笔记。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Recommendation" scheme="http://www.phoebepan.cn/categories/Recommendation/"/>
    
    
      <category term="Recommendation" scheme="http://www.phoebepan.cn/tags/Recommendation/"/>
    
  </entry>
  
</feed>
